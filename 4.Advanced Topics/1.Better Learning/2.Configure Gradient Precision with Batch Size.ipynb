{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Gradient Precision with Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are trained using gradient descent, where the estimate of the error used to update the weights is calculated based on a subset of the training dataset. The number of examples from the training dataset used in the estimate of the error gradient is called the batch size and is an important hyperparameter that influences the dynamics of the learning algorithm. It is important to explore the dynamics of your model to ensure that you're getting the most out of it. In this tutorial, you will discover three different favors of gradient descent and how to explore and diagnose the effect of batch size on the learning process. After completing this tutorial, you will know:\n",
    "* Batch size controls the accuracy of the estimate of the error gradient when training neural networks.\n",
    "* Batch, Stochastic, and Minibatch gradient descent are the three main favors of the learning algorithm.\n",
    "* There is a tension between batch size and the speed and stability of the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are trained using the stochastic gradient descent optimization algorithm. This involves using the model's current state to predict, compare the prediction to the actual values, and use the difference as an estimate of the error gradient. This error gradient is then used to update the model weights, and the process is repeated. The error gradient is a statistical estimate. The more training examples used in the estimate, the more accurate this estimate will be and the more likely that the weights of the network will be adjusted to improve the model's performance. The improved estimate of the error gradient comes at the computational cost of using the model to make many more predictions before the estimate can be calculated. In turn, the weights updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, using fewer examples results in a less accurate estimate of the error gradient that is highly dependent on the specific training examples used. This results in a noisy estimate that, in turn, results in noisy updates to the model weights, e.g., many updates with perhaps quite different estimates of the error gradient. Nevertheless, these noisy updates can result in faster learning and sometimes a more robust model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of training examples used in the estimate of the error gradient is a hyperparameter for the learning algorithm called the batch size, or simply the batch. A batch size of 32 means that 32 samples from the training dataset will be used to estimate the error gradient before the model weights are updated. One training epoch means that the learning algorithm has made one pass through the training dataset (using every example once), where examples were separated into randomly selected batch size groups. Historically, a training algorithm where the batch size is set to the total number of training examples is called batch gradient descent, and a training algorithm where the batch size is set to 1 training example is called stochastic gradient descent or online gradient descent. A configuration of the batch size anywhere in between (e.g., more than 1 example and less than the number of examples in the training dataset) is called minibatch gradient descent.\n",
    "\n",
    "* **Batch Gradient Descent**. Batch size is set to the total number of examples in the training dataset.\n",
    "* **Stochastic Gradient Descent**. The batch size is set to one.\n",
    "* **Minibatch Gradient Descent**. Batch size is set to more than one and less than the total number of examples in the training dataset.\n",
    "\n",
    "For shorthand, the algorithm is often referred to as stochastic gradient descent regardless of the batch size. Given that very large datasets are often used to train deep learning neural networks, the batch size is rarely set to the size of the training dataset. Smaller batch sizes are used for two main reasons:\n",
    "\n",
    "* Smaller batch sizes are noisy, offering a regularizing effect and lower generalization error.\n",
    "* Smaller batch sizes make it easier to fit one batch's worth of training data in memory (i.e., when using a GPU with access to less local memory than system RAM).\n",
    "\n",
    "A third reason is that the batch size is often set at something small, such as 32 examples, and is not tuned by the practitioner. Small batch sizes such as 32 do work well generally. Nevertheless, the batch size impacts how quickly a model learns and the stability of the learning process. It is an important hyperparameter that should be well understood and tuned by the deep learning practitioner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate how to use gradient descent batch size to control learning with an MLP on a simple classification problem. This example provides a template for exploring batch size with your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a small multiclass classification problem as the basis to demonstrate the effect of batch size on learning. The scikit-learn class provides the make blobs() function that can be used to create a multiclass classification problem with the prescribed number of samples, input variables, classes, and variance of samples within a class. The problem can be configured to have two input variables (representing the x and y coordinates of the points) and a standard deviation of 2.0 for points within each group. We will use the same random state (seed for the pseudorandom number generator) always to get the same data points.\n",
    "\n",
    "```\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are the input and output elements of a dataset that we can model. To get a feeling for the complexity of the problem, we can plot each point on a two-dimensional scatter plot and color each point by class value. The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 2\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "random.seed(seed)\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# scatter plot of blobs dataset\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\n",
    "# scatter plot for each class value\n",
    "for class_value in range(3):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "    \n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "\n",
    "    # show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a scatter plot of the entire dataset. We can see that the standard deviation of 2.0 means that the classes are not linearly separable (separable by a line), causing many ambiguous points. This is desirable as it means that the problem is non-trivial and will allow a neural network model to find many different good enough candidate solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Fit With Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can develop a Multilayer Perceptron model (MLP) to address the multiclass classification problem described in the previous section and train it using batch gradient descent. Firstly, we need to one-hot encode the target variable, transforming the integer class values into binary vectors. This will allow the model to predict the probability of each example belonging to each of the three classes, providing more nuance in the predictions and context when training the model.\n",
    "\n",
    "```\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the training dataset of 1,000 examples into a train and test dataset with 500 examples each. This even split will allow us to evaluate and compare different configurations of the batch size on the model and its performance.\n",
    "\n",
    "```\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "return trainX, trainy, testX, testy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define an MLP model with an input layer that expects two input variables for the two variables in the dataset. The model will have a single hidden layer with 50 nodes and a rectified linear activation function and He random weight initialization. Finally, the output layer has three nodes to make predictions for the three classes and a softmax activation function.\n",
    "\n",
    "```\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will optimize the model with stochastic gradient descent and use categorical cross-entropy to calculate the model's error during training. In this example, we will use batch gradient descent, meaning that the batch size will be set to the size of the training dataset. The model will fit 200 training epochs, and the test dataset will be used as the validation set to monitor the performance of the model on a holdout set during training. The effect will be more time between weight updates, and we would expect faster training than other batch sizes and more stable estimates of the gradient, which should result in a more stable performance of the model during training.\n",
    "\n",
    "```\n",
    "# compile model\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0, batch_size=len(trainX))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is fit, the performance is evaluated and reported on the train and test datasets.\n",
    "\n",
    "```\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot is created showing the train and test set accuracy of the model for each training epoch. These learning curves indicate three things:\n",
    "* how quickly the model learns the problem\n",
    "* how well it has learned the problem\n",
    "* how noisy the updates were to the model during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tying these elements together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 7.4486 - accuracy: 0.3140 - val_loss: 2.1244 - val_accuracy: 0.2720\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1159 - accuracy: 0.2900 - val_loss: 5.0237 - val_accuracy: 0.3260\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1869 - accuracy: 0.3420 - val_loss: 6.2291 - val_accuracy: 0.3260\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.4922 - accuracy: 0.3420 - val_loss: 5.2320 - val_accuracy: 0.3260\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.5168 - accuracy: 0.3420 - val_loss: 2.3969 - val_accuracy: 0.3700\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6128 - accuracy: 0.3580 - val_loss: 3.4920 - val_accuracy: 0.5120\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7005 - accuracy: 0.4800 - val_loss: 3.9491 - val_accuracy: 0.5240\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1219 - accuracy: 0.4700 - val_loss: 1.2553 - val_accuracy: 0.6720\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3672 - accuracy: 0.6240 - val_loss: 2.2887 - val_accuracy: 0.5820\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6108 - accuracy: 0.5500 - val_loss: 2.3259 - val_accuracy: 0.5900\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 2.6594 - accuracy: 0.5500 - val_loss: 1.5186 - val_accuracy: 0.6420\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6699 - accuracy: 0.6200 - val_loss: 1.8162 - val_accuracy: 0.5700\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8982 - accuracy: 0.5480 - val_loss: 1.5983 - val_accuracy: 0.6280\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6772 - accuracy: 0.5680 - val_loss: 1.3799 - val_accuracy: 0.6480\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5021 - accuracy: 0.6200 - val_loss: 1.7208 - val_accuracy: 0.6240\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9350 - accuracy: 0.5960 - val_loss: 1.4069 - val_accuracy: 0.6420\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5534 - accuracy: 0.6140 - val_loss: 0.9495 - val_accuracy: 0.6860\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9713 - accuracy: 0.6280 - val_loss: 1.7301 - val_accuracy: 0.5180\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8271 - accuracy: 0.4940 - val_loss: 1.0677 - val_accuracy: 0.6620\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1813 - accuracy: 0.6240 - val_loss: 1.5282 - val_accuracy: 0.6220\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7504 - accuracy: 0.5840 - val_loss: 1.2535 - val_accuracy: 0.6420\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4276 - accuracy: 0.6080 - val_loss: 0.7610 - val_accuracy: 0.6980\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7928 - accuracy: 0.6680 - val_loss: 2.1733 - val_accuracy: 0.4960\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2590 - accuracy: 0.4640 - val_loss: 0.9704 - val_accuracy: 0.6200\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1077 - accuracy: 0.6020 - val_loss: 1.5088 - val_accuracy: 0.5760\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7612 - accuracy: 0.5480 - val_loss: 1.2391 - val_accuracy: 0.6140\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4447 - accuracy: 0.5800 - val_loss: 0.6409 - val_accuracy: 0.7080\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.6460 - val_loss: 2.1941 - val_accuracy: 0.4900\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3111 - accuracy: 0.4540 - val_loss: 0.8060 - val_accuracy: 0.7040\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8905 - accuracy: 0.6700 - val_loss: 1.2972 - val_accuracy: 0.6180\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4933 - accuracy: 0.6000 - val_loss: 1.2614 - val_accuracy: 0.6600\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4495 - accuracy: 0.6260 - val_loss: 0.8960 - val_accuracy: 0.7160\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9898 - accuracy: 0.6820 - val_loss: 1.0288 - val_accuracy: 0.6640\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0973 - accuracy: 0.6060 - val_loss: 0.8529 - val_accuracy: 0.7040\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8976 - accuracy: 0.6380 - val_loss: 0.8885 - val_accuracy: 0.6760\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9757 - accuracy: 0.6400 - val_loss: 0.9829 - val_accuracy: 0.6560\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0976 - accuracy: 0.6220 - val_loss: 0.8213 - val_accuracy: 0.6760\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8878 - accuracy: 0.6380 - val_loss: 0.9879 - val_accuracy: 0.5500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0333 - accuracy: 0.5160 - val_loss: 0.7217 - val_accuracy: 0.6820\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7794 - accuracy: 0.6440 - val_loss: 0.7826 - val_accuracy: 0.6940\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8720 - accuracy: 0.6460 - val_loss: 0.7045 - val_accuracy: 0.7040\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7716 - accuracy: 0.6620 - val_loss: 0.9399 - val_accuracy: 0.6520\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9411 - accuracy: 0.6300 - val_loss: 0.6342 - val_accuracy: 0.7200\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6786 - accuracy: 0.6840 - val_loss: 0.6814 - val_accuracy: 0.6700\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7540 - accuracy: 0.6200 - val_loss: 0.6798 - val_accuracy: 0.6740\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7402 - accuracy: 0.6160 - val_loss: 0.6978 - val_accuracy: 0.7080\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7278 - accuracy: 0.6760 - val_loss: 0.6271 - val_accuracy: 0.7380\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6579 - accuracy: 0.6880 - val_loss: 0.5964 - val_accuracy: 0.7160\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6344 - accuracy: 0.6820 - val_loss: 0.6113 - val_accuracy: 0.7400\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6488 - accuracy: 0.7080 - val_loss: 0.6508 - val_accuracy: 0.7720\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6854 - accuracy: 0.7180 - val_loss: 0.6297 - val_accuracy: 0.7780\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6581 - accuracy: 0.7100 - val_loss: 0.5997 - val_accuracy: 0.7560\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6296 - accuracy: 0.7040 - val_loss: 0.6053 - val_accuracy: 0.7140\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6401 - accuracy: 0.6800 - val_loss: 0.6031 - val_accuracy: 0.7380\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6323 - accuracy: 0.6900 - val_loss: 0.6030 - val_accuracy: 0.7580\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6269 - accuracy: 0.7140 - val_loss: 0.5701 - val_accuracy: 0.7300\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5953 - accuracy: 0.7080 - val_loss: 0.5655 - val_accuracy: 0.7460\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5920 - accuracy: 0.7140 - val_loss: 0.5802 - val_accuracy: 0.7820\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6016 - accuracy: 0.7480 - val_loss: 0.5922 - val_accuracy: 0.7960\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6094 - accuracy: 0.7480 - val_loss: 0.5626 - val_accuracy: 0.7680\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5819 - accuracy: 0.7420 - val_loss: 0.5592 - val_accuracy: 0.7560\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5778 - accuracy: 0.7300 - val_loss: 0.5660 - val_accuracy: 0.7620\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5766 - accuracy: 0.7380 - val_loss: 0.5743 - val_accuracy: 0.7680\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5803 - accuracy: 0.7440 - val_loss: 0.5668 - val_accuracy: 0.7640\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5740 - accuracy: 0.7400 - val_loss: 0.5649 - val_accuracy: 0.7680\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5702 - accuracy: 0.7380 - val_loss: 0.5672 - val_accuracy: 0.7940\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5673 - accuracy: 0.7480 - val_loss: 0.5704 - val_accuracy: 0.7980\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5704 - accuracy: 0.7420 - val_loss: 0.5616 - val_accuracy: 0.7880\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5656 - accuracy: 0.7540 - val_loss: 0.5529 - val_accuracy: 0.7860\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5578 - accuracy: 0.7400 - val_loss: 0.5484 - val_accuracy: 0.8040\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5503 - accuracy: 0.7580 - val_loss: 0.5476 - val_accuracy: 0.7960\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5509 - accuracy: 0.7580 - val_loss: 0.5412 - val_accuracy: 0.7760\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5513 - accuracy: 0.7380 - val_loss: 0.5388 - val_accuracy: 0.7760\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5499 - accuracy: 0.7440 - val_loss: 0.5405 - val_accuracy: 0.8040\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5468 - accuracy: 0.7540 - val_loss: 0.5379 - val_accuracy: 0.8140\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5440 - accuracy: 0.7640 - val_loss: 0.5354 - val_accuracy: 0.8060\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5443 - accuracy: 0.7600 - val_loss: 0.5348 - val_accuracy: 0.8140\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5417 - accuracy: 0.7600 - val_loss: 0.5359 - val_accuracy: 0.8160\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5394 - accuracy: 0.7620 - val_loss: 0.5317 - val_accuracy: 0.8040\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5367 - accuracy: 0.7600 - val_loss: 0.5300 - val_accuracy: 0.8020\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5303 - val_accuracy: 0.7980\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5362 - accuracy: 0.7520 - val_loss: 0.5318 - val_accuracy: 0.8080\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5352 - accuracy: 0.7560 - val_loss: 0.5272 - val_accuracy: 0.8040\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5317 - accuracy: 0.7560 - val_loss: 0.5245 - val_accuracy: 0.8100\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5306 - accuracy: 0.7520 - val_loss: 0.5250 - val_accuracy: 0.8080\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5293 - accuracy: 0.7620 - val_loss: 0.5260 - val_accuracy: 0.8140\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5293 - accuracy: 0.7680 - val_loss: 0.5215 - val_accuracy: 0.8120\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5274 - accuracy: 0.7660 - val_loss: 0.5192 - val_accuracy: 0.8100\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5266 - accuracy: 0.7600 - val_loss: 0.5200 - val_accuracy: 0.8120\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5255 - accuracy: 0.7680 - val_loss: 0.5196 - val_accuracy: 0.8100\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5248 - accuracy: 0.7720 - val_loss: 0.5163 - val_accuracy: 0.8060\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5232 - accuracy: 0.7620 - val_loss: 0.5152 - val_accuracy: 0.8060\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5217 - accuracy: 0.7620 - val_loss: 0.5163 - val_accuracy: 0.8120\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5205 - accuracy: 0.7700 - val_loss: 0.5157 - val_accuracy: 0.8160\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5198 - accuracy: 0.7680 - val_loss: 0.5136 - val_accuracy: 0.8120\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5191 - accuracy: 0.7640 - val_loss: 0.5126 - val_accuracy: 0.8120\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5179 - accuracy: 0.7660 - val_loss: 0.5124 - val_accuracy: 0.8180\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5168 - accuracy: 0.7760 - val_loss: 0.5106 - val_accuracy: 0.8180\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5157 - accuracy: 0.7680 - val_loss: 0.5084 - val_accuracy: 0.8120\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5149 - accuracy: 0.7680 - val_loss: 0.5074 - val_accuracy: 0.8140\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5139 - accuracy: 0.7720 - val_loss: 0.5073 - val_accuracy: 0.8180\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5129 - accuracy: 0.7780 - val_loss: 0.5060 - val_accuracy: 0.8180\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5119 - accuracy: 0.7880 - val_loss: 0.5045 - val_accuracy: 0.8100\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5111 - accuracy: 0.7940 - val_loss: 0.5039 - val_accuracy: 0.8120\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5103 - accuracy: 0.7920 - val_loss: 0.5041 - val_accuracy: 0.8160\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5093 - accuracy: 0.7980 - val_loss: 0.5027 - val_accuracy: 0.8160\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5083 - accuracy: 0.7940 - val_loss: 0.5012 - val_accuracy: 0.8140\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5073 - accuracy: 0.7920 - val_loss: 0.5009 - val_accuracy: 0.8200\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5065 - accuracy: 0.7920 - val_loss: 0.5010 - val_accuracy: 0.8220\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5057 - accuracy: 0.7880 - val_loss: 0.4998 - val_accuracy: 0.8180\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5048 - accuracy: 0.7920 - val_loss: 0.4986 - val_accuracy: 0.8160\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5040 - accuracy: 0.7900 - val_loss: 0.4983 - val_accuracy: 0.8200\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5030 - accuracy: 0.7940 - val_loss: 0.4977 - val_accuracy: 0.8200\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5023 - accuracy: 0.7940 - val_loss: 0.4966 - val_accuracy: 0.8220\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5014 - accuracy: 0.7920 - val_loss: 0.4953 - val_accuracy: 0.8180\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5006 - accuracy: 0.7960 - val_loss: 0.4944 - val_accuracy: 0.8200\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4997 - accuracy: 0.8000 - val_loss: 0.4938 - val_accuracy: 0.8200\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4989 - accuracy: 0.8020 - val_loss: 0.4926 - val_accuracy: 0.8220\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4981 - accuracy: 0.8020 - val_loss: 0.4916 - val_accuracy: 0.8220\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4973 - accuracy: 0.8020 - val_loss: 0.4910 - val_accuracy: 0.8220\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4965 - accuracy: 0.8020 - val_loss: 0.4905 - val_accuracy: 0.8220\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4956 - accuracy: 0.8000 - val_loss: 0.4897 - val_accuracy: 0.8200\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4949 - accuracy: 0.7980 - val_loss: 0.4887 - val_accuracy: 0.8200\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4941 - accuracy: 0.7960 - val_loss: 0.4883 - val_accuracy: 0.8220\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4934 - accuracy: 0.7980 - val_loss: 0.4877 - val_accuracy: 0.8220\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4926 - accuracy: 0.7980 - val_loss: 0.4869 - val_accuracy: 0.8220\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4918 - accuracy: 0.8000 - val_loss: 0.4858 - val_accuracy: 0.8220\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4911 - accuracy: 0.7980 - val_loss: 0.4853 - val_accuracy: 0.8200\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4903 - accuracy: 0.8020 - val_loss: 0.4848 - val_accuracy: 0.8220\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4895 - accuracy: 0.8020 - val_loss: 0.4837 - val_accuracy: 0.8240\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4888 - accuracy: 0.8000 - val_loss: 0.4830 - val_accuracy: 0.8240\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4880 - accuracy: 0.7960 - val_loss: 0.4825 - val_accuracy: 0.8280\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4873 - accuracy: 0.8020 - val_loss: 0.4818 - val_accuracy: 0.8260\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4865 - accuracy: 0.8020 - val_loss: 0.4811 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4859 - accuracy: 0.8020 - val_loss: 0.4803 - val_accuracy: 0.8240\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4851 - accuracy: 0.8000 - val_loss: 0.4796 - val_accuracy: 0.8280\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4844 - accuracy: 0.8020 - val_loss: 0.4791 - val_accuracy: 0.8260\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4837 - accuracy: 0.8020 - val_loss: 0.4784 - val_accuracy: 0.8260\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4830 - accuracy: 0.8020 - val_loss: 0.4776 - val_accuracy: 0.8260\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4823 - accuracy: 0.8000 - val_loss: 0.4773 - val_accuracy: 0.8260\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4816 - accuracy: 0.7980 - val_loss: 0.4767 - val_accuracy: 0.8260\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4808 - accuracy: 0.7980 - val_loss: 0.4757 - val_accuracy: 0.8260\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4802 - accuracy: 0.8000 - val_loss: 0.4751 - val_accuracy: 0.8260\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4795 - accuracy: 0.8000 - val_loss: 0.4748 - val_accuracy: 0.8280\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4788 - accuracy: 0.8000 - val_loss: 0.4740 - val_accuracy: 0.8280\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4781 - accuracy: 0.8000 - val_loss: 0.4731 - val_accuracy: 0.8280\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4774 - accuracy: 0.8000 - val_loss: 0.4725 - val_accuracy: 0.8280\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4767 - accuracy: 0.8000 - val_loss: 0.4722 - val_accuracy: 0.8300\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4760 - accuracy: 0.7980 - val_loss: 0.4715 - val_accuracy: 0.8280\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4754 - accuracy: 0.8000 - val_loss: 0.4706 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4747 - accuracy: 0.8020 - val_loss: 0.4701 - val_accuracy: 0.8280\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4740 - accuracy: 0.8000 - val_loss: 0.4699 - val_accuracy: 0.8320\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4734 - accuracy: 0.8000 - val_loss: 0.4692 - val_accuracy: 0.8300\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4728 - accuracy: 0.8000 - val_loss: 0.4683 - val_accuracy: 0.8320\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4721 - accuracy: 0.8000 - val_loss: 0.4680 - val_accuracy: 0.8320\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4715 - accuracy: 0.8000 - val_loss: 0.4676 - val_accuracy: 0.8320\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4708 - accuracy: 0.8000 - val_loss: 0.4669 - val_accuracy: 0.8320\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4702 - accuracy: 0.8000 - val_loss: 0.4662 - val_accuracy: 0.8340\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4695 - accuracy: 0.8000 - val_loss: 0.4657 - val_accuracy: 0.8360\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4689 - accuracy: 0.8000 - val_loss: 0.4653 - val_accuracy: 0.8340\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4683 - accuracy: 0.8020 - val_loss: 0.4647 - val_accuracy: 0.8360\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4677 - accuracy: 0.8040 - val_loss: 0.4640 - val_accuracy: 0.8380\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4671 - accuracy: 0.8040 - val_loss: 0.4634 - val_accuracy: 0.8380\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4665 - accuracy: 0.8040 - val_loss: 0.4633 - val_accuracy: 0.8380\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4659 - accuracy: 0.8080 - val_loss: 0.4625 - val_accuracy: 0.8380\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4653 - accuracy: 0.8080 - val_loss: 0.4618 - val_accuracy: 0.8380\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4647 - accuracy: 0.8040 - val_loss: 0.4615 - val_accuracy: 0.8380\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4641 - accuracy: 0.8080 - val_loss: 0.4610 - val_accuracy: 0.8380\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4635 - accuracy: 0.8080 - val_loss: 0.4605 - val_accuracy: 0.8380\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4629 - accuracy: 0.8080 - val_loss: 0.4599 - val_accuracy: 0.8380\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4624 - accuracy: 0.8080 - val_loss: 0.4593 - val_accuracy: 0.8380\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4618 - accuracy: 0.8080 - val_loss: 0.4590 - val_accuracy: 0.8380\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4612 - accuracy: 0.8080 - val_loss: 0.4585 - val_accuracy: 0.8380\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4607 - accuracy: 0.8080 - val_loss: 0.4578 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4601 - accuracy: 0.8080 - val_loss: 0.4573 - val_accuracy: 0.8380\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4596 - accuracy: 0.8080 - val_loss: 0.4572 - val_accuracy: 0.8360\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4590 - accuracy: 0.8100 - val_loss: 0.4564 - val_accuracy: 0.8380\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4585 - accuracy: 0.8080 - val_loss: 0.4557 - val_accuracy: 0.8380\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4580 - accuracy: 0.8080 - val_loss: 0.4556 - val_accuracy: 0.8360\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4574 - accuracy: 0.8100 - val_loss: 0.4550 - val_accuracy: 0.8360\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4568 - accuracy: 0.8100 - val_loss: 0.4544 - val_accuracy: 0.8360\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4563 - accuracy: 0.8100 - val_loss: 0.4539 - val_accuracy: 0.8360\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4558 - accuracy: 0.8100 - val_loss: 0.4534 - val_accuracy: 0.8360\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4553 - accuracy: 0.8100 - val_loss: 0.4532 - val_accuracy: 0.8360\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4548 - accuracy: 0.8100 - val_loss: 0.4526 - val_accuracy: 0.8340\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4542 - accuracy: 0.8100 - val_loss: 0.4520 - val_accuracy: 0.8340\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4538 - accuracy: 0.8100 - val_loss: 0.4518 - val_accuracy: 0.8340\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4532 - accuracy: 0.8120 - val_loss: 0.4514 - val_accuracy: 0.8340\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4528 - accuracy: 0.8140 - val_loss: 0.4506 - val_accuracy: 0.8340\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4523 - accuracy: 0.8120 - val_loss: 0.4504 - val_accuracy: 0.8340\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4518 - accuracy: 0.8120 - val_loss: 0.4500 - val_accuracy: 0.8340\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4512 - accuracy: 0.8160 - val_loss: 0.4494 - val_accuracy: 0.8300\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4507 - accuracy: 0.8180 - val_loss: 0.4490 - val_accuracy: 0.8300\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4503 - accuracy: 0.8180 - val_loss: 0.4485 - val_accuracy: 0.8320\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4498 - accuracy: 0.8160 - val_loss: 0.4484 - val_accuracy: 0.8320\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4494 - accuracy: 0.8160 - val_loss: 0.4478 - val_accuracy: 0.8320\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4489 - accuracy: 0.8180 - val_loss: 0.4473 - val_accuracy: 0.8320\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4484 - accuracy: 0.8180 - val_loss: 0.4469 - val_accuracy: 0.8320\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4480 - accuracy: 0.8180 - val_loss: 0.4468 - val_accuracy: 0.8320\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4475 - accuracy: 0.8180 - val_loss: 0.4461 - val_accuracy: 0.8340\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.8200\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8340\n",
      "Train: 0.820, Test: 0.834\n"
     ]
    }
   ],
   "source": [
    "#Plot of images as baseline for comparison\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# prepare multiclass classification dataset\n",
    "def create_dataset():\n",
    "    # generate 2d classification dataset\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "    \n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "    \n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "    \n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# fit model with given number of nodes, returns test set accuracy\n",
    "def evaluate_model(n_nodes, trainX, trainy, testX, testy, batch_size, learning_rate = 0.01):\n",
    "    # configure the model based on the data\n",
    "    n_input, n_classes = trainX.shape[1], testy.shape[1]\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, input_dim=n_input, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # fit model on train set\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, batch_size=batch_size)\n",
    "\n",
    "    # evaluate model on test set\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=1)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=1)\n",
    "    \n",
    "    return history, train_acc, test_acc\n",
    "\n",
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = create_dataset()\n",
    "history, train_acc, test_acc = evaluate_model(50, trainX, trainy, testX, testy, batch_size = len(trainX))\n",
    "\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the performance of the model on the train and test datasets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that performance was similar between the train and test sets with 81% and 83%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot of model loss and classification accuracy on the train (blue) and test (orange) dataset is created. We can see that the model is relatively slow to learn this problem, converging on a solution after about 100 epochs, after which changes in model performance are minor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Fit With Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of batch gradient descent from the previous section can be updated instead of stochastic gradient descent. This requires changing the batch size from the size of the training dataset to 1.\n",
    "\n",
    "```\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=0, batch_size=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent requires that the model make a prediction and have the weights updated for each training example. This has the effect of dramatically slowing down the training process as compared to batch gradient descent. This change expects that the model learns faster (e.g., in terms of the learning curve) and that changes to the model are noisy, resulting, in turn, in noisy performance over training epochs. The complete example with this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 3.4254 - accuracy: 0.4299 - val_loss: 0.9674 - val_accuracy: 0.5900\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0382 - accuracy: 0.5435 - val_loss: 0.9413 - val_accuracy: 0.5200\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0127 - accuracy: 0.4958 - val_loss: 0.9922 - val_accuracy: 0.4580\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0265 - accuracy: 0.4134 - val_loss: 1.0437 - val_accuracy: 0.4080\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9453 - accuracy: 0.4762 - val_loss: 1.0550 - val_accuracy: 0.5280\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9487 - accuracy: 0.4856 - val_loss: 0.9530 - val_accuracy: 0.5080\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9353 - accuracy: 0.4988 - val_loss: 0.9291 - val_accuracy: 0.5100\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9246 - accuracy: 0.4877 - val_loss: 0.9256 - val_accuracy: 0.5920\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9244 - accuracy: 0.5433 - val_loss: 0.8591 - val_accuracy: 0.6120\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9329 - accuracy: 0.5886 - val_loss: 0.8825 - val_accuracy: 0.5220\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8279 - accuracy: 0.5816 - val_loss: 0.7667 - val_accuracy: 0.6060\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8677 - accuracy: 0.5806 - val_loss: 0.9246 - val_accuracy: 0.5720\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8739 - accuracy: 0.6290 - val_loss: 1.0188 - val_accuracy: 0.6280\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9277 - accuracy: 0.5814 - val_loss: 0.9060 - val_accuracy: 0.4780\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8431 - accuracy: 0.6228 - val_loss: 0.7151 - val_accuracy: 0.7020\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8912 - accuracy: 0.5692 - val_loss: 0.8850 - val_accuracy: 0.6800\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8729 - accuracy: 0.6596 - val_loss: 1.0081 - val_accuracy: 0.6020\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9552 - accuracy: 0.5747 - val_loss: 0.9929 - val_accuracy: 0.5580\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9849 - accuracy: 0.5255 - val_loss: 0.8031 - val_accuracy: 0.6900\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8916 - accuracy: 0.5898 - val_loss: 0.7895 - val_accuracy: 0.6800\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9166 - accuracy: 0.5450 - val_loss: 0.6488 - val_accuracy: 0.7400\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8193 - accuracy: 0.6364 - val_loss: 0.8987 - val_accuracy: 0.5480\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0335 - accuracy: 0.5462 - val_loss: 0.9532 - val_accuracy: 0.5400\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9369 - accuracy: 0.4969 - val_loss: 1.0004 - val_accuracy: 0.4780\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8562 - accuracy: 0.6037 - val_loss: 0.9654 - val_accuracy: 0.5160\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9919 - accuracy: 0.4862 - val_loss: 0.9993 - val_accuracy: 0.5020\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9302 - accuracy: 0.5094 - val_loss: 1.0459 - val_accuracy: 0.5520\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9701 - accuracy: 0.5586 - val_loss: 1.0021 - val_accuracy: 0.4700\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9440 - accuracy: 0.5106 - val_loss: 0.9965 - val_accuracy: 0.5460\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9268 - accuracy: 0.5524 - val_loss: 0.8472 - val_accuracy: 0.6520\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7805 - accuracy: 0.6383 - val_loss: 1.1086 - val_accuracy: 0.4880\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.3015 - accuracy: 0.4623 - val_loss: 0.9465 - val_accuracy: 0.5220\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9616 - accuracy: 0.5268 - val_loss: 1.0413 - val_accuracy: 0.5780\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0130 - accuracy: 0.5059 - val_loss: 0.9182 - val_accuracy: 0.5520\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9012 - accuracy: 0.5609 - val_loss: 1.2811 - val_accuracy: 0.5120\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7972 - accuracy: 0.6619 - val_loss: 0.8696 - val_accuracy: 0.5280\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8803 - accuracy: 0.5511 - val_loss: 0.8292 - val_accuracy: 0.6720\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8345 - accuracy: 0.6191 - val_loss: 0.9373 - val_accuracy: 0.5080\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9596 - accuracy: 0.4669 - val_loss: 0.9405 - val_accuracy: 0.5200\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9899 - accuracy: 0.4466 - val_loss: 0.9850 - val_accuracy: 0.5560\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9872 - accuracy: 0.5254 - val_loss: 0.9080 - val_accuracy: 0.5440\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9130 - accuracy: 0.5486 - val_loss: 0.7894 - val_accuracy: 0.6300\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9548 - accuracy: 0.5674 - val_loss: 0.9930 - val_accuracy: 0.4980\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9997 - accuracy: 0.4558 - val_loss: 1.0189 - val_accuracy: 0.5580\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0464 - accuracy: 0.4928 - val_loss: 0.8749 - val_accuracy: 0.5860\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8800 - accuracy: 0.5580 - val_loss: 1.1498 - val_accuracy: 0.3980\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8978 - accuracy: 0.5530 - val_loss: 0.6834 - val_accuracy: 0.6920\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7619 - accuracy: 0.6626 - val_loss: 1.4196 - val_accuracy: 0.5160\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9501 - accuracy: 0.5630 - val_loss: 0.8316 - val_accuracy: 0.5640\n",
      "Epoch 50/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8088 - accuracy: 0.6392 - val_loss: 0.8930 - val_accuracy: 0.5660\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7841 - accuracy: 0.6229 - val_loss: 0.7769 - val_accuracy: 0.6380\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7779 - accuracy: 0.6439 - val_loss: 1.0907 - val_accuracy: 0.5420\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8464 - accuracy: 0.6361 - val_loss: 0.8735 - val_accuracy: 0.5780\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7898 - accuracy: 0.6316 - val_loss: 0.8359 - val_accuracy: 0.6160\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7373 - accuracy: 0.6766 - val_loss: 0.8259 - val_accuracy: 0.6220\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8238 - accuracy: 0.6402 - val_loss: 0.8478 - val_accuracy: 0.6080\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8639 - accuracy: 0.6202 - val_loss: 0.9381 - val_accuracy: 0.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9419 - accuracy: 0.5397 - val_loss: 1.0112 - val_accuracy: 0.5720\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0301 - accuracy: 0.5525 - val_loss: 0.9300 - val_accuracy: 0.5020\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9347 - accuracy: 0.5236 - val_loss: 0.9552 - val_accuracy: 0.5720\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9275 - accuracy: 0.5518 - val_loss: 0.8227 - val_accuracy: 0.5900\n",
      "Epoch 62/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7878 - accuracy: 0.6130 - val_loss: 0.7590 - val_accuracy: 0.6520\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8106 - accuracy: 0.6127 - val_loss: 0.7357 - val_accuracy: 0.6740\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8975 - accuracy: 0.5627 - val_loss: 0.9770 - val_accuracy: 0.4800\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8830 - accuracy: 0.5794 - val_loss: 1.0106 - val_accuracy: 0.5340\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9953 - accuracy: 0.4331 - val_loss: 0.9059 - val_accuracy: 0.5440\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9036 - accuracy: 0.5378 - val_loss: 0.8957 - val_accuracy: 0.5420\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8521 - accuracy: 0.5775 - val_loss: 0.8313 - val_accuracy: 0.5800\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8241 - accuracy: 0.6690 - val_loss: 1.0453 - val_accuracy: 0.5600\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9999 - accuracy: 0.5450 - val_loss: 1.0785 - val_accuracy: 0.4340\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9686 - accuracy: 0.5180 - val_loss: 0.9891 - val_accuracy: 0.4600\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9254 - accuracy: 0.5393 - val_loss: 0.9540 - val_accuracy: 0.5600\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0433 - accuracy: 0.4238 - val_loss: 1.0363 - val_accuracy: 0.5440\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0993 - accuracy: 0.4444 - val_loss: 1.0573 - val_accuracy: 0.5640\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9085 - accuracy: 0.5237 - val_loss: 0.8370 - val_accuracy: 0.5960\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9880 - accuracy: 0.5588 - val_loss: 0.9779 - val_accuracy: 0.5220\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9189 - accuracy: 0.5679 - val_loss: 1.0116 - val_accuracy: 0.5060\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0297 - accuracy: 0.5162 - val_loss: 0.9875 - val_accuracy: 0.5440\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9058 - accuracy: 0.5731 - val_loss: 1.0209 - val_accuracy: 0.5020\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8945 - accuracy: 0.5485 - val_loss: 0.9386 - val_accuracy: 0.4520\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9816 - accuracy: 0.5286 - val_loss: 0.8185 - val_accuracy: 0.5780\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8979 - accuracy: 0.5331 - val_loss: 0.7337 - val_accuracy: 0.5920\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8481 - accuracy: 0.6778 - val_loss: 0.9836 - val_accuracy: 0.5380\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0075 - accuracy: 0.5122 - val_loss: 1.0040 - val_accuracy: 0.5120\n",
      "Epoch 85/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0657 - accuracy: 0.4520 - val_loss: 0.9660 - val_accuracy: 0.5160\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9936 - accuracy: 0.4702 - val_loss: 0.9132 - val_accuracy: 0.4800\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8997 - accuracy: 0.5054 - val_loss: 0.7448 - val_accuracy: 0.7240\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8973 - accuracy: 0.6570 - val_loss: 0.9286 - val_accuracy: 0.5380\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9098 - accuracy: 0.5404 - val_loss: 0.9888 - val_accuracy: 0.5160\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9098 - accuracy: 0.5718 - val_loss: 1.0814 - val_accuracy: 0.5420\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9592 - accuracy: 0.5043 - val_loss: 0.8468 - val_accuracy: 0.5720\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8943 - accuracy: 0.5703 - val_loss: 0.7917 - val_accuracy: 0.6200\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8287 - accuracy: 0.6270 - val_loss: 0.9072 - val_accuracy: 0.4580\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8991 - accuracy: 0.5564 - val_loss: 0.9269 - val_accuracy: 0.6040\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9488 - accuracy: 0.5700 - val_loss: 0.8853 - val_accuracy: 0.5340\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8872 - accuracy: 0.5981 - val_loss: 0.9507 - val_accuracy: 0.5580\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9307 - accuracy: 0.5899 - val_loss: 0.8490 - val_accuracy: 0.5960\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8673 - accuracy: 0.5912 - val_loss: 0.6745 - val_accuracy: 0.7080\n",
      "Epoch 99/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7279 - accuracy: 0.6875 - val_loss: 0.9775 - val_accuracy: 0.5580\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8864 - accuracy: 0.6090 - val_loss: 0.8258 - val_accuracy: 0.6680\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7347 - accuracy: 0.6745 - val_loss: 1.2190 - val_accuracy: 0.5060\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8641 - accuracy: 0.5766 - val_loss: 0.9204 - val_accuracy: 0.6080\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9459 - accuracy: 0.5717 - val_loss: 0.8559 - val_accuracy: 0.5160\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9457 - accuracy: 0.5757 - val_loss: 1.0180 - val_accuracy: 0.6320\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8897 - accuracy: 0.5646 - val_loss: 0.9268 - val_accuracy: 0.5880\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9661 - accuracy: 0.5729 - val_loss: 0.8774 - val_accuracy: 0.6500\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8301 - accuracy: 0.6369 - val_loss: 0.9429 - val_accuracy: 0.4920\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9568 - accuracy: 0.4829 - val_loss: 1.1515 - val_accuracy: 0.6200\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7896 - accuracy: 0.6690 - val_loss: 0.8117 - val_accuracy: 0.7240\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7711 - accuracy: 0.6942 - val_loss: 0.8949 - val_accuracy: 0.6080\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9104 - accuracy: 0.5944 - val_loss: 1.1053 - val_accuracy: 0.6360\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8817 - accuracy: 0.6037 - val_loss: 0.8975 - val_accuracy: 0.4440\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8534 - accuracy: 0.5921 - val_loss: 0.7196 - val_accuracy: 0.7260\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0077 - accuracy: 0.5579 - val_loss: 1.0821 - val_accuracy: 0.4660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9229 - accuracy: 0.4841 - val_loss: 0.8547 - val_accuracy: 0.5940\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9414 - accuracy: 0.5546 - val_loss: 0.7332 - val_accuracy: 0.7640\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8062 - accuracy: 0.6693 - val_loss: 0.9201 - val_accuracy: 0.4300\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8297 - accuracy: 0.6262 - val_loss: 0.6692 - val_accuracy: 0.7360\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8299 - accuracy: 0.6715 - val_loss: 0.8985 - val_accuracy: 0.6920\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8457 - accuracy: 0.6679 - val_loss: 0.8448 - val_accuracy: 0.5980\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9077 - accuracy: 0.5441 - val_loss: 0.8582 - val_accuracy: 0.5820\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8722 - accuracy: 0.6199 - val_loss: 1.0347 - val_accuracy: 0.4860\n",
      "Epoch 123/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8721 - accuracy: 0.5836 - val_loss: 0.8856 - val_accuracy: 0.6040\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8660 - accuracy: 0.6527 - val_loss: 0.7497 - val_accuracy: 0.6520\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8367 - accuracy: 0.6358 - val_loss: 0.9764 - val_accuracy: 0.4860\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0072 - accuracy: 0.5232 - val_loss: 0.9996 - val_accuracy: 0.5480\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9455 - accuracy: 0.5507 - val_loss: 0.9059 - val_accuracy: 0.5940\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8887 - accuracy: 0.5608 - val_loss: 0.9006 - val_accuracy: 0.5760\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7885 - accuracy: 0.5877 - val_loss: 0.9810 - val_accuracy: 0.5260\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9530 - accuracy: 0.4750 - val_loss: 0.8623 - val_accuracy: 0.5720\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8661 - accuracy: 0.5848 - val_loss: 0.8023 - val_accuracy: 0.6200\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8497 - accuracy: 0.6393 - val_loss: 1.0386 - val_accuracy: 0.5600\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8773 - accuracy: 0.5674 - val_loss: 0.9656 - val_accuracy: 0.5140\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9082 - accuracy: 0.5681 - val_loss: 1.0031 - val_accuracy: 0.5780\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9250 - accuracy: 0.5904 - val_loss: 1.0167 - val_accuracy: 0.5040\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9633 - accuracy: 0.4651 - val_loss: 0.8994 - val_accuracy: 0.5600\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9246 - accuracy: 0.5439 - val_loss: 0.9480 - val_accuracy: 0.6700\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8910 - accuracy: 0.6151 - val_loss: 0.8954 - val_accuracy: 0.5660\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8894 - accuracy: 0.5811 - val_loss: 0.9220 - val_accuracy: 0.5780\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8089 - accuracy: 0.6272 - val_loss: 0.8908 - val_accuracy: 0.4800\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8942 - accuracy: 0.5378 - val_loss: 0.8838 - val_accuracy: 0.5580\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8112 - accuracy: 0.5777 - val_loss: 0.7558 - val_accuracy: 0.6420\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8041 - accuracy: 0.6173 - val_loss: 0.8884 - val_accuracy: 0.6740\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8510 - accuracy: 0.6252 - val_loss: 0.9681 - val_accuracy: 0.4840\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9229 - accuracy: 0.4783 - val_loss: 1.3526 - val_accuracy: 0.4760\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1389 - accuracy: 0.4685 - val_loss: 0.9995 - val_accuracy: 0.5220\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9830 - accuracy: 0.5142 - val_loss: 0.7861 - val_accuracy: 0.6700\n",
      "Epoch 148/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8018 - accuracy: 0.5725 - val_loss: 0.6546 - val_accuracy: 0.7240\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9872 - accuracy: 0.5413 - val_loss: 0.9701 - val_accuracy: 0.5540\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9658 - accuracy: 0.5244 - val_loss: 0.8211 - val_accuracy: 0.5220\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8272 - accuracy: 0.6339 - val_loss: 0.9130 - val_accuracy: 0.5940\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8978 - accuracy: 0.5729 - val_loss: 0.9719 - val_accuracy: 0.5360\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9599 - accuracy: 0.4691 - val_loss: 0.9289 - val_accuracy: 0.5460\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9152 - accuracy: 0.5225 - val_loss: 1.5667 - val_accuracy: 0.5080\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9023 - accuracy: 0.6216 - val_loss: 0.7048 - val_accuracy: 0.6900\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1594 - accuracy: 0.5193 - val_loss: 1.0552 - val_accuracy: 0.4940\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0482 - accuracy: 0.4867 - val_loss: 0.8881 - val_accuracy: 0.6420\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8472 - accuracy: 0.6422 - val_loss: 0.8670 - val_accuracy: 0.6200\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8230 - accuracy: 0.5976 - val_loss: 0.6819 - val_accuracy: 0.6940\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8730 - accuracy: 0.6385 - val_loss: 0.9349 - val_accuracy: 0.5900\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7937 - accuracy: 0.6455 - val_loss: 0.8158 - val_accuracy: 0.7020\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6993 - accuracy: 0.6533 - val_loss: 1.1152 - val_accuracy: 0.5980\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8989 - accuracy: 0.5787 - val_loss: 0.8113 - val_accuracy: 0.6340\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7846 - accuracy: 0.6338 - val_loss: 0.8665 - val_accuracy: 0.6220\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8783 - accuracy: 0.6379 - val_loss: 0.9553 - val_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8794 - accuracy: 0.5559 - val_loss: 0.7316 - val_accuracy: 0.6840\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8544 - accuracy: 0.6095 - val_loss: 0.9763 - val_accuracy: 0.4920\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8764 - accuracy: 0.5680 - val_loss: 1.0106 - val_accuracy: 0.5720\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9876 - accuracy: 0.5888 - val_loss: 0.7244 - val_accuracy: 0.6960\n",
      "Epoch 170/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9007 - accuracy: 0.5821 - val_loss: 1.0919 - val_accuracy: 0.5600\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0754 - accuracy: 0.5648 - val_loss: 0.7959 - val_accuracy: 0.7380\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7232 - accuracy: 0.6877 - val_loss: 0.8006 - val_accuracy: 0.6640\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8272 - accuracy: 0.6138 - val_loss: 0.8635 - val_accuracy: 0.6540\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7485 - accuracy: 0.6733 - val_loss: 1.1686 - val_accuracy: 0.6020\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8829 - accuracy: 0.6010 - val_loss: 0.9993 - val_accuracy: 0.4220\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8056 - accuracy: 0.6186 - val_loss: 0.9646 - val_accuracy: 0.5640\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9230 - accuracy: 0.5694 - val_loss: 0.8403 - val_accuracy: 0.6160\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8244 - accuracy: 0.6426 - val_loss: 0.8613 - val_accuracy: 0.5860\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9408 - accuracy: 0.5254 - val_loss: 1.1828 - val_accuracy: 0.4640\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.0146 - accuracy: 0.4945 - val_loss: 0.8363 - val_accuracy: 0.6100\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7504 - accuracy: 0.6418 - val_loss: 2.3742 - val_accuracy: 0.4600\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8714 - accuracy: 0.6127 - val_loss: 0.8738 - val_accuracy: 0.4360\n",
      "Epoch 183/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1051 - accuracy: 0.5393 - val_loss: 0.9650 - val_accuracy: 0.5940\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9905 - accuracy: 0.5552 - val_loss: 0.9525 - val_accuracy: 0.5680\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9378 - accuracy: 0.5519 - val_loss: 1.1252 - val_accuracy: 0.5460\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9028 - accuracy: 0.5395 - val_loss: 0.9240 - val_accuracy: 0.5760\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8870 - accuracy: 0.5522 - val_loss: 0.7755 - val_accuracy: 0.6480\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7623 - accuracy: 0.6856 - val_loss: 0.7930 - val_accuracy: 0.6560\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8116 - accuracy: 0.6349 - val_loss: 1.3705 - val_accuracy: 0.5440\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8741 - accuracy: 0.6749 - val_loss: 0.7530 - val_accuracy: 0.5360\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9115 - accuracy: 0.5869 - val_loss: 0.9484 - val_accuracy: 0.5660\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8527 - accuracy: 0.5603 - val_loss: 0.9650 - val_accuracy: 0.5060\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9734 - accuracy: 0.5091 - val_loss: 0.7054 - val_accuracy: 0.7140\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9532 - accuracy: 0.5506 - val_loss: 0.8921 - val_accuracy: 0.6040\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8485 - accuracy: 0.6178 - val_loss: 0.9794 - val_accuracy: 0.5600\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8870 - accuracy: 0.5692 - val_loss: 0.7154 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8784 - accuracy: 0.6014 - val_loss: 0.8639 - val_accuracy: 0.6460\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8289 - accuracy: 0.6486 - val_loss: 0.9819 - val_accuracy: 0.5140\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8013 - accuracy: 0.6345 - val_loss: 1.2887 - val_accuracy: 0.4080\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9857 - accuracy: 0.5316 - val_loss: 0.7723 - val_accuracy: 0.6900\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.7300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7724 - accuracy: 0.6900\n",
      "Train: 0.730, Test: 0.690\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = create_dataset()\n",
    "history, train_acc, test_acc = evaluate_model(50, trainX, trainy, testX, testy, batch_size = 1)\n",
    "\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the performance of the model on the train and test datasets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that performance was similar between the train and test sets, around 50% accuracy, but was dramatically worse (about 30 percentage points) than using batch gradient descent. At least for this problem and the chosen model and model configuration, stochastic (online) gradient descent is not appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot of model loss and classification accuracy on the train (blue) and test (orange) dataset is created. The plot shows the unstable nature of the training process with the chosen configuration. The poor performance and erratic changes to the model suggest that the learning rate used to update weights after each training example may be too large and that a smaller learning rate may make the learning process more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this by re-running the model fit with stochastic gradient descent and a smaller learning rate. For example, we can drop the learning rate by order of magnitude from 0.01 to 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 3.0389 - accuracy: 0.4753 - val_loss: 0.8267 - val_accuracy: 0.7140\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.1592 - accuracy: 0.6064 - val_loss: 0.5616 - val_accuracy: 0.7480\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8071 - accuracy: 0.7044 - val_loss: 2.5876 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7581 - accuracy: 0.7146 - val_loss: 0.4728 - val_accuracy: 0.8240\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5211 - accuracy: 0.7878 - val_loss: 0.5372 - val_accuracy: 0.7460\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7834 - val_loss: 0.4633 - val_accuracy: 0.8260\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7919 - val_loss: 0.4480 - val_accuracy: 0.8160\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4564 - accuracy: 0.8102 - val_loss: 0.4429 - val_accuracy: 0.8300\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7731 - val_loss: 0.4330 - val_accuracy: 0.8380\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4853 - accuracy: 0.7881 - val_loss: 0.4918 - val_accuracy: 0.8200\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4352 - accuracy: 0.8136 - val_loss: 0.4536 - val_accuracy: 0.8100\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4964 - accuracy: 0.7693 - val_loss: 0.5494 - val_accuracy: 0.7720\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4973 - accuracy: 0.7815 - val_loss: 0.4905 - val_accuracy: 0.8320\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4690 - accuracy: 0.7978 - val_loss: 0.4525 - val_accuracy: 0.8020\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4259 - accuracy: 0.8222 - val_loss: 0.4073 - val_accuracy: 0.8300\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4624 - accuracy: 0.7994 - val_loss: 0.4456 - val_accuracy: 0.8220\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.8068 - val_loss: 0.4247 - val_accuracy: 0.8320\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4681 - accuracy: 0.8054 - val_loss: 0.4245 - val_accuracy: 0.8280\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4038 - accuracy: 0.8385 - val_loss: 0.4336 - val_accuracy: 0.8100\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4654 - accuracy: 0.8038 - val_loss: 0.5339 - val_accuracy: 0.7780\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4301 - accuracy: 0.8279 - val_loss: 0.4348 - val_accuracy: 0.8340\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4502 - accuracy: 0.7898 - val_loss: 0.4272 - val_accuracy: 0.8260\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4127 - accuracy: 0.8051 - val_loss: 0.4192 - val_accuracy: 0.8300\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4465 - accuracy: 0.7832 - val_loss: 0.4332 - val_accuracy: 0.8220\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.7949 - val_loss: 0.4200 - val_accuracy: 0.8280\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.8165 - val_loss: 0.4720 - val_accuracy: 0.7960\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8264 - val_loss: 0.4500 - val_accuracy: 0.8240\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4312 - accuracy: 0.7846 - val_loss: 0.4460 - val_accuracy: 0.8140\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3942 - accuracy: 0.8329 - val_loss: 0.4355 - val_accuracy: 0.8200\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4092 - accuracy: 0.8207 - val_loss: 0.4527 - val_accuracy: 0.8140\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3818 - accuracy: 0.8280 - val_loss: 0.4196 - val_accuracy: 0.8280\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4134 - accuracy: 0.8287 - val_loss: 0.4395 - val_accuracy: 0.8240\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4532 - accuracy: 0.7885 - val_loss: 0.4365 - val_accuracy: 0.8220\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8285 - val_loss: 0.4272 - val_accuracy: 0.8200\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.8208 - val_loss: 0.4048 - val_accuracy: 0.8240\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4444 - accuracy: 0.7884 - val_loss: 0.4425 - val_accuracy: 0.8160\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4499 - accuracy: 0.8099 - val_loss: 0.4292 - val_accuracy: 0.8280\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4257 - accuracy: 0.8217 - val_loss: 0.4314 - val_accuracy: 0.8180\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3889 - accuracy: 0.8398 - val_loss: 0.4580 - val_accuracy: 0.8160\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4312 - accuracy: 0.7791 - val_loss: 0.4314 - val_accuracy: 0.8280\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4161 - accuracy: 0.7965 - val_loss: 0.4241 - val_accuracy: 0.8180\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8267 - val_loss: 0.4110 - val_accuracy: 0.8340\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4106 - accuracy: 0.8033 - val_loss: 0.4602 - val_accuracy: 0.8240\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4483 - accuracy: 0.7921 - val_loss: 0.4329 - val_accuracy: 0.8340\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4212 - accuracy: 0.8231 - val_loss: 0.4128 - val_accuracy: 0.8260\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.8423 - val_loss: 0.4814 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4430 - accuracy: 0.8048 - val_loss: 0.4247 - val_accuracy: 0.8100\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3665 - accuracy: 0.8572 - val_loss: 0.4229 - val_accuracy: 0.8260\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3843 - accuracy: 0.8301 - val_loss: 0.4211 - val_accuracy: 0.8160\n",
      "Epoch 50/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8291 - val_loss: 0.4088 - val_accuracy: 0.8220\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4320 - accuracy: 0.8015 - val_loss: 0.4237 - val_accuracy: 0.8300\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4216 - accuracy: 0.8214 - val_loss: 0.4427 - val_accuracy: 0.8240\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3769 - accuracy: 0.8338 - val_loss: 0.4460 - val_accuracy: 0.8160\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8222 - val_loss: 0.4280 - val_accuracy: 0.8240\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3653 - accuracy: 0.8451 - val_loss: 0.4085 - val_accuracy: 0.8220\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8324 - val_loss: 0.4387 - val_accuracy: 0.8240\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3925 - accuracy: 0.8341 - val_loss: 0.4814 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4193 - accuracy: 0.8196 - val_loss: 0.4505 - val_accuracy: 0.8280\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4154 - accuracy: 0.8126 - val_loss: 0.4213 - val_accuracy: 0.8300\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8525 - val_loss: 0.4755 - val_accuracy: 0.8040\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8303 - val_loss: 0.4454 - val_accuracy: 0.8300\n",
      "Epoch 62/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4111 - accuracy: 0.8183 - val_loss: 0.4194 - val_accuracy: 0.8180\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4373 - accuracy: 0.8038 - val_loss: 0.4614 - val_accuracy: 0.8120\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4564 - accuracy: 0.7911 - val_loss: 0.4282 - val_accuracy: 0.8320\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8323 - val_loss: 0.4256 - val_accuracy: 0.8280\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.7886 - val_loss: 0.4459 - val_accuracy: 0.8100\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8450 - val_loss: 0.4190 - val_accuracy: 0.8360\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8410 - val_loss: 0.4475 - val_accuracy: 0.8100\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3854 - accuracy: 0.8374 - val_loss: 0.4386 - val_accuracy: 0.8220\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3679 - accuracy: 0.8317 - val_loss: 0.4451 - val_accuracy: 0.8260\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4237 - accuracy: 0.8191 - val_loss: 0.4363 - val_accuracy: 0.8440\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.8090 - val_loss: 0.4332 - val_accuracy: 0.8280\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4224 - accuracy: 0.8312 - val_loss: 0.4152 - val_accuracy: 0.8280\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4148 - accuracy: 0.8182 - val_loss: 0.4239 - val_accuracy: 0.8280\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8347 - val_loss: 0.4653 - val_accuracy: 0.8240\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.7876 - val_loss: 0.4667 - val_accuracy: 0.8120\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3668 - accuracy: 0.8497 - val_loss: 0.4566 - val_accuracy: 0.8040\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4543 - accuracy: 0.7747 - val_loss: 0.4516 - val_accuracy: 0.8260\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3810 - accuracy: 0.8237 - val_loss: 0.4509 - val_accuracy: 0.8180\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4153 - accuracy: 0.7990 - val_loss: 0.4415 - val_accuracy: 0.8120\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8373 - val_loss: 0.4331 - val_accuracy: 0.8320\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3959 - accuracy: 0.8253 - val_loss: 0.4365 - val_accuracy: 0.8340\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.8021 - val_loss: 0.4345 - val_accuracy: 0.8300\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.4332 - val_accuracy: 0.8180\n",
      "Epoch 85/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4163 - accuracy: 0.8280 - val_loss: 0.4338 - val_accuracy: 0.8180\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8094 - val_loss: 0.4298 - val_accuracy: 0.8140\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.4628 - val_accuracy: 0.8140\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8265 - val_loss: 0.4591 - val_accuracy: 0.8160\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8440 - val_loss: 0.4598 - val_accuracy: 0.8200\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3891 - accuracy: 0.8181 - val_loss: 0.4359 - val_accuracy: 0.8220\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3954 - accuracy: 0.8254 - val_loss: 0.4435 - val_accuracy: 0.8260\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4172 - accuracy: 0.8204 - val_loss: 0.4409 - val_accuracy: 0.8120\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8141 - val_loss: 0.4890 - val_accuracy: 0.8020\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.4619 - val_accuracy: 0.8180\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4336 - accuracy: 0.7899 - val_loss: 0.4294 - val_accuracy: 0.8280\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8394 - val_loss: 0.4600 - val_accuracy: 0.8140\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4522 - accuracy: 0.8030 - val_loss: 0.4346 - val_accuracy: 0.8180\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4088 - accuracy: 0.8246 - val_loss: 0.4542 - val_accuracy: 0.8260\n",
      "Epoch 99/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3480 - accuracy: 0.8522 - val_loss: 0.4295 - val_accuracy: 0.8300\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3684 - accuracy: 0.8359 - val_loss: 0.4237 - val_accuracy: 0.8180\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4000 - accuracy: 0.8022 - val_loss: 0.4363 - val_accuracy: 0.8160\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4438 - accuracy: 0.8070 - val_loss: 0.4437 - val_accuracy: 0.8260\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3832 - accuracy: 0.8334 - val_loss: 0.4387 - val_accuracy: 0.8300\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4244 - accuracy: 0.8272 - val_loss: 0.4558 - val_accuracy: 0.8180\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8453 - val_loss: 0.4293 - val_accuracy: 0.8300\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.7999 - val_loss: 0.4344 - val_accuracy: 0.8220\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4109 - accuracy: 0.8220 - val_loss: 0.4595 - val_accuracy: 0.8220\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8203 - val_loss: 0.4448 - val_accuracy: 0.8240\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4060 - accuracy: 0.8386 - val_loss: 0.4468 - val_accuracy: 0.8260\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4193 - accuracy: 0.8111 - val_loss: 0.4354 - val_accuracy: 0.8240\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4351 - accuracy: 0.8280 - val_loss: 0.4448 - val_accuracy: 0.8300\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4329 - accuracy: 0.8125 - val_loss: 0.4583 - val_accuracy: 0.8060\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4082 - accuracy: 0.8213 - val_loss: 0.4379 - val_accuracy: 0.8220\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8341 - val_loss: 0.4499 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3724 - accuracy: 0.8406 - val_loss: 0.4647 - val_accuracy: 0.8060\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3927 - accuracy: 0.8402 - val_loss: 0.4388 - val_accuracy: 0.8260\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8431 - val_loss: 0.4530 - val_accuracy: 0.8140\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4454 - accuracy: 0.8096 - val_loss: 0.4575 - val_accuracy: 0.8100\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3905 - accuracy: 0.8278 - val_loss: 0.4333 - val_accuracy: 0.8300\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4126 - accuracy: 0.7977 - val_loss: 0.4403 - val_accuracy: 0.8260\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3895 - accuracy: 0.8400 - val_loss: 0.4436 - val_accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3538 - accuracy: 0.8319 - val_loss: 0.4662 - val_accuracy: 0.8020\n",
      "Epoch 123/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4318 - accuracy: 0.7983 - val_loss: 0.4461 - val_accuracy: 0.8260\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3996 - accuracy: 0.8167 - val_loss: 0.4794 - val_accuracy: 0.8240\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4269 - accuracy: 0.8142 - val_loss: 0.4404 - val_accuracy: 0.8220\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3371 - accuracy: 0.8660 - val_loss: 0.4436 - val_accuracy: 0.8120\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3614 - accuracy: 0.8360 - val_loss: 0.4526 - val_accuracy: 0.8220\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3701 - accuracy: 0.8127 - val_loss: 0.4590 - val_accuracy: 0.8140\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3724 - accuracy: 0.8250 - val_loss: 0.4730 - val_accuracy: 0.8120\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8218 - val_loss: 0.4470 - val_accuracy: 0.8260\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3703 - accuracy: 0.8455 - val_loss: 0.4287 - val_accuracy: 0.8260\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4109 - accuracy: 0.7947 - val_loss: 0.5091 - val_accuracy: 0.7880\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8438 - val_loss: 0.4584 - val_accuracy: 0.8220\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8197 - val_loss: 0.4307 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3723 - accuracy: 0.8401 - val_loss: 0.4816 - val_accuracy: 0.7980\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3628 - accuracy: 0.8397 - val_loss: 0.4366 - val_accuracy: 0.8260\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4219 - accuracy: 0.8228 - val_loss: 0.4558 - val_accuracy: 0.8360\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3732 - accuracy: 0.8398 - val_loss: 0.4766 - val_accuracy: 0.8140\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3872 - accuracy: 0.8253 - val_loss: 0.4687 - val_accuracy: 0.8260\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3796 - accuracy: 0.8423 - val_loss: 0.4599 - val_accuracy: 0.8060\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8339 - val_loss: 0.4468 - val_accuracy: 0.8160\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3658 - accuracy: 0.8278 - val_loss: 0.4317 - val_accuracy: 0.8180\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8487 - val_loss: 0.4816 - val_accuracy: 0.8180\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4463 - val_accuracy: 0.8260\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3908 - accuracy: 0.8149 - val_loss: 0.4998 - val_accuracy: 0.7840\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4436 - accuracy: 0.7938 - val_loss: 0.4428 - val_accuracy: 0.8300\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4318 - accuracy: 0.8219 - val_loss: 0.4664 - val_accuracy: 0.8200\n",
      "Epoch 148/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3973 - accuracy: 0.8161 - val_loss: 0.4404 - val_accuracy: 0.8140\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4168 - accuracy: 0.8066 - val_loss: 0.4649 - val_accuracy: 0.8200\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8321 - val_loss: 0.4604 - val_accuracy: 0.8240\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3343 - accuracy: 0.8345 - val_loss: 0.4806 - val_accuracy: 0.7980\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3973 - accuracy: 0.8225 - val_loss: 0.4301 - val_accuracy: 0.8240\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4264 - accuracy: 0.8347 - val_loss: 0.5024 - val_accuracy: 0.7960\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3469 - accuracy: 0.8614 - val_loss: 0.4501 - val_accuracy: 0.8160\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8104 - val_loss: 0.4629 - val_accuracy: 0.8220\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4064 - accuracy: 0.8152 - val_loss: 0.5246 - val_accuracy: 0.7940\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.8163 - val_loss: 0.4779 - val_accuracy: 0.8160\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4178 - accuracy: 0.8235 - val_loss: 0.4667 - val_accuracy: 0.8260\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4227 - accuracy: 0.7749 - val_loss: 0.4811 - val_accuracy: 0.8080\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4028 - accuracy: 0.8132 - val_loss: 0.4333 - val_accuracy: 0.8260\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.7999 - val_loss: 0.4642 - val_accuracy: 0.8300\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3765 - accuracy: 0.8283 - val_loss: 0.4366 - val_accuracy: 0.8180\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3730 - accuracy: 0.8243 - val_loss: 0.4469 - val_accuracy: 0.8240\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4172 - accuracy: 0.8322 - val_loss: 0.4509 - val_accuracy: 0.8300\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4069 - accuracy: 0.8084 - val_loss: 0.4746 - val_accuracy: 0.8320\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3962 - accuracy: 0.8266 - val_loss: 0.4645 - val_accuracy: 0.8280\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4258 - accuracy: 0.8073 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3869 - accuracy: 0.8219 - val_loss: 0.4709 - val_accuracy: 0.8220\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.8570 - val_loss: 0.4535 - val_accuracy: 0.8200\n",
      "Epoch 170/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.8456 - val_loss: 0.4796 - val_accuracy: 0.8180\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4077 - accuracy: 0.8207 - val_loss: 0.4710 - val_accuracy: 0.8180\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3439 - accuracy: 0.8399 - val_loss: 0.4492 - val_accuracy: 0.8240\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8678 - val_loss: 0.4469 - val_accuracy: 0.8160\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8245 - val_loss: 0.4539 - val_accuracy: 0.8260\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3832 - accuracy: 0.8433 - val_loss: 0.4667 - val_accuracy: 0.8180\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8435 - val_loss: 0.4518 - val_accuracy: 0.8220\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3603 - accuracy: 0.8269 - val_loss: 0.4364 - val_accuracy: 0.8260\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3788 - accuracy: 0.8403 - val_loss: 0.4666 - val_accuracy: 0.8200\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4187 - accuracy: 0.8172 - val_loss: 0.4707 - val_accuracy: 0.8200\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3700 - accuracy: 0.8488 - val_loss: 0.4697 - val_accuracy: 0.8280\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3730 - accuracy: 0.8248 - val_loss: 0.4693 - val_accuracy: 0.8040\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3736 - accuracy: 0.8192 - val_loss: 0.4584 - val_accuracy: 0.8220\n",
      "Epoch 183/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3956 - accuracy: 0.8384 - val_loss: 0.4745 - val_accuracy: 0.8160\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4203 - accuracy: 0.7710 - val_loss: 0.4868 - val_accuracy: 0.8220\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3892 - accuracy: 0.8089 - val_loss: 0.4436 - val_accuracy: 0.8280\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3586 - accuracy: 0.8208 - val_loss: 0.4603 - val_accuracy: 0.8160\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3721 - accuracy: 0.8609 - val_loss: 0.4440 - val_accuracy: 0.8060\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3562 - accuracy: 0.8403 - val_loss: 0.4563 - val_accuracy: 0.8240\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3931 - accuracy: 0.8186 - val_loss: 0.4439 - val_accuracy: 0.8280\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4048 - accuracy: 0.8060 - val_loss: 0.4855 - val_accuracy: 0.8060\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3588 - accuracy: 0.8126 - val_loss: 0.4550 - val_accuracy: 0.8300\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3642 - accuracy: 0.8601 - val_loss: 0.4920 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3468 - accuracy: 0.8482 - val_loss: 0.4906 - val_accuracy: 0.8160\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.7923 - val_loss: 0.4629 - val_accuracy: 0.8240\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4079 - accuracy: 0.8339 - val_loss: 0.4634 - val_accuracy: 0.8200\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4634 - accuracy: 0.7704 - val_loss: 0.4795 - val_accuracy: 0.8200\n",
      "Epoch 197/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8197 - val_loss: 0.4593 - val_accuracy: 0.8220\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4140 - accuracy: 0.8214 - val_loss: 0.5083 - val_accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4369 - accuracy: 0.8232 - val_loss: 0.4777 - val_accuracy: 0.7920\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.8009 - val_loss: 0.4666 - val_accuracy: 0.8240\n",
      "16/16 [==============================] - 0s 994us/step - loss: 0.3720 - accuracy: 0.8360\n",
      "16/16 [==============================] - 0s 992us/step - loss: 0.4666 - accuracy: 0.8240\n",
      "Train: 0.836, Test: 0.824\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = create_dataset()\n",
    "history, train_acc, test_acc = evaluate_model(50, trainX, trainy, testX, testy, batch_size = 1, learning_rate=0.001)\n",
    "\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example tells a very different story.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "The reported performance is greatly improved, achieving classification accuracy on the train and test sets on par with fit using batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line plot shows the expected behavior. Namely, the model rapidly learns the problem compared to batch gradient descent, leaping up to about 80% accuracy in about 25 epochs rather than the 100 epochs seen when using batch gradient descent. We could have stopped training at epoch 50 instead of epoch 200 due to the faster training. This is not surprising. With batch gradient descent, 100 epochs involved 100 estimates of error and 100 weight updates. In stochastic gradient descent, 25 epochs involved (500 x 25) or 12,500 weight updates, providing more than 10-times more feedback, albeit more noisy feedback, about how to improve the model.\n",
    "\n",
    "The line plot also shows that train and test performance remain comparable during training, compared to the dynamics with batch gradient descent, where the performance on the test set was slightly better and remained so throughout training. Unlike batch gradient descent, we can see that the noisy updates result in noisy performance throughout the duration of training. This variance in the model means that it may be challenging to choose which model to use as the final model instead of batch gradient descent, where performance is stabilized because the model has converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example highlights the important relationship between batch size and the learning rate. Namely, more noisy updates to the model require a smaller learning rate, whereas less noisy, more accurate estimates of the error gradient may be applied to the model more liberally. We can summarize this as follows:\n",
    "* **Batch Gradient Descent**: Use a relatively larger learning rate and more training epochs.\n",
    "* **Stochastic Gradient Descent**: Use a relatively smaller learning rate and fewer training epochs.\n",
    "\n",
    "Mini-batch gradient descent provides an alternative approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Fit With Minibatch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to using stochastic gradient descent and tuning the learning rate is to hold the learning rate constant and to change the batch size. In effect, we specify the rate of learning or amount of change to apply to the weights each time we estimate the error gradient and vary the gradient-based accuracy on the number of samples used to estimate it. Holding the learning rate at 0.01 as we did with batch gradient descent, we can set the batch size to 32, a widely adopted default batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 3.6356 - accuracy: 0.4304 - val_loss: 1.4490 - val_accuracy: 0.7020\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9666 - accuracy: 0.6078 - val_loss: 1.2587 - val_accuracy: 0.6060\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.7057 - accuracy: 0.5562 - val_loss: 2.5045 - val_accuracy: 0.4380\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9946 - accuracy: 0.5661 - val_loss: 1.1981 - val_accuracy: 0.6940\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1936 - accuracy: 0.6396 - val_loss: 0.9816 - val_accuracy: 0.6500\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0592 - accuracy: 0.6115 - val_loss: 1.1111 - val_accuracy: 0.6880\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7817 - accuracy: 0.7204 - val_loss: 0.5203 - val_accuracy: 0.7980\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7261 - val_loss: 0.5775 - val_accuracy: 0.7620\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7251 - val_loss: 0.4736 - val_accuracy: 0.8100\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.8031 - val_loss: 0.4958 - val_accuracy: 0.8220\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7833 - val_loss: 0.4697 - val_accuracy: 0.8200\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7784 - val_loss: 0.4679 - val_accuracy: 0.8200\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4720 - accuracy: 0.7749 - val_loss: 0.4948 - val_accuracy: 0.7820\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7733 - val_loss: 0.5493 - val_accuracy: 0.7840\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.8083 - val_loss: 0.5094 - val_accuracy: 0.7840\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7489 - val_loss: 0.4457 - val_accuracy: 0.8280\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7911 - val_loss: 0.4335 - val_accuracy: 0.8120\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7879 - val_loss: 0.4505 - val_accuracy: 0.8260\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8216 - val_loss: 0.4514 - val_accuracy: 0.8060\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7628 - val_loss: 0.4252 - val_accuracy: 0.8240\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8225 - val_loss: 0.4232 - val_accuracy: 0.8280\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7944 - val_loss: 0.4307 - val_accuracy: 0.8240\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8212 - val_loss: 0.4525 - val_accuracy: 0.8120\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7868 - val_loss: 0.4982 - val_accuracy: 0.7920\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7733 - val_loss: 0.4209 - val_accuracy: 0.8400\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7981 - val_loss: 0.4279 - val_accuracy: 0.8200\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8257 - val_loss: 0.4352 - val_accuracy: 0.8240\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8015 - val_loss: 0.4124 - val_accuracy: 0.8280\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8339 - val_loss: 0.4078 - val_accuracy: 0.8300\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8113 - val_loss: 0.4340 - val_accuracy: 0.8240\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8385 - val_loss: 0.4234 - val_accuracy: 0.8240\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8455 - val_loss: 0.4098 - val_accuracy: 0.8320\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8157 - val_loss: 0.4145 - val_accuracy: 0.8260\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8342 - val_loss: 0.4674 - val_accuracy: 0.8240\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.8320 - val_loss: 0.4404 - val_accuracy: 0.8220\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7946 - val_loss: 0.4084 - val_accuracy: 0.8360\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8116 - val_loss: 0.4291 - val_accuracy: 0.8300\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8148 - val_loss: 0.4229 - val_accuracy: 0.8200\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8172 - val_loss: 0.5339 - val_accuracy: 0.7720\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7968 - val_loss: 0.4251 - val_accuracy: 0.8260\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8044 - val_loss: 0.4086 - val_accuracy: 0.8320\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8169 - val_loss: 0.4384 - val_accuracy: 0.8240\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8290 - val_loss: 0.4431 - val_accuracy: 0.8180\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8084 - val_loss: 0.4628 - val_accuracy: 0.8200\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8193 - val_loss: 0.4570 - val_accuracy: 0.8140\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8228 - val_loss: 0.4354 - val_accuracy: 0.8240\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8159 - val_loss: 0.4045 - val_accuracy: 0.8240\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8447 - val_loss: 0.4146 - val_accuracy: 0.8340\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8293 - val_loss: 0.4034 - val_accuracy: 0.8340\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8290 - val_loss: 0.4039 - val_accuracy: 0.8380\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8099 - val_loss: 0.4143 - val_accuracy: 0.8200\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8324 - val_loss: 0.4128 - val_accuracy: 0.8240\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8468 - val_loss: 0.4891 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8119 - val_loss: 0.4512 - val_accuracy: 0.8060\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8379 - val_loss: 0.4038 - val_accuracy: 0.8180\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8497 - val_loss: 0.4300 - val_accuracy: 0.8340\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8430 - val_loss: 0.4079 - val_accuracy: 0.8280\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8301 - val_loss: 0.4223 - val_accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8027 - val_loss: 0.4078 - val_accuracy: 0.8300\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8440 - val_loss: 0.4229 - val_accuracy: 0.8300\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8361 - val_loss: 0.4284 - val_accuracy: 0.8220\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7899 - val_loss: 0.4230 - val_accuracy: 0.8380\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.7948 - val_loss: 0.4247 - val_accuracy: 0.8220\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7738 - val_loss: 0.4062 - val_accuracy: 0.8260\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8451 - val_loss: 0.4163 - val_accuracy: 0.8340\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8272 - val_loss: 0.4213 - val_accuracy: 0.8280\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8279 - val_loss: 0.4069 - val_accuracy: 0.8260\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8290 - val_loss: 0.4084 - val_accuracy: 0.8320\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8233 - val_loss: 0.4292 - val_accuracy: 0.8280\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8282 - val_loss: 0.4001 - val_accuracy: 0.8340\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8345 - val_loss: 0.4199 - val_accuracy: 0.8260\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8142 - val_loss: 0.4072 - val_accuracy: 0.8380\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8312 - val_loss: 0.4475 - val_accuracy: 0.8220\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8278 - val_loss: 0.4022 - val_accuracy: 0.8260\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8366 - val_loss: 0.4296 - val_accuracy: 0.8240\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7831 - val_loss: 0.4436 - val_accuracy: 0.8080\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8422 - val_loss: 0.4093 - val_accuracy: 0.8280\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7922 - val_loss: 0.4160 - val_accuracy: 0.8260\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8360 - val_loss: 0.4074 - val_accuracy: 0.8280\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8424 - val_loss: 0.4128 - val_accuracy: 0.8320\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8228 - val_loss: 0.4454 - val_accuracy: 0.8040\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8365 - val_loss: 0.4155 - val_accuracy: 0.8300\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7942 - val_loss: 0.4048 - val_accuracy: 0.8360\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8171 - val_loss: 0.4246 - val_accuracy: 0.8240\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8205 - val_loss: 0.4289 - val_accuracy: 0.8240\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8213 - val_loss: 0.4598 - val_accuracy: 0.8120\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8318 - val_loss: 0.4226 - val_accuracy: 0.8280\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8337 - val_loss: 0.4257 - val_accuracy: 0.8160\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8393 - val_loss: 0.4146 - val_accuracy: 0.8260\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8348 - val_loss: 0.4049 - val_accuracy: 0.8160\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.8209 - val_loss: 0.4172 - val_accuracy: 0.8280\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8113 - val_loss: 0.4078 - val_accuracy: 0.8280\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8158 - val_loss: 0.4315 - val_accuracy: 0.8280\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8199 - val_loss: 0.4621 - val_accuracy: 0.7980\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7975 - val_loss: 0.4190 - val_accuracy: 0.8280\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8365 - val_loss: 0.4447 - val_accuracy: 0.8300\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8048 - val_loss: 0.4513 - val_accuracy: 0.8160\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8099 - val_loss: 0.4254 - val_accuracy: 0.8220\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8510 - val_loss: 0.4317 - val_accuracy: 0.8160\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8258 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8297 - val_loss: 0.4104 - val_accuracy: 0.8180\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8180 - val_loss: 0.4189 - val_accuracy: 0.8280\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8358 - val_loss: 0.4058 - val_accuracy: 0.8260\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8054 - val_loss: 0.4046 - val_accuracy: 0.8300\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3925 - accuracy: 0.8138 - val_loss: 0.4127 - val_accuracy: 0.8300\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7873 - val_loss: 0.4612 - val_accuracy: 0.8120\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8311 - val_loss: 0.4402 - val_accuracy: 0.8260\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8184 - val_loss: 0.4104 - val_accuracy: 0.8320\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8363 - val_loss: 0.4295 - val_accuracy: 0.8260\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8051 - val_loss: 0.4148 - val_accuracy: 0.8220\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8180 - val_loss: 0.4193 - val_accuracy: 0.8260\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8141 - val_loss: 0.4217 - val_accuracy: 0.8280\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.8353 - val_loss: 0.4534 - val_accuracy: 0.8220\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8290 - val_loss: 0.4105 - val_accuracy: 0.8220\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8316 - val_loss: 0.4121 - val_accuracy: 0.8360\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8330 - val_loss: 0.4055 - val_accuracy: 0.8200\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8474 - val_loss: 0.4038 - val_accuracy: 0.8300\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8132 - val_loss: 0.4148 - val_accuracy: 0.8180\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8280 - val_loss: 0.4167 - val_accuracy: 0.8260\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8292 - val_loss: 0.4276 - val_accuracy: 0.8200\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8332 - val_loss: 0.4109 - val_accuracy: 0.8240\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8367 - val_loss: 0.4296 - val_accuracy: 0.8220\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8029 - val_loss: 0.4207 - val_accuracy: 0.8220\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8255 - val_loss: 0.4111 - val_accuracy: 0.8240\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8321 - val_loss: 0.4147 - val_accuracy: 0.8240\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8547 - val_loss: 0.4556 - val_accuracy: 0.8080\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8186 - val_loss: 0.3983 - val_accuracy: 0.8320\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8239 - val_loss: 0.4134 - val_accuracy: 0.8220\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8186 - val_loss: 0.4272 - val_accuracy: 0.8300\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8301 - val_loss: 0.4106 - val_accuracy: 0.8140\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8436 - val_loss: 0.4122 - val_accuracy: 0.8280\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8155 - val_loss: 0.4047 - val_accuracy: 0.8360\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8317 - val_loss: 0.4160 - val_accuracy: 0.8180\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8417 - val_loss: 0.4107 - val_accuracy: 0.8220\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8499 - val_loss: 0.4343 - val_accuracy: 0.8220\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8438 - val_loss: 0.4158 - val_accuracy: 0.8200\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8381 - val_loss: 0.4091 - val_accuracy: 0.8300\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8328 - val_loss: 0.4484 - val_accuracy: 0.8200\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8456 - val_loss: 0.4109 - val_accuracy: 0.8260\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3556 - accuracy: 0.8308 - val_loss: 0.4207 - val_accuracy: 0.8240\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8254 - val_loss: 0.4323 - val_accuracy: 0.8260\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8462 - val_loss: 0.4381 - val_accuracy: 0.8180\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8578 - val_loss: 0.4603 - val_accuracy: 0.8060\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8097 - val_loss: 0.4433 - val_accuracy: 0.8200\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8097 - val_loss: 0.4169 - val_accuracy: 0.8200\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8228 - val_loss: 0.4171 - val_accuracy: 0.8320\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8214 - val_loss: 0.4156 - val_accuracy: 0.8220\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8294 - val_loss: 0.4322 - val_accuracy: 0.8160\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8197 - val_loss: 0.4192 - val_accuracy: 0.8220\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8435 - val_loss: 0.4114 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8537 - val_loss: 0.4351 - val_accuracy: 0.8080\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8194 - val_loss: 0.4411 - val_accuracy: 0.8200\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8280 - val_loss: 0.4604 - val_accuracy: 0.8080\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8462 - val_loss: 0.4141 - val_accuracy: 0.8260\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8290 - val_loss: 0.4096 - val_accuracy: 0.8220\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8059 - val_loss: 0.4411 - val_accuracy: 0.8220\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8271 - val_loss: 0.4383 - val_accuracy: 0.8220\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8412 - val_loss: 0.4072 - val_accuracy: 0.8300\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8125 - val_loss: 0.4313 - val_accuracy: 0.8220\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8286 - val_loss: 0.4315 - val_accuracy: 0.8180\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8157 - val_loss: 0.4225 - val_accuracy: 0.8280\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8488 - val_loss: 0.4191 - val_accuracy: 0.8240\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8207 - val_loss: 0.4175 - val_accuracy: 0.8300\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8358 - val_loss: 0.4189 - val_accuracy: 0.8240\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8036 - val_loss: 0.4232 - val_accuracy: 0.8300\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8277 - val_loss: 0.4393 - val_accuracy: 0.8180\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8017 - val_loss: 0.4714 - val_accuracy: 0.8120\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8300 - val_loss: 0.4149 - val_accuracy: 0.8220\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8426 - val_loss: 0.4205 - val_accuracy: 0.8300\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8549 - val_loss: 0.4342 - val_accuracy: 0.8200\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8112 - val_loss: 0.4134 - val_accuracy: 0.8280\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8483 - val_loss: 0.4208 - val_accuracy: 0.8180\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8799 - val_loss: 0.4199 - val_accuracy: 0.8180\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8385 - val_loss: 0.4118 - val_accuracy: 0.8180\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8343 - val_loss: 0.4363 - val_accuracy: 0.8220\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8563 - val_loss: 0.4132 - val_accuracy: 0.8140\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8326 - val_loss: 0.4257 - val_accuracy: 0.8240\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3677 - accuracy: 0.8436 - val_loss: 0.4243 - val_accuracy: 0.8180\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8136 - val_loss: 0.4235 - val_accuracy: 0.8160\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3703 - accuracy: 0.8464 - val_loss: 0.4313 - val_accuracy: 0.8160\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3686 - accuracy: 0.8607 - val_loss: 0.4186 - val_accuracy: 0.8240\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8357 - val_loss: 0.4282 - val_accuracy: 0.8280\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8298 - val_loss: 0.4588 - val_accuracy: 0.8240\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8029 - val_loss: 0.4505 - val_accuracy: 0.8100\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8255 - val_loss: 0.4564 - val_accuracy: 0.8100\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8308 - val_loss: 0.4212 - val_accuracy: 0.8260\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8545 - val_loss: 0.4178 - val_accuracy: 0.8160\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.8387 - val_loss: 0.4195 - val_accuracy: 0.8280\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3668 - accuracy: 0.8439 - val_loss: 0.4229 - val_accuracy: 0.8200\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8193 - val_loss: 0.4377 - val_accuracy: 0.8220\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8312 - val_loss: 0.4217 - val_accuracy: 0.8160\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8528 - val_loss: 0.4181 - val_accuracy: 0.8220\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8553 - val_loss: 0.4118 - val_accuracy: 0.8180\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8143 - val_loss: 0.4130 - val_accuracy: 0.8180\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8251 - val_loss: 0.4159 - val_accuracy: 0.8260\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7946 - val_loss: 0.4262 - val_accuracy: 0.8240\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8052 - val_loss: 0.4147 - val_accuracy: 0.8200\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8223 - val_loss: 0.4487 - val_accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8155 - val_loss: 0.4295 - val_accuracy: 0.8260\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8022 - val_loss: 0.4193 - val_accuracy: 0.8300\n",
      "16/16 [==============================] - 0s 864us/step - loss: 0.3894 - accuracy: 0.8060\n",
      "16/16 [==============================] - 0s 818us/step - loss: 0.4193 - accuracy: 0.8300\n",
      "Train: 0.806, Test: 0.830\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = create_dataset()\n",
    "history, train_acc, test_acc = evaluate_model(50, trainX, trainy, testX, testy, batch_size = 32, learning_rate=0.01)\n",
    "\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect to get some of the benefits of stochastic gradient descent with a larger learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports similar performance on both train and test sets, comparable with batch gradient descent and stochastic gradient descent after reducing the learning rate.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line plot shows the dynamics of both stochastic and batch gradient descent. Specifically, the model learns fast and has noisy updates and stabilizes more towards the end of the run, more so than stochastic gradient descent. Holding learning rate constant and varying the batch size allows you to dial in the best of both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effects of Batch Size on Model Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refit the model with different batch sizes and review the impact the change in batch size has on learning speed, stability during learning, and the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function to fit a model on the problem with a given batch size and plot the learning curves of classification accuracy on the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model and plot learning curve\n",
    "def fit_model(trainX, trainy, testX, testy, n_batch):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=200, verbose=1, batch_size=n_batch)\n",
    "    \n",
    "    # plot learning curves\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.title('batch='+str(n_batch), pad=-40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model behavior with a suite of different batch sizes while holding everything else about the model constant, including the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.5933 - accuracy: 0.4997 - val_loss: 0.7338 - val_accuracy: 0.7420\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7021 - val_loss: 0.4847 - val_accuracy: 0.8180\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7844 - val_loss: 0.5089 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7754 - val_loss: 0.4886 - val_accuracy: 0.8080\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.8093 - val_loss: 0.4787 - val_accuracy: 0.8120\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7821 - val_loss: 0.5706 - val_accuracy: 0.7580\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7782 - val_loss: 0.4551 - val_accuracy: 0.8200\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8299 - val_loss: 0.4755 - val_accuracy: 0.8200\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7784 - val_loss: 0.4728 - val_accuracy: 0.8360\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7891 - val_loss: 0.5073 - val_accuracy: 0.8300\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8134 - val_loss: 0.4080 - val_accuracy: 0.8320\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7811 - val_loss: 0.6652 - val_accuracy: 0.7680\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.7664 - val_loss: 0.4261 - val_accuracy: 0.8400\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7822 - val_loss: 0.5517 - val_accuracy: 0.7640\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8248 - val_loss: 0.4104 - val_accuracy: 0.8360\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8128 - val_loss: 0.4310 - val_accuracy: 0.8180\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8056 - val_loss: 0.4427 - val_accuracy: 0.8280\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8327 - val_loss: 0.4502 - val_accuracy: 0.8040\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8242 - val_loss: 0.4540 - val_accuracy: 0.8200\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7980 - val_loss: 0.4963 - val_accuracy: 0.8240\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7730 - val_loss: 0.4255 - val_accuracy: 0.8340\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7947 - val_loss: 0.4511 - val_accuracy: 0.8220\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7940 - val_loss: 0.4431 - val_accuracy: 0.8300\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7977 - val_loss: 0.4714 - val_accuracy: 0.8140\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7879 - val_loss: 0.4483 - val_accuracy: 0.8300\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8080 - val_loss: 0.4541 - val_accuracy: 0.8280\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7992 - val_loss: 0.5149 - val_accuracy: 0.8140\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7667 - val_loss: 0.4805 - val_accuracy: 0.8200\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8145 - val_loss: 0.4136 - val_accuracy: 0.8280\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8133 - val_loss: 0.4825 - val_accuracy: 0.7860\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8173 - val_loss: 0.4314 - val_accuracy: 0.8420\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8037 - val_loss: 0.5457 - val_accuracy: 0.7980\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7752 - val_loss: 0.4994 - val_accuracy: 0.7860\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7949 - val_loss: 0.4268 - val_accuracy: 0.8340\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7997 - val_loss: 0.4353 - val_accuracy: 0.8320\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8218 - val_loss: 0.4522 - val_accuracy: 0.7980\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4639 - val_accuracy: 0.8240\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8094 - val_loss: 0.4523 - val_accuracy: 0.8240\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8347 - val_loss: 0.4833 - val_accuracy: 0.8180\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7834 - val_loss: 0.4732 - val_accuracy: 0.8140\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7843 - val_loss: 0.4468 - val_accuracy: 0.8280\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8503 - val_loss: 0.4408 - val_accuracy: 0.8400\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7680 - val_loss: 0.4762 - val_accuracy: 0.8340\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7787 - val_loss: 0.4397 - val_accuracy: 0.8380\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8108 - val_loss: 0.4258 - val_accuracy: 0.8360\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8427 - val_loss: 0.5718 - val_accuracy: 0.7420\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7746 - val_loss: 0.4177 - val_accuracy: 0.8160\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7902 - val_loss: 0.4439 - val_accuracy: 0.8320\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8390 - val_loss: 0.4369 - val_accuracy: 0.8300\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8295 - val_loss: 0.4358 - val_accuracy: 0.8040\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7763 - val_loss: 0.4360 - val_accuracy: 0.8340\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7993 - val_loss: 0.4493 - val_accuracy: 0.8360\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8475 - val_loss: 0.4524 - val_accuracy: 0.8360\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7974 - val_loss: 0.4532 - val_accuracy: 0.8300\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8463 - val_loss: 0.4238 - val_accuracy: 0.8320\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8334 - val_loss: 0.4992 - val_accuracy: 0.8020\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8396 - val_loss: 0.4998 - val_accuracy: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8151 - val_loss: 0.4422 - val_accuracy: 0.8360\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8004 - val_loss: 0.4589 - val_accuracy: 0.8260\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8306 - val_loss: 0.5912 - val_accuracy: 0.7400\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7821 - val_loss: 0.4720 - val_accuracy: 0.8300\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8246 - val_loss: 0.4764 - val_accuracy: 0.8260\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8193 - val_loss: 0.4975 - val_accuracy: 0.8100\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7760 - val_loss: 0.4576 - val_accuracy: 0.8400\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8230 - val_loss: 0.4341 - val_accuracy: 0.8400\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7882 - val_loss: 0.4542 - val_accuracy: 0.8060\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8502 - val_loss: 0.4337 - val_accuracy: 0.8360\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8364 - val_loss: 0.4572 - val_accuracy: 0.8040\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7981 - val_loss: 0.4607 - val_accuracy: 0.8240\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8324 - val_loss: 0.5327 - val_accuracy: 0.8240\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8107 - val_loss: 0.4550 - val_accuracy: 0.8400\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7967 - val_loss: 0.5601 - val_accuracy: 0.7560\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7880 - val_loss: 0.4399 - val_accuracy: 0.8360\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8019 - val_loss: 0.4370 - val_accuracy: 0.8360\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8071 - val_loss: 0.5510 - val_accuracy: 0.7940\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7848 - val_loss: 0.5312 - val_accuracy: 0.7800\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8480 - val_loss: 0.4693 - val_accuracy: 0.8180\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7554 - val_loss: 0.4701 - val_accuracy: 0.8240\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8143 - val_loss: 0.5004 - val_accuracy: 0.8100\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7925 - val_loss: 0.4882 - val_accuracy: 0.7880\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8213 - val_loss: 0.4714 - val_accuracy: 0.8280\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8033 - val_loss: 0.4384 - val_accuracy: 0.8280\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7860 - val_loss: 0.4653 - val_accuracy: 0.8380\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8004 - val_loss: 0.4758 - val_accuracy: 0.8320\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7902 - val_loss: 0.4552 - val_accuracy: 0.8340\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7919 - val_loss: 0.4505 - val_accuracy: 0.8060\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7857 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8126 - val_loss: 0.4951 - val_accuracy: 0.8120\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8485 - val_loss: 0.5063 - val_accuracy: 0.8220\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8110 - val_loss: 0.4794 - val_accuracy: 0.8100\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8079 - val_loss: 0.4570 - val_accuracy: 0.8300\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8107 - val_loss: 0.5036 - val_accuracy: 0.7820\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8178 - val_loss: 0.5416 - val_accuracy: 0.7800\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8039 - val_loss: 0.4650 - val_accuracy: 0.8160\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7788 - val_loss: 0.4483 - val_accuracy: 0.8200\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8287 - val_loss: 0.4400 - val_accuracy: 0.8280\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7932 - val_loss: 0.5304 - val_accuracy: 0.7740\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8200 - val_loss: 0.4883 - val_accuracy: 0.8200\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8461 - val_loss: 0.4420 - val_accuracy: 0.8260\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8325 - val_loss: 0.4457 - val_accuracy: 0.8280\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8171 - val_loss: 0.4406 - val_accuracy: 0.8220\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8044 - val_loss: 0.4757 - val_accuracy: 0.8060\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8363 - val_loss: 0.4605 - val_accuracy: 0.8260\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8320 - val_loss: 0.4909 - val_accuracy: 0.8280\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8255 - val_loss: 0.4663 - val_accuracy: 0.8240\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8019 - val_loss: 0.4503 - val_accuracy: 0.8280\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8280 - val_loss: 0.4913 - val_accuracy: 0.8180\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8118 - val_loss: 0.4807 - val_accuracy: 0.8280\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8147 - val_loss: 0.4827 - val_accuracy: 0.8180\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7982 - val_loss: 0.4241 - val_accuracy: 0.8320\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.8090 - val_loss: 0.4636 - val_accuracy: 0.8360\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8011 - val_loss: 0.4793 - val_accuracy: 0.8160\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7988 - val_loss: 0.4764 - val_accuracy: 0.8400\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8264 - val_loss: 0.4624 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8066 - val_loss: 0.4671 - val_accuracy: 0.8180\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8513 - val_loss: 0.5021 - val_accuracy: 0.8180\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8404 - val_loss: 0.4747 - val_accuracy: 0.8180\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8008 - val_loss: 0.4563 - val_accuracy: 0.8220\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8020 - val_loss: 0.4448 - val_accuracy: 0.8240\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8193 - val_loss: 0.4547 - val_accuracy: 0.8340\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8042 - val_loss: 0.4931 - val_accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8517 - val_loss: 0.4778 - val_accuracy: 0.8240\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8048 - val_loss: 0.4489 - val_accuracy: 0.8360\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8192 - val_loss: 0.5182 - val_accuracy: 0.8300\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8208 - val_loss: 0.4697 - val_accuracy: 0.8180\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8492 - val_loss: 0.4752 - val_accuracy: 0.8180\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8437 - val_loss: 0.4894 - val_accuracy: 0.8300\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8291 - val_loss: 0.5012 - val_accuracy: 0.8040\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8135 - val_loss: 0.4864 - val_accuracy: 0.8240\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8327 - val_loss: 0.5323 - val_accuracy: 0.7760\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8578 - val_loss: 0.4596 - val_accuracy: 0.8100\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8050 - val_loss: 0.4964 - val_accuracy: 0.7900\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8139 - val_loss: 0.5040 - val_accuracy: 0.8100\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8083 - val_loss: 0.4887 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8254 - val_loss: 0.5109 - val_accuracy: 0.7980\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8231 - val_loss: 0.5023 - val_accuracy: 0.8280\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8331 - val_loss: 0.4972 - val_accuracy: 0.8360\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8247 - val_loss: 0.4988 - val_accuracy: 0.7900\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.7952 - val_loss: 0.5277 - val_accuracy: 0.8320\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8200 - val_loss: 0.4809 - val_accuracy: 0.8100\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8310 - val_loss: 0.4759 - val_accuracy: 0.7960\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8363 - val_loss: 0.4712 - val_accuracy: 0.8120\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8141 - val_loss: 0.6048 - val_accuracy: 0.7820\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.8260\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7900 - val_loss: 0.5791 - val_accuracy: 0.7840\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7635 - val_loss: 0.4661 - val_accuracy: 0.8360\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8265 - val_loss: 0.4817 - val_accuracy: 0.8220\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8314 - val_loss: 0.4642 - val_accuracy: 0.8340\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.80 - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8030 - val_loss: 0.5014 - val_accuracy: 0.8160\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8069 - val_loss: 0.5117 - val_accuracy: 0.8200\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8420 - val_loss: 0.5197 - val_accuracy: 0.7920\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8026 - val_loss: 0.4472 - val_accuracy: 0.8140\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8068 - val_loss: 0.5656 - val_accuracy: 0.8000\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8627 - val_loss: 0.5679 - val_accuracy: 0.7580\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8055 - val_loss: 0.4914 - val_accuracy: 0.8200\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8170 - val_loss: 0.5982 - val_accuracy: 0.7680\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7823 - val_loss: 0.4941 - val_accuracy: 0.8200\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8093 - val_loss: 0.5077 - val_accuracy: 0.8380\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7927 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7868 - val_loss: 0.4657 - val_accuracy: 0.8340\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7960 - val_loss: 0.5159 - val_accuracy: 0.8340\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8023 - val_loss: 0.4625 - val_accuracy: 0.8160\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8235 - val_loss: 0.4722 - val_accuracy: 0.8220\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8329 - val_loss: 0.4829 - val_accuracy: 0.8200\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7898 - val_loss: 0.5858 - val_accuracy: 0.8000\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7949 - val_loss: 0.5301 - val_accuracy: 0.8360\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8054 - val_loss: 0.5877 - val_accuracy: 0.8020\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8036 - val_loss: 0.5181 - val_accuracy: 0.8340\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8441 - val_loss: 0.4543 - val_accuracy: 0.8240\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8534 - val_loss: 0.5198 - val_accuracy: 0.8240\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8070 - val_loss: 0.4931 - val_accuracy: 0.8220\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8614 - val_loss: 0.4831 - val_accuracy: 0.8300\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8706 - val_loss: 0.5264 - val_accuracy: 0.7360\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7871 - val_loss: 0.4988 - val_accuracy: 0.8280\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8255 - val_loss: 0.4873 - val_accuracy: 0.8120\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8199 - val_loss: 0.4818 - val_accuracy: 0.8260\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8034 - val_loss: 0.4654 - val_accuracy: 0.8200\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8350 - val_loss: 0.4862 - val_accuracy: 0.8180\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8312 - val_loss: 0.5009 - val_accuracy: 0.8380\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8621 - val_loss: 0.5362 - val_accuracy: 0.8220\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8074 - val_loss: 0.4714 - val_accuracy: 0.8160\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8203 - val_loss: 0.4979 - val_accuracy: 0.8180\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8050 - val_loss: 0.5225 - val_accuracy: 0.8260\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7585 - val_loss: 0.4746 - val_accuracy: 0.8380\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8047 - val_loss: 0.4915 - val_accuracy: 0.8380\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8211 - val_loss: 0.4918 - val_accuracy: 0.8020\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8527 - val_loss: 0.4618 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8369 - val_loss: 0.4758 - val_accuracy: 0.8220\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8027 - val_loss: 0.4841 - val_accuracy: 0.8260\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8198 - val_loss: 0.5170 - val_accuracy: 0.8140\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8266 - val_loss: 0.5096 - val_accuracy: 0.8320\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8309 - val_loss: 0.5217 - val_accuracy: 0.7700\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8293 - val_loss: 0.5413 - val_accuracy: 0.7920\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7849 - val_loss: 0.5127 - val_accuracy: 0.8340\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8369 - val_loss: 0.5038 - val_accuracy: 0.8340\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7740 - val_loss: 0.5033 - val_accuracy: 0.8220\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8023 - val_loss: 0.4729 - val_accuracy: 0.8260\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8228 - val_loss: 0.5287 - val_accuracy: 0.8060\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8221 - val_loss: 0.4853 - val_accuracy: 0.8160\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7943 - val_loss: 0.4967 - val_accuracy: 0.8320\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 3.5674 - accuracy: 0.3927 - val_loss: 0.6930 - val_accuracy: 0.7440\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8273 - accuracy: 0.6543 - val_loss: 0.5868 - val_accuracy: 0.7380\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7938 - val_loss: 0.4956 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7327 - val_loss: 0.7361 - val_accuracy: 0.6780\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7602 - val_loss: 0.4525 - val_accuracy: 0.8200\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7716 - val_loss: 0.4270 - val_accuracy: 0.8300\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7804 - val_loss: 0.4326 - val_accuracy: 0.8240\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8204 - val_loss: 0.4340 - val_accuracy: 0.8280\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7851 - val_loss: 0.4628 - val_accuracy: 0.8300\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7894 - val_loss: 0.4638 - val_accuracy: 0.8200\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8334 - val_loss: 0.4516 - val_accuracy: 0.8020\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7622 - val_loss: 0.4471 - val_accuracy: 0.8240\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7892 - val_loss: 0.4256 - val_accuracy: 0.8340\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8055 - val_loss: 0.4213 - val_accuracy: 0.8260\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8130 - val_loss: 0.4799 - val_accuracy: 0.8020\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8139 - val_loss: 0.4213 - val_accuracy: 0.8220\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7996 - val_loss: 0.4132 - val_accuracy: 0.8340\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8107 - val_loss: 0.4207 - val_accuracy: 0.8240\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8183 - val_loss: 0.4231 - val_accuracy: 0.8400\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8316 - val_loss: 0.4283 - val_accuracy: 0.8400\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8399 - val_loss: 0.4121 - val_accuracy: 0.8200\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8025 - val_loss: 0.4378 - val_accuracy: 0.8260\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8102 - val_loss: 0.4231 - val_accuracy: 0.8280\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7670 - val_loss: 0.4367 - val_accuracy: 0.8260\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7631 - val_loss: 0.4438 - val_accuracy: 0.8260\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8109 - val_loss: 0.5143 - val_accuracy: 0.7700\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8166 - val_loss: 0.4681 - val_accuracy: 0.8060\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8256 - val_loss: 0.4288 - val_accuracy: 0.8280\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7828 - val_loss: 0.4342 - val_accuracy: 0.8220\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8219 - val_loss: 0.4206 - val_accuracy: 0.8220\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8489 - val_loss: 0.4210 - val_accuracy: 0.8140\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8361 - val_loss: 0.4248 - val_accuracy: 0.8380\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7745 - val_loss: 0.4251 - val_accuracy: 0.8220\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8518 - val_loss: 0.4200 - val_accuracy: 0.8280\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8069 - val_loss: 0.4449 - val_accuracy: 0.8260\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8145 - val_loss: 0.4215 - val_accuracy: 0.8180\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8039 - val_loss: 0.4535 - val_accuracy: 0.8120\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8018 - val_loss: 0.4559 - val_accuracy: 0.8200\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8189 - val_loss: 0.4259 - val_accuracy: 0.8240\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8149 - val_loss: 0.4630 - val_accuracy: 0.8060\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8001 - val_loss: 0.4350 - val_accuracy: 0.8360\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8344 - val_loss: 0.4118 - val_accuracy: 0.8320\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8107 - val_loss: 0.4535 - val_accuracy: 0.8260\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8096 - val_loss: 0.4508 - val_accuracy: 0.8220\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8250 - val_loss: 0.4158 - val_accuracy: 0.8220\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8360 - val_loss: 0.4243 - val_accuracy: 0.8260\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8191 - val_loss: 0.4191 - val_accuracy: 0.8340\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8479 - val_loss: 0.4681 - val_accuracy: 0.8040\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8433 - val_loss: 0.4463 - val_accuracy: 0.8160\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8111 - val_loss: 0.4062 - val_accuracy: 0.8260\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7939 - val_loss: 0.4720 - val_accuracy: 0.8140\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8238 - val_loss: 0.4134 - val_accuracy: 0.8300\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8273 - val_loss: 0.4220 - val_accuracy: 0.8260\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8434 - val_loss: 0.4905 - val_accuracy: 0.7880\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8199 - val_loss: 0.4309 - val_accuracy: 0.8320\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8403 - val_loss: 0.4447 - val_accuracy: 0.8240\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8421 - val_loss: 0.4234 - val_accuracy: 0.8320\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8391 - val_loss: 0.4652 - val_accuracy: 0.8160\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8131 - val_loss: 0.4349 - val_accuracy: 0.8220\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8484 - val_loss: 0.4321 - val_accuracy: 0.8260\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8278 - val_loss: 0.4346 - val_accuracy: 0.8320\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4190 - val_accuracy: 0.8340\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8078 - val_loss: 0.5030 - val_accuracy: 0.7840\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7911 - val_loss: 0.4412 - val_accuracy: 0.8260\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8480 - val_loss: 0.4429 - val_accuracy: 0.8340\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8143 - val_loss: 0.4475 - val_accuracy: 0.8160\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8273 - val_loss: 0.4171 - val_accuracy: 0.8300\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8320 - val_loss: 0.4154 - val_accuracy: 0.8260\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8324 - val_loss: 0.4305 - val_accuracy: 0.8320\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8279 - val_loss: 0.4618 - val_accuracy: 0.8140\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8109 - val_loss: 0.4344 - val_accuracy: 0.8300\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8140 - val_loss: 0.4218 - val_accuracy: 0.8280\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8038 - val_loss: 0.4226 - val_accuracy: 0.8280\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8122 - val_loss: 0.4619 - val_accuracy: 0.8160\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8211 - val_loss: 0.4516 - val_accuracy: 0.8320\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7849 - val_loss: 0.4211 - val_accuracy: 0.8280\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8532 - val_loss: 0.4278 - val_accuracy: 0.8240\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7753 - val_loss: 0.4521 - val_accuracy: 0.8260\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8304 - val_loss: 0.4282 - val_accuracy: 0.8260\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.7926 - val_loss: 0.4836 - val_accuracy: 0.8000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8351 - val_loss: 0.4320 - val_accuracy: 0.8300\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8172 - val_loss: 0.4211 - val_accuracy: 0.8280\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8115 - val_loss: 0.4390 - val_accuracy: 0.8300\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8312 - val_loss: 0.4270 - val_accuracy: 0.8200\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8459 - val_loss: 0.4633 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8018 - val_loss: 0.4305 - val_accuracy: 0.8220\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8296 - val_loss: 0.5014 - val_accuracy: 0.7940\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8285 - val_loss: 0.4899 - val_accuracy: 0.7860\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8563 - val_loss: 0.4508 - val_accuracy: 0.8180\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8253 - val_loss: 0.4497 - val_accuracy: 0.8180\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8235 - val_loss: 0.4650 - val_accuracy: 0.8160\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7764 - val_loss: 0.4210 - val_accuracy: 0.8320\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8265 - val_loss: 0.4642 - val_accuracy: 0.8060\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8303 - val_loss: 0.4701 - val_accuracy: 0.8180\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7502 - val_loss: 0.4253 - val_accuracy: 0.8320\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8307 - val_loss: 0.4324 - val_accuracy: 0.8220\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7974 - val_loss: 0.4321 - val_accuracy: 0.8180\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8261 - val_loss: 0.4255 - val_accuracy: 0.8340\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8368 - val_loss: 0.4717 - val_accuracy: 0.8260\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8187 - val_loss: 0.4325 - val_accuracy: 0.8240\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8303 - val_loss: 0.4210 - val_accuracy: 0.8160\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8046 - val_loss: 0.4504 - val_accuracy: 0.8200\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8267 - val_loss: 0.4504 - val_accuracy: 0.8120\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8445 - val_loss: 0.4468 - val_accuracy: 0.8200\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8164 - val_loss: 0.4378 - val_accuracy: 0.8260\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8001 - val_loss: 0.4522 - val_accuracy: 0.8200\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8088 - val_loss: 0.4698 - val_accuracy: 0.8180\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8107 - val_loss: 0.4335 - val_accuracy: 0.8300\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8470 - val_loss: 0.4354 - val_accuracy: 0.8280\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8192 - val_loss: 0.4241 - val_accuracy: 0.8320\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8146 - val_loss: 0.4302 - val_accuracy: 0.8220\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8061 - val_loss: 0.4445 - val_accuracy: 0.8240\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8442 - val_loss: 0.4465 - val_accuracy: 0.8200\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8348 - val_loss: 0.4282 - val_accuracy: 0.8180\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8418 - val_loss: 0.4971 - val_accuracy: 0.7840\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8044 - val_loss: 0.4282 - val_accuracy: 0.8260\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8267 - val_loss: 0.4575 - val_accuracy: 0.8280\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7970 - val_loss: 0.4309 - val_accuracy: 0.8180\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8111 - val_loss: 0.4515 - val_accuracy: 0.8240\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8255 - val_loss: 0.4314 - val_accuracy: 0.8320\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8372 - val_loss: 0.4548 - val_accuracy: 0.8300\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8399 - val_loss: 0.4762 - val_accuracy: 0.8160\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7972 - val_loss: 0.4378 - val_accuracy: 0.8260\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8335 - val_loss: 0.4588 - val_accuracy: 0.8300\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8116 - val_loss: 0.4672 - val_accuracy: 0.8120\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8584 - val_loss: 0.4351 - val_accuracy: 0.8200\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8397 - val_loss: 0.4582 - val_accuracy: 0.8120\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8337 - val_loss: 0.4658 - val_accuracy: 0.8260\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8322 - val_loss: 0.4788 - val_accuracy: 0.8180\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8283 - val_loss: 0.4298 - val_accuracy: 0.8320\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8321 - val_loss: 0.4318 - val_accuracy: 0.8340\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8015 - val_loss: 0.4593 - val_accuracy: 0.8220\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8226 - val_loss: 0.4531 - val_accuracy: 0.8220\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8270 - val_loss: 0.4304 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8251 - val_loss: 0.5272 - val_accuracy: 0.7820\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8331 - val_loss: 0.4398 - val_accuracy: 0.8240\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8189 - val_loss: 0.4549 - val_accuracy: 0.8400\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8288 - val_loss: 0.4860 - val_accuracy: 0.7980\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8210 - val_loss: 0.4358 - val_accuracy: 0.8320\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8306 - val_loss: 0.4564 - val_accuracy: 0.8180\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8218 - val_loss: 0.4412 - val_accuracy: 0.8220\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8289 - val_loss: 0.4851 - val_accuracy: 0.8100\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8378 - val_loss: 0.4614 - val_accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8024 - val_loss: 0.4516 - val_accuracy: 0.8280\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8020 - val_loss: 0.4487 - val_accuracy: 0.8240\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8025 - val_loss: 0.4404 - val_accuracy: 0.8260\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8271 - val_loss: 0.4510 - val_accuracy: 0.8240\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8108 - val_loss: 0.4278 - val_accuracy: 0.8280\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8015 - val_loss: 0.4546 - val_accuracy: 0.8260\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8328 - val_loss: 0.4705 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8498 - val_loss: 0.4527 - val_accuracy: 0.8220\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8129 - val_loss: 0.4549 - val_accuracy: 0.8240\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8302 - val_loss: 0.4893 - val_accuracy: 0.8060\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8566 - val_loss: 0.5181 - val_accuracy: 0.7780\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7928 - val_loss: 0.4509 - val_accuracy: 0.8160\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8085 - val_loss: 0.5046 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8207 - val_loss: 0.4956 - val_accuracy: 0.8060\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8059 - val_loss: 0.4483 - val_accuracy: 0.8300\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8062 - val_loss: 0.4693 - val_accuracy: 0.8200\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7901 - val_loss: 0.4616 - val_accuracy: 0.8160\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8295 - val_loss: 0.4587 - val_accuracy: 0.8340\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8191 - val_loss: 0.4300 - val_accuracy: 0.8280\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8319 - val_loss: 0.4595 - val_accuracy: 0.8120\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8363 - val_loss: 0.4632 - val_accuracy: 0.8260\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8058 - val_loss: 0.4773 - val_accuracy: 0.8240\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8242 - val_loss: 0.4653 - val_accuracy: 0.8240\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8185 - val_loss: 0.5384 - val_accuracy: 0.8040\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7956 - val_loss: 0.4616 - val_accuracy: 0.8220\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8576 - val_loss: 0.4337 - val_accuracy: 0.8220\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8574 - val_loss: 0.4967 - val_accuracy: 0.8120\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8102 - val_loss: 0.4702 - val_accuracy: 0.8220\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8316 - val_loss: 0.4625 - val_accuracy: 0.8220\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8753 - val_loss: 0.4793 - val_accuracy: 0.7920\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8210 - val_loss: 0.4340 - val_accuracy: 0.8280\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8494 - val_loss: 0.4315 - val_accuracy: 0.8260\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8563 - val_loss: 0.4434 - val_accuracy: 0.8240\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8238 - val_loss: 0.4457 - val_accuracy: 0.8260\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8204 - val_loss: 0.4852 - val_accuracy: 0.8120\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8258 - val_loss: 0.4551 - val_accuracy: 0.8220\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8383 - val_loss: 0.4595 - val_accuracy: 0.8240\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.8186 - val_loss: 0.4804 - val_accuracy: 0.7940\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8176 - val_loss: 0.4417 - val_accuracy: 0.8260\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8189 - val_loss: 0.4953 - val_accuracy: 0.8100\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7695 - val_loss: 0.4771 - val_accuracy: 0.8300\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7880 - val_loss: 0.4336 - val_accuracy: 0.8360\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8131 - val_loss: 0.4824 - val_accuracy: 0.7820\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8544 - val_loss: 0.4506 - val_accuracy: 0.8140\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8329 - val_loss: 0.4442 - val_accuracy: 0.8220\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8256 - val_loss: 0.4553 - val_accuracy: 0.8280\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8298 - val_loss: 0.5501 - val_accuracy: 0.7760\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8115 - val_loss: 0.4473 - val_accuracy: 0.8260\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8302 - val_loss: 0.4544 - val_accuracy: 0.8120\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8412 - val_loss: 0.4561 - val_accuracy: 0.8260\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7673 - val_loss: 0.4467 - val_accuracy: 0.8160\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8202 - val_loss: 0.4578 - val_accuracy: 0.8320\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7734 - val_loss: 0.4751 - val_accuracy: 0.8340\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8189 - val_loss: 0.4815 - val_accuracy: 0.8160\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8408 - val_loss: 0.5261 - val_accuracy: 0.7820\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8135 - val_loss: 0.4589 - val_accuracy: 0.8300\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8360 - val_loss: 0.4569 - val_accuracy: 0.8240\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0911 - accuracy: 0.4543 - val_loss: 4.4926 - val_accuracy: 0.5640\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.1618 - accuracy: 0.6137 - val_loss: 0.9435 - val_accuracy: 0.6800\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.6573 - val_loss: 0.5933 - val_accuracy: 0.7520\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.7092 - val_loss: 1.0617 - val_accuracy: 0.6580\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.7477 - val_loss: 0.6954 - val_accuracy: 0.7080\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.6815 - val_loss: 0.4632 - val_accuracy: 0.8100\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7570 - val_loss: 0.4787 - val_accuracy: 0.8140\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8089 - val_loss: 0.4981 - val_accuracy: 0.8060\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7733 - val_loss: 0.4738 - val_accuracy: 0.8160\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.8006 - val_loss: 0.5714 - val_accuracy: 0.7800\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7854 - val_loss: 0.6021 - val_accuracy: 0.7420\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7217 - val_loss: 0.4402 - val_accuracy: 0.8220\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7948 - val_loss: 0.4313 - val_accuracy: 0.8180\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8256 - val_loss: 0.4663 - val_accuracy: 0.8140\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8088 - val_loss: 0.4275 - val_accuracy: 0.8300\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7982 - val_loss: 0.4450 - val_accuracy: 0.8060\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8088 - val_loss: 0.4406 - val_accuracy: 0.8320\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8015 - val_loss: 0.4321 - val_accuracy: 0.8300\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8314 - val_loss: 0.4342 - val_accuracy: 0.8300\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7947 - val_loss: 0.4464 - val_accuracy: 0.8260\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8243 - val_loss: 0.4411 - val_accuracy: 0.8280\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8010 - val_loss: 0.4337 - val_accuracy: 0.8320\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8108 - val_loss: 0.4575 - val_accuracy: 0.8060\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8029 - val_loss: 0.4755 - val_accuracy: 0.8120\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7871 - val_loss: 0.4207 - val_accuracy: 0.8400\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8127 - val_loss: 0.4287 - val_accuracy: 0.8200\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8405 - val_loss: 0.4127 - val_accuracy: 0.8220\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8224 - val_loss: 0.4280 - val_accuracy: 0.8260\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8070 - val_loss: 0.4159 - val_accuracy: 0.8260\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3827 - accuracy: 0.8201 - val_loss: 0.4704 - val_accuracy: 0.8060\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8343 - val_loss: 0.4115 - val_accuracy: 0.8220\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8196 - val_loss: 0.4179 - val_accuracy: 0.8340\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7950 - val_loss: 0.4116 - val_accuracy: 0.8260\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8359 - val_loss: 0.5071 - val_accuracy: 0.7920\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7904 - val_loss: 0.4690 - val_accuracy: 0.8100\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8044 - val_loss: 0.4513 - val_accuracy: 0.8020\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7963 - val_loss: 0.4213 - val_accuracy: 0.8240\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8147 - val_loss: 0.4742 - val_accuracy: 0.8020\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8184 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8030 - val_loss: 0.4524 - val_accuracy: 0.8120\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8074 - val_loss: 0.4186 - val_accuracy: 0.8340\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8096 - val_loss: 0.4644 - val_accuracy: 0.8120\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8301 - val_loss: 0.4375 - val_accuracy: 0.8320\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8039 - val_loss: 0.4449 - val_accuracy: 0.8300\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8146 - val_loss: 0.4100 - val_accuracy: 0.8220\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8175 - val_loss: 0.4399 - val_accuracy: 0.8240\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8165 - val_loss: 0.4140 - val_accuracy: 0.8180\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8580 - val_loss: 0.4183 - val_accuracy: 0.8300\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8277 - val_loss: 0.4081 - val_accuracy: 0.8220\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8200 - val_loss: 0.4153 - val_accuracy: 0.8260\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8060 - val_loss: 0.4175 - val_accuracy: 0.8220\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8179 - val_loss: 0.4348 - val_accuracy: 0.8200\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8419 - val_loss: 0.4518 - val_accuracy: 0.8060\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8171 - val_loss: 0.4482 - val_accuracy: 0.8100\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8177 - val_loss: 0.4253 - val_accuracy: 0.8240\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8338 - val_loss: 0.4231 - val_accuracy: 0.8220\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8408 - val_loss: 0.4297 - val_accuracy: 0.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8385 - val_loss: 0.4287 - val_accuracy: 0.8360\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8194 - val_loss: 0.4110 - val_accuracy: 0.8360\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8444 - val_loss: 0.4337 - val_accuracy: 0.8200\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8403 - val_loss: 0.4374 - val_accuracy: 0.8260\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7971 - val_loss: 0.4171 - val_accuracy: 0.8200\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8141 - val_loss: 0.4288 - val_accuracy: 0.8240\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7862 - val_loss: 0.4639 - val_accuracy: 0.8040\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8375 - val_loss: 0.4271 - val_accuracy: 0.8400\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8037 - val_loss: 0.4387 - val_accuracy: 0.8200\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8462 - val_loss: 0.4241 - val_accuracy: 0.8220\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8425 - val_loss: 0.4146 - val_accuracy: 0.8180\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8463 - val_loss: 0.4188 - val_accuracy: 0.8200\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8294 - val_loss: 0.4309 - val_accuracy: 0.8180\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8066 - val_loss: 0.4260 - val_accuracy: 0.8160\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8083 - val_loss: 0.4198 - val_accuracy: 0.8320\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8228 - val_loss: 0.4727 - val_accuracy: 0.7840\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8100 - val_loss: 0.4138 - val_accuracy: 0.8260\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8131 - val_loss: 0.5004 - val_accuracy: 0.8020\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7779 - val_loss: 0.4189 - val_accuracy: 0.8200\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8480 - val_loss: 0.4172 - val_accuracy: 0.8360\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7801 - val_loss: 0.4214 - val_accuracy: 0.8200\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8441 - val_loss: 0.4170 - val_accuracy: 0.8240\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8184 - val_loss: 0.4316 - val_accuracy: 0.8200\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8251 - val_loss: 0.4205 - val_accuracy: 0.8080\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8280\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7930 - val_loss: 0.4211 - val_accuracy: 0.8300\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8194 - val_loss: 0.4412 - val_accuracy: 0.8060\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8287 - val_loss: 0.4350 - val_accuracy: 0.8160\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.7985 - val_loss: 0.4689 - val_accuracy: 0.7960\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8313 - val_loss: 0.4343 - val_accuracy: 0.8180\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8198 - val_loss: 0.4500 - val_accuracy: 0.8140\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8512 - val_loss: 0.4251 - val_accuracy: 0.8180\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8203 - val_loss: 0.4162 - val_accuracy: 0.8260\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8464 - val_loss: 0.4336 - val_accuracy: 0.8240\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8113 - val_loss: 0.4117 - val_accuracy: 0.8260\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8297 - val_loss: 0.4298 - val_accuracy: 0.8180\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8300 - val_loss: 0.4631 - val_accuracy: 0.8100\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7841 - val_loss: 0.4229 - val_accuracy: 0.8220\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8456 - val_loss: 0.4342 - val_accuracy: 0.8280\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8084 - val_loss: 0.4376 - val_accuracy: 0.8140\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8268 - val_loss: 0.4187 - val_accuracy: 0.8280\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8337 - val_loss: 0.4287 - val_accuracy: 0.8080\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8257 - val_loss: 0.5133 - val_accuracy: 0.7720\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8174 - val_loss: 0.4235 - val_accuracy: 0.8160\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8342 - val_loss: 0.4486 - val_accuracy: 0.8160\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8259 - val_loss: 0.4165 - val_accuracy: 0.8220\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8273 - val_loss: 0.4175 - val_accuracy: 0.8260\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8032 - val_loss: 0.4168 - val_accuracy: 0.8280\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8025 - val_loss: 0.4805 - val_accuracy: 0.8080\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8251 - val_loss: 0.4352 - val_accuracy: 0.8240\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8309 - val_loss: 0.4193 - val_accuracy: 0.8300\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8298 - val_loss: 0.4323 - val_accuracy: 0.8200\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8157 - val_loss: 0.4281 - val_accuracy: 0.8180\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8236 - val_loss: 0.4276 - val_accuracy: 0.8260\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8277 - val_loss: 0.4271 - val_accuracy: 0.8240\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8413 - val_loss: 0.4322 - val_accuracy: 0.8180\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8505 - val_loss: 0.4164 - val_accuracy: 0.8320\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8323 - val_loss: 0.4171 - val_accuracy: 0.8140\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8316 - val_loss: 0.4704 - val_accuracy: 0.8040\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8185 - val_loss: 0.4294 - val_accuracy: 0.8200\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8125 - val_loss: 0.4337 - val_accuracy: 0.8140\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8102 - val_loss: 0.4251 - val_accuracy: 0.8260\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8394 - val_loss: 0.4136 - val_accuracy: 0.8280\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8421 - val_loss: 0.4372 - val_accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8382 - val_loss: 0.4252 - val_accuracy: 0.8160\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8205 - val_loss: 0.4352 - val_accuracy: 0.8240\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8249 - val_loss: 0.4332 - val_accuracy: 0.8180\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8210 - val_loss: 0.4341 - val_accuracy: 0.8140\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8636 - val_loss: 0.4239 - val_accuracy: 0.8220\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8417 - val_loss: 0.4222 - val_accuracy: 0.8260\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8305 - val_loss: 0.4171 - val_accuracy: 0.8160\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8183 - val_loss: 0.4762 - val_accuracy: 0.8100\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.8335 - val_loss: 0.4233 - val_accuracy: 0.8120\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8456 - val_loss: 0.4220 - val_accuracy: 0.8280\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8256 - val_loss: 0.4207 - val_accuracy: 0.8200\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8313 - val_loss: 0.4366 - val_accuracy: 0.8240\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8340 - val_loss: 0.4104 - val_accuracy: 0.8220\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8371 - val_loss: 0.4542 - val_accuracy: 0.8120\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8539 - val_loss: 0.4187 - val_accuracy: 0.8260\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8206 - val_loss: 0.4342 - val_accuracy: 0.8300\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8389 - val_loss: 0.4508 - val_accuracy: 0.8060\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8173 - val_loss: 0.4202 - val_accuracy: 0.8260\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8320 - val_loss: 0.4257 - val_accuracy: 0.8240\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8207 - val_loss: 0.4436 - val_accuracy: 0.8260\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8344 - val_loss: 0.4625 - val_accuracy: 0.8140\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8406 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8058 - val_loss: 0.4320 - val_accuracy: 0.8220\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8270 - val_loss: 0.4217 - val_accuracy: 0.8240\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8113 - val_loss: 0.4238 - val_accuracy: 0.8280\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8096 - val_loss: 0.4290 - val_accuracy: 0.8180\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8133 - val_loss: 0.4290 - val_accuracy: 0.8100\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8053 - val_loss: 0.4230 - val_accuracy: 0.8240\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8409 - val_loss: 0.4264 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8533 - val_loss: 0.4245 - val_accuracy: 0.8100\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8160 - val_loss: 0.4505 - val_accuracy: 0.8120\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8265 - val_loss: 0.4487 - val_accuracy: 0.8140\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8530 - val_loss: 0.4244 - val_accuracy: 0.8220\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8188 - val_loss: 0.4291 - val_accuracy: 0.8320\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7825 - val_loss: 0.4799 - val_accuracy: 0.8040\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.4871 - val_accuracy: 0.8080\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8195 - val_loss: 0.4308 - val_accuracy: 0.8280\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8094 - val_loss: 0.4286 - val_accuracy: 0.8180\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8255 - val_loss: 0.4321 - val_accuracy: 0.8200\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8408 - val_loss: 0.4339 - val_accuracy: 0.8300\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8329 - val_loss: 0.4224 - val_accuracy: 0.8200\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8269 - val_loss: 0.4273 - val_accuracy: 0.8260\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8385 - val_loss: 0.4336 - val_accuracy: 0.8240\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8009 - val_loss: 0.4401 - val_accuracy: 0.8400\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8356 - val_loss: 0.4222 - val_accuracy: 0.8280\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8180 - val_loss: 0.4434 - val_accuracy: 0.8260\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8408 - val_loss: 0.4307 - val_accuracy: 0.8360\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8555 - val_loss: 0.4274 - val_accuracy: 0.8200\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8283 - val_loss: 0.4431 - val_accuracy: 0.8220\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8188 - val_loss: 0.4390 - val_accuracy: 0.8220\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8485 - val_loss: 0.4493 - val_accuracy: 0.8160\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8712 - val_loss: 0.4342 - val_accuracy: 0.8180\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8319 - val_loss: 0.4166 - val_accuracy: 0.8260\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8380 - val_loss: 0.4416 - val_accuracy: 0.8200\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8566 - val_loss: 0.4246 - val_accuracy: 0.8220\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8182 - val_loss: 0.4257 - val_accuracy: 0.8260\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8201 - val_loss: 0.4337 - val_accuracy: 0.8280\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8213 - val_loss: 0.4285 - val_accuracy: 0.8200\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8368 - val_loss: 0.4410 - val_accuracy: 0.8200\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8503 - val_loss: 0.4333 - val_accuracy: 0.8180\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8089 - val_loss: 0.4686 - val_accuracy: 0.8140\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8274 - val_loss: 0.4449 - val_accuracy: 0.8160\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.4445 - val_accuracy: 0.8260\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8191 - val_loss: 0.4316 - val_accuracy: 0.8220\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8290 - val_loss: 0.4468 - val_accuracy: 0.8140\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8526 - val_loss: 0.4278 - val_accuracy: 0.8280\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8504 - val_loss: 0.4290 - val_accuracy: 0.8180\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8310 - val_loss: 0.4394 - val_accuracy: 0.8240\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8147 - val_loss: 0.4533 - val_accuracy: 0.8080\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8134 - val_loss: 0.4283 - val_accuracy: 0.8240\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8645 - val_loss: 0.4192 - val_accuracy: 0.8300\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8653 - val_loss: 0.4202 - val_accuracy: 0.8140\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7935 - val_loss: 0.4271 - val_accuracy: 0.8240\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8314 - val_loss: 0.4296 - val_accuracy: 0.8300\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7946 - val_loss: 0.4598 - val_accuracy: 0.8240\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8033 - val_loss: 0.4381 - val_accuracy: 0.8280\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8435 - val_loss: 0.4709 - val_accuracy: 0.8120\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7993 - val_loss: 0.4381 - val_accuracy: 0.8260\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8152 - val_loss: 0.4382 - val_accuracy: 0.8300\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1.9205 - accuracy: 0.4240 - val_loss: 1.8367 - val_accuracy: 0.5520\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2336 - accuracy: 0.5472 - val_loss: 0.9831 - val_accuracy: 0.6880\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6809 - accuracy: 0.6136 - val_loss: 0.8054 - val_accuracy: 0.6580\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1722 - accuracy: 0.5731 - val_loss: 0.9352 - val_accuracy: 0.7160\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.8720 - accuracy: 0.6720 - val_loss: 0.7572 - val_accuracy: 0.7220\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.8501 - accuracy: 0.6532 - val_loss: 1.1511 - val_accuracy: 0.5740\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.9126 - accuracy: 0.6655 - val_loss: 0.6135 - val_accuracy: 0.7100\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6994 - val_loss: 0.5353 - val_accuracy: 0.7620\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7246 - val_loss: 0.4759 - val_accuracy: 0.8200\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7753 - val_loss: 0.4806 - val_accuracy: 0.8120\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.7792 - val_loss: 0.4592 - val_accuracy: 0.8180\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7810 - val_loss: 0.4497 - val_accuracy: 0.8280\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7799 - val_loss: 0.4673 - val_accuracy: 0.8060\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7977 - val_loss: 0.5681 - val_accuracy: 0.7520\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7787 - val_loss: 0.5221 - val_accuracy: 0.7880\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7604 - val_loss: 0.4620 - val_accuracy: 0.8200\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.7884 - val_loss: 0.4357 - val_accuracy: 0.8140\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8015 - val_loss: 0.4321 - val_accuracy: 0.8380\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8245 - val_loss: 0.4450 - val_accuracy: 0.8080\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8013 - val_loss: 0.4151 - val_accuracy: 0.8340\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8314 - val_loss: 0.4282 - val_accuracy: 0.8220\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8037 - val_loss: 0.4324 - val_accuracy: 0.8340\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8304 - val_loss: 0.4321 - val_accuracy: 0.8140\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8026 - val_loss: 0.4980 - val_accuracy: 0.7940\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7744 - val_loss: 0.4199 - val_accuracy: 0.8380\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8078 - val_loss: 0.4150 - val_accuracy: 0.8360\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8558 - val_loss: 0.4217 - val_accuracy: 0.8300\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8082 - val_loss: 0.4182 - val_accuracy: 0.8260\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8136 - val_loss: 0.4155 - val_accuracy: 0.8280\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8131 - val_loss: 0.4352 - val_accuracy: 0.8220\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8440 - val_loss: 0.4283 - val_accuracy: 0.8240\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8310 - val_loss: 0.4102 - val_accuracy: 0.8360\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8067 - val_loss: 0.4354 - val_accuracy: 0.8300\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8393 - val_loss: 0.4761 - val_accuracy: 0.8100\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8276 - val_loss: 0.4616 - val_accuracy: 0.8120\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7988 - val_loss: 0.4063 - val_accuracy: 0.8300\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8099 - val_loss: 0.4401 - val_accuracy: 0.8180\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8130 - val_loss: 0.4296 - val_accuracy: 0.8220\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8199 - val_loss: 0.4984 - val_accuracy: 0.7860\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8235 - val_loss: 0.4552 - val_accuracy: 0.8120\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8053 - val_loss: 0.4074 - val_accuracy: 0.8220\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8221 - val_loss: 0.4543 - val_accuracy: 0.8120\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8343 - val_loss: 0.4382 - val_accuracy: 0.8160\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8233 - val_loss: 0.4446 - val_accuracy: 0.8220\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8312 - val_loss: 0.4533 - val_accuracy: 0.8160\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8147 - val_loss: 0.4534 - val_accuracy: 0.8200\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8003 - val_loss: 0.4093 - val_accuracy: 0.8280\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8540 - val_loss: 0.4315 - val_accuracy: 0.8240\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8179 - val_loss: 0.4083 - val_accuracy: 0.8280\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8193 - val_loss: 0.4124 - val_accuracy: 0.8380\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8229 - val_loss: 0.4148 - val_accuracy: 0.8280\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8157 - val_loss: 0.4214 - val_accuracy: 0.8180\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8434 - val_loss: 0.4960 - val_accuracy: 0.7900\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8182 - val_loss: 0.4455 - val_accuracy: 0.8120\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3728 - accuracy: 0.8323 - val_loss: 0.4078 - val_accuracy: 0.8240\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8485 - val_loss: 0.4281 - val_accuracy: 0.8260\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8449 - val_loss: 0.4122 - val_accuracy: 0.8200\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8359 - val_loss: 0.4339 - val_accuracy: 0.8220\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8052 - val_loss: 0.4142 - val_accuracy: 0.8320\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8446 - val_loss: 0.4197 - val_accuracy: 0.8320\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8404 - val_loss: 0.4471 - val_accuracy: 0.8160\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8077 - val_loss: 0.4400 - val_accuracy: 0.8200\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7973 - val_loss: 0.4358 - val_accuracy: 0.8240\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7833 - val_loss: 0.4314 - val_accuracy: 0.8260\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8416 - val_loss: 0.4277 - val_accuracy: 0.8180\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8237 - val_loss: 0.4252 - val_accuracy: 0.8220\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8291 - val_loss: 0.4121 - val_accuracy: 0.8180\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8372 - val_loss: 0.4253 - val_accuracy: 0.8320\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8292 - val_loss: 0.4261 - val_accuracy: 0.8180\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8398 - val_loss: 0.4056 - val_accuracy: 0.8320\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8241 - val_loss: 0.4284 - val_accuracy: 0.8200\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.4087 - val_accuracy: 0.8340\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8390 - val_loss: 0.4750 - val_accuracy: 0.8040\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7906 - val_loss: 0.4139 - val_accuracy: 0.8240\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8122 - val_loss: 0.4439 - val_accuracy: 0.8220\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7829 - val_loss: 0.4519 - val_accuracy: 0.8040\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8485 - val_loss: 0.4154 - val_accuracy: 0.8260\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7907 - val_loss: 0.4243 - val_accuracy: 0.8240\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8393 - val_loss: 0.4176 - val_accuracy: 0.8260\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8054 - val_loss: 0.4318 - val_accuracy: 0.8160\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8033 - val_loss: 0.4533 - val_accuracy: 0.8020\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3743 - accuracy: 0.8425 - val_loss: 0.4195 - val_accuracy: 0.8280\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7886 - val_loss: 0.4235 - val_accuracy: 0.8300\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8175 - val_loss: 0.4220 - val_accuracy: 0.8180\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8369 - val_loss: 0.4295 - val_accuracy: 0.8140\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8124 - val_loss: 0.4851 - val_accuracy: 0.7920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8148 - val_loss: 0.4291 - val_accuracy: 0.8220\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8291 - val_loss: 0.4528 - val_accuracy: 0.8100\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8448 - val_loss: 0.4219 - val_accuracy: 0.8240\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8407 - val_loss: 0.4135 - val_accuracy: 0.8160\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8274 - val_loss: 0.4217 - val_accuracy: 0.8220\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8178 - val_loss: 0.4114 - val_accuracy: 0.8220\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8218 - val_loss: 0.4284 - val_accuracy: 0.8180\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8255 - val_loss: 0.4698 - val_accuracy: 0.8040\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7896 - val_loss: 0.4262 - val_accuracy: 0.8180\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8398 - val_loss: 0.4521 - val_accuracy: 0.8180\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8073 - val_loss: 0.4639 - val_accuracy: 0.8060\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8144 - val_loss: 0.4341 - val_accuracy: 0.8200\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3614 - accuracy: 0.8434 - val_loss: 0.4376 - val_accuracy: 0.8160\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8307 - val_loss: 0.5050 - val_accuracy: 0.7900\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8329 - val_loss: 0.4431 - val_accuracy: 0.8160\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8144 - val_loss: 0.4386 - val_accuracy: 0.8200\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8267 - val_loss: 0.4267 - val_accuracy: 0.8200\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8157 - val_loss: 0.4093 - val_accuracy: 0.8220\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8257 - val_loss: 0.4218 - val_accuracy: 0.8220\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.7939 - val_loss: 0.4778 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8334 - val_loss: 0.4547 - val_accuracy: 0.8120\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8215 - val_loss: 0.4164 - val_accuracy: 0.8240\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8378 - val_loss: 0.4276 - val_accuracy: 0.8220\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.8024 - val_loss: 0.4344 - val_accuracy: 0.8180\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8149 - val_loss: 0.4251 - val_accuracy: 0.8220\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.4267 - val_accuracy: 0.8260\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8388 - val_loss: 0.4605 - val_accuracy: 0.8120\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8348 - val_loss: 0.4215 - val_accuracy: 0.8220\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8325 - val_loss: 0.4218 - val_accuracy: 0.8300\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8429 - val_loss: 0.4203 - val_accuracy: 0.8220\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8276 - val_loss: 0.4158 - val_accuracy: 0.8220\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8062 - val_loss: 0.4271 - val_accuracy: 0.8140\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8134 - val_loss: 0.4233 - val_accuracy: 0.8200\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8458 - val_loss: 0.4307 - val_accuracy: 0.8140\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8255 - val_loss: 0.4272 - val_accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8399 - val_loss: 0.4377 - val_accuracy: 0.8160\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8128 - val_loss: 0.4334 - val_accuracy: 0.8180\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8087 - val_loss: 0.4243 - val_accuracy: 0.8240\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8227 - val_loss: 0.4288 - val_accuracy: 0.8180\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8582 - val_loss: 0.4531 - val_accuracy: 0.8100\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8337 - val_loss: 0.4116 - val_accuracy: 0.8320\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8331 - val_loss: 0.4261 - val_accuracy: 0.8300\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8057 - val_loss: 0.4372 - val_accuracy: 0.8220\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8137 - val_loss: 0.4188 - val_accuracy: 0.8200\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8439 - val_loss: 0.4217 - val_accuracy: 0.8260\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8143 - val_loss: 0.4180 - val_accuracy: 0.8260\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.8284 - val_loss: 0.4225 - val_accuracy: 0.8260\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3872 - accuracy: 0.8347 - val_loss: 0.4178 - val_accuracy: 0.8180\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8366 - val_loss: 0.4535 - val_accuracy: 0.8200\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.8493 - val_loss: 0.4301 - val_accuracy: 0.8160\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8321 - val_loss: 0.4200 - val_accuracy: 0.8300\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3824 - accuracy: 0.8423 - val_loss: 0.4580 - val_accuracy: 0.8180\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3803 - accuracy: 0.8447 - val_loss: 0.4182 - val_accuracy: 0.8180\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8363 - val_loss: 0.4283 - val_accuracy: 0.8220\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8240 - val_loss: 0.4446 - val_accuracy: 0.8200\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8320 - val_loss: 0.4589 - val_accuracy: 0.8120\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3795 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7900\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7978 - val_loss: 0.4544 - val_accuracy: 0.8040\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8098 - val_loss: 0.4264 - val_accuracy: 0.8100\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8135 - val_loss: 0.4231 - val_accuracy: 0.8260\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8132 - val_loss: 0.4232 - val_accuracy: 0.8180\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8156 - val_loss: 0.4331 - val_accuracy: 0.8220\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8115 - val_loss: 0.4225 - val_accuracy: 0.8180\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8407 - val_loss: 0.4182 - val_accuracy: 0.8240\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8578 - val_loss: 0.4353 - val_accuracy: 0.8100\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3831 - accuracy: 0.8254 - val_loss: 0.4521 - val_accuracy: 0.8160\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8251 - val_loss: 0.4726 - val_accuracy: 0.8060\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3736 - accuracy: 0.8461 - val_loss: 0.4338 - val_accuracy: 0.8160\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8144 - val_loss: 0.4180 - val_accuracy: 0.8280\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.7977 - val_loss: 0.4506 - val_accuracy: 0.8180\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8318 - val_loss: 0.4559 - val_accuracy: 0.8080\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8295 - val_loss: 0.4172 - val_accuracy: 0.8340\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8017 - val_loss: 0.4331 - val_accuracy: 0.8220\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8276 - val_loss: 0.4375 - val_accuracy: 0.8160\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8162 - val_loss: 0.4293 - val_accuracy: 0.8220\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8553 - val_loss: 0.4320 - val_accuracy: 0.8300\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8168 - val_loss: 0.4263 - val_accuracy: 0.8220\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8234 - val_loss: 0.4366 - val_accuracy: 0.8240\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7967 - val_loss: 0.4265 - val_accuracy: 0.8300\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8382 - val_loss: 0.4290 - val_accuracy: 0.8220\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8090 - val_loss: 0.4653 - val_accuracy: 0.7980\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8258 - val_loss: 0.4200 - val_accuracy: 0.8260\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8455 - val_loss: 0.4288 - val_accuracy: 0.8260\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8483 - val_loss: 0.4333 - val_accuracy: 0.8220\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8198 - val_loss: 0.4315 - val_accuracy: 0.8340\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8461 - val_loss: 0.4249 - val_accuracy: 0.8160\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8727 - val_loss: 0.4265 - val_accuracy: 0.8260\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8346 - val_loss: 0.4178 - val_accuracy: 0.8160\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8266 - val_loss: 0.4497 - val_accuracy: 0.8220\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8640 - val_loss: 0.4222 - val_accuracy: 0.8200\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8270 - val_loss: 0.4396 - val_accuracy: 0.8180\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8295 - val_loss: 0.4358 - val_accuracy: 0.8140\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8251 - val_loss: 0.4354 - val_accuracy: 0.8220\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8367 - val_loss: 0.4446 - val_accuracy: 0.8180\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3710 - accuracy: 0.8638 - val_loss: 0.4240 - val_accuracy: 0.8320\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8329 - val_loss: 0.4540 - val_accuracy: 0.8180\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8202 - val_loss: 0.4625 - val_accuracy: 0.8200\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8069 - val_loss: 0.4566 - val_accuracy: 0.8100\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8201 - val_loss: 0.4727 - val_accuracy: 0.8020\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3804 - accuracy: 0.8266 - val_loss: 0.4328 - val_accuracy: 0.8220\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8680 - val_loss: 0.4304 - val_accuracy: 0.8240\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8381 - val_loss: 0.4224 - val_accuracy: 0.8220\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.8399 - val_loss: 0.4262 - val_accuracy: 0.8160\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8144 - val_loss: 0.4442 - val_accuracy: 0.8160\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8248 - val_loss: 0.4328 - val_accuracy: 0.8200\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8706 - val_loss: 0.4233 - val_accuracy: 0.8200\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8393 - val_loss: 0.4200 - val_accuracy: 0.8200\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8089 - val_loss: 0.4195 - val_accuracy: 0.8220\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8237 - val_loss: 0.4212 - val_accuracy: 0.8240\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8029 - val_loss: 0.4351 - val_accuracy: 0.8260\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8104 - val_loss: 0.4239 - val_accuracy: 0.8200\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8306 - val_loss: 0.4598 - val_accuracy: 0.8120\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8098 - val_loss: 0.4453 - val_accuracy: 0.8180\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8074 - val_loss: 0.4321 - val_accuracy: 0.8200\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 29ms/step - loss: 4.0915 - accuracy: 0.4383 - val_loss: 5.1564 - val_accuracy: 0.4160\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.6912 - accuracy: 0.4750 - val_loss: 2.7205 - val_accuracy: 0.6140\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.9183 - accuracy: 0.5859 - val_loss: 1.5136 - val_accuracy: 0.6520\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1.7486 - accuracy: 0.6092 - val_loss: 1.1345 - val_accuracy: 0.6320\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.1488 - accuracy: 0.6159 - val_loss: 1.0055 - val_accuracy: 0.6840\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0765 - accuracy: 0.6168 - val_loss: 0.7757 - val_accuracy: 0.7080\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7807 - accuracy: 0.6842 - val_loss: 0.7422 - val_accuracy: 0.7100\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7163 - accuracy: 0.6903 - val_loss: 0.7017 - val_accuracy: 0.7220\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.8114 - accuracy: 0.6359 - val_loss: 0.7588 - val_accuracy: 0.7000\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7165 - accuracy: 0.6813 - val_loss: 0.5557 - val_accuracy: 0.7600\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7357 - val_loss: 0.5295 - val_accuracy: 0.7780\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.7590 - val_loss: 0.5043 - val_accuracy: 0.7960\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7437 - val_loss: 0.4982 - val_accuracy: 0.8140\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7589 - val_loss: 0.4896 - val_accuracy: 0.8160\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7460 - val_loss: 0.4992 - val_accuracy: 0.7900\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7596 - val_loss: 0.4851 - val_accuracy: 0.8380\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.8047 - val_loss: 0.4769 - val_accuracy: 0.8240\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7505 - val_loss: 0.4764 - val_accuracy: 0.8280\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7997 - val_loss: 0.5571 - val_accuracy: 0.7900\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5750 - accuracy: 0.7452 - val_loss: 0.4595 - val_accuracy: 0.8400\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7821 - val_loss: 0.4656 - val_accuracy: 0.8160\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7630 - val_loss: 0.4510 - val_accuracy: 0.8300\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.8118 - val_loss: 0.4507 - val_accuracy: 0.8200\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7934 - val_loss: 0.4635 - val_accuracy: 0.8320\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8046 - val_loss: 0.4632 - val_accuracy: 0.8240\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.7938 - val_loss: 0.4390 - val_accuracy: 0.8260\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4502 - accuracy: 0.8106 - val_loss: 0.4378 - val_accuracy: 0.8260\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8187 - val_loss: 0.4474 - val_accuracy: 0.8240\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8132 - val_loss: 0.4436 - val_accuracy: 0.8260\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8240 - val_loss: 0.4409 - val_accuracy: 0.8320\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.8471 - val_loss: 0.4631 - val_accuracy: 0.8180\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7989 - val_loss: 0.4464 - val_accuracy: 0.8260\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.8127 - val_loss: 0.4571 - val_accuracy: 0.8240\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8409 - val_loss: 0.4519 - val_accuracy: 0.8200\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.8088 - val_loss: 0.4270 - val_accuracy: 0.8360\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8212 - val_loss: 0.4184 - val_accuracy: 0.8340\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8065 - val_loss: 0.4357 - val_accuracy: 0.8240\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.8173 - val_loss: 0.4289 - val_accuracy: 0.8320\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8115 - val_loss: 0.4977 - val_accuracy: 0.7840\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7955 - val_loss: 0.4380 - val_accuracy: 0.8200\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.8106 - val_loss: 0.4339 - val_accuracy: 0.8220\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.8236 - val_loss: 0.4273 - val_accuracy: 0.8320\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8210 - val_loss: 0.4331 - val_accuracy: 0.8240\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.8049 - val_loss: 0.4150 - val_accuracy: 0.8260\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8154 - val_loss: 0.4048 - val_accuracy: 0.8340\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.8313 - val_loss: 0.4221 - val_accuracy: 0.8180\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.8249 - val_loss: 0.4320 - val_accuracy: 0.8200\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8021 - val_loss: 0.4568 - val_accuracy: 0.8080\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4502 - accuracy: 0.8234 - val_loss: 0.4506 - val_accuracy: 0.8220\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7937 - val_loss: 0.4416 - val_accuracy: 0.8220\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7973 - val_loss: 0.4788 - val_accuracy: 0.7960\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7764 - val_loss: 0.4521 - val_accuracy: 0.8160\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8213 - val_loss: 0.5031 - val_accuracy: 0.7780\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.8177 - val_loss: 0.4276 - val_accuracy: 0.8280\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8351 - val_loss: 0.4244 - val_accuracy: 0.8220\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8514 - val_loss: 0.4003 - val_accuracy: 0.8320\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8166 - val_loss: 0.4020 - val_accuracy: 0.8380\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8076 - val_loss: 0.3986 - val_accuracy: 0.8340\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.8186 - val_loss: 0.4032 - val_accuracy: 0.8320\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8341 - val_loss: 0.5014 - val_accuracy: 0.7960\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7934 - val_loss: 0.4203 - val_accuracy: 0.8240\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8049 - val_loss: 0.4228 - val_accuracy: 0.8280\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.8019 - val_loss: 0.4351 - val_accuracy: 0.8200\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7985 - val_loss: 0.4365 - val_accuracy: 0.8220\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8457 - val_loss: 0.4013 - val_accuracy: 0.8360\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8156 - val_loss: 0.3961 - val_accuracy: 0.8440\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8436 - val_loss: 0.4069 - val_accuracy: 0.8280\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8414 - val_loss: 0.4010 - val_accuracy: 0.8360\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8331 - val_loss: 0.3985 - val_accuracy: 0.8300\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4027 - accuracy: 0.8294 - val_loss: 0.4043 - val_accuracy: 0.8360\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.8142 - val_loss: 0.3991 - val_accuracy: 0.8360\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8100 - val_loss: 0.3977 - val_accuracy: 0.8360\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8361 - val_loss: 0.4063 - val_accuracy: 0.8300\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8338 - val_loss: 0.4167 - val_accuracy: 0.8200\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8055 - val_loss: 0.3987 - val_accuracy: 0.8400\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7972 - val_loss: 0.4051 - val_accuracy: 0.8260\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3762 - accuracy: 0.8477 - val_loss: 0.3983 - val_accuracy: 0.8360\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8092 - val_loss: 0.4016 - val_accuracy: 0.8320\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8418 - val_loss: 0.4027 - val_accuracy: 0.8300\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8447 - val_loss: 0.4018 - val_accuracy: 0.8300\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8296 - val_loss: 0.4142 - val_accuracy: 0.8300\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8394 - val_loss: 0.4050 - val_accuracy: 0.8280\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8259 - val_loss: 0.4011 - val_accuracy: 0.8360\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8187 - val_loss: 0.4377 - val_accuracy: 0.8180\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8216 - val_loss: 0.4354 - val_accuracy: 0.8200\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8249 - val_loss: 0.4091 - val_accuracy: 0.8260\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8432 - val_loss: 0.3995 - val_accuracy: 0.8340\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.8118 - val_loss: 0.4014 - val_accuracy: 0.8320\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8357 - val_loss: 0.3990 - val_accuracy: 0.8320\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8086 - val_loss: 0.4008 - val_accuracy: 0.8340\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7955 - val_loss: 0.3985 - val_accuracy: 0.8380\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4170 - accuracy: 0.8282 - val_loss: 0.4178 - val_accuracy: 0.8280\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8056 - val_loss: 0.4572 - val_accuracy: 0.8140\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8391 - val_loss: 0.4269 - val_accuracy: 0.8280\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8172 - val_loss: 0.4029 - val_accuracy: 0.8300\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8437 - val_loss: 0.4024 - val_accuracy: 0.8300\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8061 - val_loss: 0.4199 - val_accuracy: 0.8340\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8319 - val_loss: 0.4176 - val_accuracy: 0.8240\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3709 - accuracy: 0.8509 - val_loss: 0.4067 - val_accuracy: 0.8280\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8517 - val_loss: 0.4527 - val_accuracy: 0.8140\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8328 - val_loss: 0.4021 - val_accuracy: 0.8300\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8309 - val_loss: 0.4030 - val_accuracy: 0.8360\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8279 - val_loss: 0.4053 - val_accuracy: 0.8300\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.7928 - val_loss: 0.4137 - val_accuracy: 0.8300\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8251 - val_loss: 0.4057 - val_accuracy: 0.8320\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7935 - val_loss: 0.5681 - val_accuracy: 0.7720\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.8181 - val_loss: 0.4098 - val_accuracy: 0.8240\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8211 - val_loss: 0.4084 - val_accuracy: 0.8300\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8267 - val_loss: 0.4239 - val_accuracy: 0.8280\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.8167 - val_loss: 0.4154 - val_accuracy: 0.8240\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.8146 - val_loss: 0.4358 - val_accuracy: 0.8220\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8281 - val_loss: 0.4249 - val_accuracy: 0.8280\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8209 - val_loss: 0.4330 - val_accuracy: 0.8260\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8311 - val_loss: 0.4100 - val_accuracy: 0.8320\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8216 - val_loss: 0.4087 - val_accuracy: 0.8300\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8248 - val_loss: 0.4022 - val_accuracy: 0.8300\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8423 - val_loss: 0.4044 - val_accuracy: 0.8220\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7978 - val_loss: 0.4172 - val_accuracy: 0.8260\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8374 - val_loss: 0.4057 - val_accuracy: 0.8200\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8547 - val_loss: 0.4363 - val_accuracy: 0.8320\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8296 - val_loss: 0.4037 - val_accuracy: 0.8320\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8474 - val_loss: 0.4256 - val_accuracy: 0.8180\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8114 - val_loss: 0.4082 - val_accuracy: 0.8220\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.8213 - val_loss: 0.4006 - val_accuracy: 0.8340\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8346 - val_loss: 0.4039 - val_accuracy: 0.8300\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8399 - val_loss: 0.4477 - val_accuracy: 0.8020\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4274 - accuracy: 0.8191 - val_loss: 0.4223 - val_accuracy: 0.8280\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8323 - val_loss: 0.4132 - val_accuracy: 0.8220\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.8163 - val_loss: 0.4157 - val_accuracy: 0.8280\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8231 - val_loss: 0.4070 - val_accuracy: 0.8320\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8301 - val_loss: 0.4161 - val_accuracy: 0.8220\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8172 - val_loss: 0.4101 - val_accuracy: 0.8240\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8307 - val_loss: 0.4317 - val_accuracy: 0.8220\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8366 - val_loss: 0.4203 - val_accuracy: 0.8200\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8563 - val_loss: 0.4182 - val_accuracy: 0.8220\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8441 - val_loss: 0.4043 - val_accuracy: 0.8280\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8317 - val_loss: 0.4038 - val_accuracy: 0.8300\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8269 - val_loss: 0.5029 - val_accuracy: 0.8040\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8259 - val_loss: 0.4037 - val_accuracy: 0.8340\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8488 - val_loss: 0.4058 - val_accuracy: 0.8280\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8422 - val_loss: 0.4238 - val_accuracy: 0.8260\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8302 - val_loss: 0.4175 - val_accuracy: 0.8280\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8441 - val_loss: 0.4264 - val_accuracy: 0.8200\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8356 - val_loss: 0.4164 - val_accuracy: 0.8200\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8192 - val_loss: 0.4051 - val_accuracy: 0.8300\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.8175 - val_loss: 0.4085 - val_accuracy: 0.8320\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8195 - val_loss: 0.4282 - val_accuracy: 0.8220\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8174 - val_loss: 0.4387 - val_accuracy: 0.8220\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8298 - val_loss: 0.4064 - val_accuracy: 0.8220\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3795 - accuracy: 0.8495 - val_loss: 0.4052 - val_accuracy: 0.8260\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8446 - val_loss: 0.4385 - val_accuracy: 0.8200\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8178 - val_loss: 0.4246 - val_accuracy: 0.8220\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8383 - val_loss: 0.4313 - val_accuracy: 0.8240\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8395 - val_loss: 0.4208 - val_accuracy: 0.8260\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8287 - val_loss: 0.4066 - val_accuracy: 0.8320\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.7938 - val_loss: 0.4899 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.8029 - val_loss: 0.4092 - val_accuracy: 0.8340\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8286 - val_loss: 0.4158 - val_accuracy: 0.8220\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8058 - val_loss: 0.4923 - val_accuracy: 0.7960\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8186 - val_loss: 0.4081 - val_accuracy: 0.8280\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8080 - val_loss: 0.4121 - val_accuracy: 0.8240\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8104 - val_loss: 0.4060 - val_accuracy: 0.8340\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8171 - val_loss: 0.4209 - val_accuracy: 0.8260\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8316 - val_loss: 0.4073 - val_accuracy: 0.8280\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8149 - val_loss: 0.4520 - val_accuracy: 0.8120\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8037 - val_loss: 0.4639 - val_accuracy: 0.8140\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.8039 - val_loss: 0.4263 - val_accuracy: 0.8240\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8289 - val_loss: 0.4229 - val_accuracy: 0.8280\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8287 - val_loss: 0.4447 - val_accuracy: 0.8260\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8512 - val_loss: 0.4235 - val_accuracy: 0.8240\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.8288 - val_loss: 0.4129 - val_accuracy: 0.8280\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8321 - val_loss: 0.4301 - val_accuracy: 0.8240\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8678 - val_loss: 0.4099 - val_accuracy: 0.8240\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8511 - val_loss: 0.4083 - val_accuracy: 0.8260\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8302 - val_loss: 0.4414 - val_accuracy: 0.8260\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8418 - val_loss: 0.4065 - val_accuracy: 0.8340\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8180 - val_loss: 0.4193 - val_accuracy: 0.8200\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8338 - val_loss: 0.4260 - val_accuracy: 0.8360\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4275 - accuracy: 0.8275 - val_loss: 0.4141 - val_accuracy: 0.8240\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8307 - val_loss: 0.4233 - val_accuracy: 0.8240\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8545 - val_loss: 0.4298 - val_accuracy: 0.8200\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8226 - val_loss: 0.4684 - val_accuracy: 0.8000\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.8254 - val_loss: 0.4219 - val_accuracy: 0.8220\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8048 - val_loss: 0.4093 - val_accuracy: 0.8260\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8401 - val_loss: 0.4178 - val_accuracy: 0.8220\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8420 - val_loss: 0.4321 - val_accuracy: 0.8180\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8350 - val_loss: 0.4099 - val_accuracy: 0.8240\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8409 - val_loss: 0.4270 - val_accuracy: 0.8240\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8536 - val_loss: 0.4131 - val_accuracy: 0.8220\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8290 - val_loss: 0.4236 - val_accuracy: 0.8260\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8338 - val_loss: 0.4115 - val_accuracy: 0.8200\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8594 - val_loss: 0.4162 - val_accuracy: 0.8220\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8537 - val_loss: 0.4178 - val_accuracy: 0.8220\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8244 - val_loss: 0.4168 - val_accuracy: 0.8220\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8245 - val_loss: 0.4144 - val_accuracy: 0.8240\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7979 - val_loss: 0.4117 - val_accuracy: 0.8280\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8034 - val_loss: 0.4251 - val_accuracy: 0.8260\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8256 - val_loss: 0.4287 - val_accuracy: 0.8220\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8209 - val_loss: 0.4193 - val_accuracy: 0.8280\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8087 - val_loss: 0.4144 - val_accuracy: 0.8260\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.0660 - accuracy: 0.3004 - val_loss: 2.2893 - val_accuracy: 0.4420\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.1879 - accuracy: 0.4858 - val_loss: 2.2758 - val_accuracy: 0.5540\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.0782 - accuracy: 0.5324 - val_loss: 1.7230 - val_accuracy: 0.5760\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2171 - accuracy: 0.4970 - val_loss: 2.4142 - val_accuracy: 0.5920\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.2163 - accuracy: 0.5764 - val_loss: 1.2504 - val_accuracy: 0.6440\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6504 - accuracy: 0.5707 - val_loss: 1.9166 - val_accuracy: 0.4980\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3448 - accuracy: 0.5701 - val_loss: 0.7621 - val_accuracy: 0.6180\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9108 - accuracy: 0.5841 - val_loss: 0.8500 - val_accuracy: 0.6660\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0107 - accuracy: 0.6068 - val_loss: 1.5614 - val_accuracy: 0.6500\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.5453 - accuracy: 0.6177 - val_loss: 1.5585 - val_accuracy: 0.5280\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7458 - accuracy: 0.5378 - val_loss: 1.4620 - val_accuracy: 0.6360\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.4534 - accuracy: 0.5933 - val_loss: 0.9786 - val_accuracy: 0.6740\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0663 - accuracy: 0.6546 - val_loss: 1.0696 - val_accuracy: 0.5900\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1179 - accuracy: 0.5607 - val_loss: 0.6626 - val_accuracy: 0.7040\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8416 - accuracy: 0.6191 - val_loss: 0.8187 - val_accuracy: 0.7200\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8238 - accuracy: 0.6714 - val_loss: 0.6434 - val_accuracy: 0.7160\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7305 - accuracy: 0.6683 - val_loss: 0.6252 - val_accuracy: 0.7680\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7784 - accuracy: 0.6635 - val_loss: 0.8273 - val_accuracy: 0.7020\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7933 - accuracy: 0.7064 - val_loss: 0.5664 - val_accuracy: 0.7660\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6416 - accuracy: 0.7223 - val_loss: 0.6469 - val_accuracy: 0.7120\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6062 - accuracy: 0.7407 - val_loss: 0.5429 - val_accuracy: 0.7760\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6151 - accuracy: 0.7359 - val_loss: 0.5815 - val_accuracy: 0.7480\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5851 - accuracy: 0.7430 - val_loss: 0.5497 - val_accuracy: 0.7440\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6040 - accuracy: 0.7078 - val_loss: 0.8403 - val_accuracy: 0.5320\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7735 - accuracy: 0.5990 - val_loss: 0.5301 - val_accuracy: 0.7840\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6646 - accuracy: 0.6862 - val_loss: 0.7438 - val_accuracy: 0.7160\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7764 - accuracy: 0.6827 - val_loss: 0.5248 - val_accuracy: 0.7720\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5695 - accuracy: 0.7155 - val_loss: 0.6114 - val_accuracy: 0.7200\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5541 - accuracy: 0.7581 - val_loss: 0.5054 - val_accuracy: 0.8060\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5239 - accuracy: 0.7864 - val_loss: 0.5047 - val_accuracy: 0.7880\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4995 - accuracy: 0.7885 - val_loss: 0.4950 - val_accuracy: 0.8100\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5110 - accuracy: 0.7760 - val_loss: 0.4867 - val_accuracy: 0.8140\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5166 - accuracy: 0.7747 - val_loss: 0.4921 - val_accuracy: 0.8200\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5098 - accuracy: 0.7867 - val_loss: 0.4896 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5253 - accuracy: 0.7647 - val_loss: 0.4922 - val_accuracy: 0.7940\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5011 - accuracy: 0.7792 - val_loss: 0.4739 - val_accuracy: 0.8240\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5041 - accuracy: 0.7722 - val_loss: 0.5870 - val_accuracy: 0.7360\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5559 - accuracy: 0.7160 - val_loss: 0.4924 - val_accuracy: 0.8180\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5329 - accuracy: 0.7678 - val_loss: 0.5046 - val_accuracy: 0.7840\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5485 - accuracy: 0.7577 - val_loss: 0.5944 - val_accuracy: 0.7400\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6378 - accuracy: 0.6894 - val_loss: 0.5239 - val_accuracy: 0.8040\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.7833 - val_loss: 0.4651 - val_accuracy: 0.8080\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5429 - accuracy: 0.7570 - val_loss: 0.5279 - val_accuracy: 0.7640\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6275 - accuracy: 0.7237 - val_loss: 0.5234 - val_accuracy: 0.7740\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5690 - accuracy: 0.7526 - val_loss: 0.4656 - val_accuracy: 0.8280\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4891 - accuracy: 0.7956 - val_loss: 0.4998 - val_accuracy: 0.8140\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5097 - accuracy: 0.7967 - val_loss: 0.5471 - val_accuracy: 0.7600\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5950 - accuracy: 0.7209 - val_loss: 0.4735 - val_accuracy: 0.7920\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5401 - accuracy: 0.7712 - val_loss: 0.5695 - val_accuracy: 0.7640\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4908 - accuracy: 0.8077 - val_loss: 0.4811 - val_accuracy: 0.7920\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5173 - accuracy: 0.7836 - val_loss: 0.4873 - val_accuracy: 0.7980\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5535 - accuracy: 0.7602 - val_loss: 0.6227 - val_accuracy: 0.7200\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5518 - accuracy: 0.7495 - val_loss: 0.4629 - val_accuracy: 0.8060\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.7836 - val_loss: 0.4563 - val_accuracy: 0.8020\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4794 - accuracy: 0.7921 - val_loss: 0.4393 - val_accuracy: 0.8320\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.7953 - val_loss: 0.5016 - val_accuracy: 0.8060\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5235 - accuracy: 0.7736 - val_loss: 0.5497 - val_accuracy: 0.7600\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5901 - accuracy: 0.7536 - val_loss: 0.4369 - val_accuracy: 0.8160\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5365 - accuracy: 0.7519 - val_loss: 0.4894 - val_accuracy: 0.8220\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7685 - val_loss: 0.4857 - val_accuracy: 0.7960\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5359 - accuracy: 0.7666 - val_loss: 0.4328 - val_accuracy: 0.8260\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5830 - accuracy: 0.7649 - val_loss: 0.5369 - val_accuracy: 0.7960\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5316 - accuracy: 0.7805 - val_loss: 0.4623 - val_accuracy: 0.8060\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5028 - accuracy: 0.7765 - val_loss: 0.4510 - val_accuracy: 0.8140\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4251 - accuracy: 0.8236 - val_loss: 0.4216 - val_accuracy: 0.8280\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4563 - accuracy: 0.8050 - val_loss: 0.4191 - val_accuracy: 0.8360\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4240 - accuracy: 0.8225 - val_loss: 0.4303 - val_accuracy: 0.8320\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4129 - accuracy: 0.8248 - val_loss: 0.4227 - val_accuracy: 0.8280\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4322 - accuracy: 0.8126 - val_loss: 0.4184 - val_accuracy: 0.8320\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.8210 - val_loss: 0.4159 - val_accuracy: 0.8400\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4281 - accuracy: 0.8241 - val_loss: 0.4150 - val_accuracy: 0.8340\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4319 - accuracy: 0.8084 - val_loss: 0.4172 - val_accuracy: 0.8320\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4322 - accuracy: 0.8220 - val_loss: 0.4243 - val_accuracy: 0.8340\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4153 - accuracy: 0.8251 - val_loss: 0.4205 - val_accuracy: 0.8300\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4545 - accuracy: 0.8032 - val_loss: 0.4167 - val_accuracy: 0.8300\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.8021 - val_loss: 0.4258 - val_accuracy: 0.8280\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4019 - accuracy: 0.8372 - val_loss: 0.4170 - val_accuracy: 0.8280\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4472 - accuracy: 0.7999 - val_loss: 0.4143 - val_accuracy: 0.8340\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4101 - accuracy: 0.8377 - val_loss: 0.4217 - val_accuracy: 0.8340\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4149 - accuracy: 0.8335 - val_loss: 0.4180 - val_accuracy: 0.8280\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4136 - accuracy: 0.8236 - val_loss: 0.4180 - val_accuracy: 0.8360\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.8273 - val_loss: 0.4104 - val_accuracy: 0.8380\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8122 - val_loss: 0.4111 - val_accuracy: 0.8320\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.4407 - val_accuracy: 0.8220\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4289 - accuracy: 0.8257 - val_loss: 0.4167 - val_accuracy: 0.8320\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.8328 - val_loss: 0.4420 - val_accuracy: 0.8240\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4121 - accuracy: 0.8377 - val_loss: 0.4088 - val_accuracy: 0.8420\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4323 - accuracy: 0.8055 - val_loss: 0.4083 - val_accuracy: 0.8340\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4147 - accuracy: 0.8226 - val_loss: 0.4142 - val_accuracy: 0.8300\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4152 - accuracy: 0.8333 - val_loss: 0.4134 - val_accuracy: 0.8300\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4277 - accuracy: 0.8170 - val_loss: 0.4108 - val_accuracy: 0.8320\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4332 - accuracy: 0.8129 - val_loss: 0.4539 - val_accuracy: 0.8180\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4309 - accuracy: 0.8060 - val_loss: 0.4108 - val_accuracy: 0.8320\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4209 - accuracy: 0.8254 - val_loss: 0.4084 - val_accuracy: 0.8360\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.8291 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4060 - accuracy: 0.8152 - val_loss: 0.4212 - val_accuracy: 0.8280\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4358 - accuracy: 0.8202 - val_loss: 0.4075 - val_accuracy: 0.8380\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4255 - accuracy: 0.8181 - val_loss: 0.4179 - val_accuracy: 0.8280\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3881 - accuracy: 0.8456 - val_loss: 0.4099 - val_accuracy: 0.8300\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4005 - accuracy: 0.8366 - val_loss: 0.4204 - val_accuracy: 0.8280\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4009 - accuracy: 0.8364 - val_loss: 0.4044 - val_accuracy: 0.8360\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4200 - accuracy: 0.8244 - val_loss: 0.4074 - val_accuracy: 0.8320\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3956 - accuracy: 0.8307 - val_loss: 0.4104 - val_accuracy: 0.8280\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4228 - accuracy: 0.8221 - val_loss: 0.4062 - val_accuracy: 0.8380\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4204 - accuracy: 0.8185 - val_loss: 0.4322 - val_accuracy: 0.8260\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.8100 - val_loss: 0.4132 - val_accuracy: 0.8340\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4248 - accuracy: 0.8181 - val_loss: 0.4097 - val_accuracy: 0.8320\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4367 - accuracy: 0.8296 - val_loss: 0.4405 - val_accuracy: 0.8240\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4191 - accuracy: 0.8144 - val_loss: 0.4032 - val_accuracy: 0.8360\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4033 - accuracy: 0.8335 - val_loss: 0.4057 - val_accuracy: 0.8320\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4348 - accuracy: 0.8074 - val_loss: 0.4528 - val_accuracy: 0.8160\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4384 - accuracy: 0.8149 - val_loss: 0.4080 - val_accuracy: 0.8380\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4032 - accuracy: 0.8279 - val_loss: 0.4445 - val_accuracy: 0.8220\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4052 - accuracy: 0.8343 - val_loss: 0.4036 - val_accuracy: 0.8360\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4135 - accuracy: 0.8118 - val_loss: 0.4087 - val_accuracy: 0.8280\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3899 - accuracy: 0.8450 - val_loss: 0.4100 - val_accuracy: 0.8260\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3884 - accuracy: 0.8537 - val_loss: 0.4010 - val_accuracy: 0.8380\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4368 - accuracy: 0.7991 - val_loss: 0.4247 - val_accuracy: 0.8320\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4177 - accuracy: 0.8321 - val_loss: 0.4037 - val_accuracy: 0.8320\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.8356 - val_loss: 0.4392 - val_accuracy: 0.8200\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4204 - accuracy: 0.8244 - val_loss: 0.4263 - val_accuracy: 0.8200\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.8194 - val_loss: 0.5458 - val_accuracy: 0.7700\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4843 - accuracy: 0.7826 - val_loss: 0.4635 - val_accuracy: 0.8020\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4772 - accuracy: 0.7947 - val_loss: 0.4443 - val_accuracy: 0.8180\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4213 - accuracy: 0.8277 - val_loss: 0.4082 - val_accuracy: 0.8340\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4372 - accuracy: 0.8302 - val_loss: 0.4570 - val_accuracy: 0.8060\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5074 - accuracy: 0.7946 - val_loss: 0.5274 - val_accuracy: 0.7720\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5070 - accuracy: 0.7836 - val_loss: 0.5150 - val_accuracy: 0.7780\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5063 - accuracy: 0.7919 - val_loss: 0.6223 - val_accuracy: 0.7340\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4916 - accuracy: 0.7995 - val_loss: 0.4658 - val_accuracy: 0.8080\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5159 - accuracy: 0.7829 - val_loss: 0.4395 - val_accuracy: 0.8260\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4151 - accuracy: 0.8036 - val_loss: 0.4022 - val_accuracy: 0.8260\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8290 - val_loss: 0.4136 - val_accuracy: 0.8220\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8298 - val_loss: 0.4102 - val_accuracy: 0.8280\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3858 - accuracy: 0.8429 - val_loss: 0.4158 - val_accuracy: 0.8300\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3748 - accuracy: 0.8343 - val_loss: 0.4015 - val_accuracy: 0.8300\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4092 - accuracy: 0.8297 - val_loss: 0.3997 - val_accuracy: 0.8320\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.8377 - val_loss: 0.4306 - val_accuracy: 0.8200\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.8477 - val_loss: 0.4093 - val_accuracy: 0.8340\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3912 - accuracy: 0.8422 - val_loss: 0.4439 - val_accuracy: 0.8260\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4194 - accuracy: 0.8246 - val_loss: 0.4004 - val_accuracy: 0.8360\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.8338 - val_loss: 0.4263 - val_accuracy: 0.8240\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3970 - accuracy: 0.8306 - val_loss: 0.4019 - val_accuracy: 0.8240\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8210 - val_loss: 0.4138 - val_accuracy: 0.8300\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.8247 - val_loss: 0.4064 - val_accuracy: 0.8280\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.8242 - val_loss: 0.4031 - val_accuracy: 0.8300\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4227 - accuracy: 0.8077 - val_loss: 0.4147 - val_accuracy: 0.8260\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3891 - accuracy: 0.8346 - val_loss: 0.4040 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3859 - accuracy: 0.8305 - val_loss: 0.4062 - val_accuracy: 0.8280\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.8377 - val_loss: 0.4156 - val_accuracy: 0.8280\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3644 - accuracy: 0.8416 - val_loss: 0.4060 - val_accuracy: 0.8300\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3908 - accuracy: 0.8221 - val_loss: 0.4116 - val_accuracy: 0.8300\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4083 - accuracy: 0.8409 - val_loss: 0.4097 - val_accuracy: 0.8240\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3740 - accuracy: 0.8426 - val_loss: 0.4037 - val_accuracy: 0.8340\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4020 - accuracy: 0.8215 - val_loss: 0.4411 - val_accuracy: 0.8160\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.8178 - val_loss: 0.4015 - val_accuracy: 0.8320\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3961 - accuracy: 0.8334 - val_loss: 0.4172 - val_accuracy: 0.8280\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.8161 - val_loss: 0.4035 - val_accuracy: 0.8300\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.8122 - val_loss: 0.4222 - val_accuracy: 0.8300\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4017 - accuracy: 0.8299 - val_loss: 0.4052 - val_accuracy: 0.8340\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.8005 - val_loss: 0.4338 - val_accuracy: 0.8220\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3873 - accuracy: 0.8215 - val_loss: 0.4047 - val_accuracy: 0.8300\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8314 - val_loss: 0.4278 - val_accuracy: 0.8280\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4012 - accuracy: 0.8260 - val_loss: 0.4030 - val_accuracy: 0.8280\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.8064 - val_loss: 0.4537 - val_accuracy: 0.8100\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4284 - accuracy: 0.8226 - val_loss: 0.4020 - val_accuracy: 0.8320\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4066 - accuracy: 0.8215 - val_loss: 0.4414 - val_accuracy: 0.8180\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4064 - accuracy: 0.8454 - val_loss: 0.4086 - val_accuracy: 0.8320\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3984 - accuracy: 0.8199 - val_loss: 0.4663 - val_accuracy: 0.8120\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4143 - accuracy: 0.8348 - val_loss: 0.4058 - val_accuracy: 0.8280\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8197 - val_loss: 0.4260 - val_accuracy: 0.8200\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3888 - accuracy: 0.8348 - val_loss: 0.4058 - val_accuracy: 0.8200\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8544 - val_loss: 0.4054 - val_accuracy: 0.8240\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3901 - accuracy: 0.8377 - val_loss: 0.4180 - val_accuracy: 0.8300\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3781 - accuracy: 0.8440 - val_loss: 0.4067 - val_accuracy: 0.8180\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3647 - accuracy: 0.8335 - val_loss: 0.4031 - val_accuracy: 0.8240\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3843 - accuracy: 0.8328 - val_loss: 0.4181 - val_accuracy: 0.8240\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3713 - accuracy: 0.8419 - val_loss: 0.4024 - val_accuracy: 0.8300\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4077 - accuracy: 0.8203 - val_loss: 0.4205 - val_accuracy: 0.8220\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4039 - accuracy: 0.8394 - val_loss: 0.4063 - val_accuracy: 0.8200\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4012 - accuracy: 0.8322 - val_loss: 0.4076 - val_accuracy: 0.8280\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.8117 - val_loss: 0.4755 - val_accuracy: 0.8020\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4374 - accuracy: 0.8107 - val_loss: 0.4155 - val_accuracy: 0.8260\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4025 - accuracy: 0.8299 - val_loss: 0.4677 - val_accuracy: 0.8080\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4207 - accuracy: 0.8255 - val_loss: 0.4062 - val_accuracy: 0.8360\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3822 - accuracy: 0.8158 - val_loss: 0.4306 - val_accuracy: 0.8280\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3898 - accuracy: 0.8461 - val_loss: 0.4048 - val_accuracy: 0.8260\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3796 - accuracy: 0.8422 - val_loss: 0.4110 - val_accuracy: 0.8220\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3757 - accuracy: 0.8508 - val_loss: 0.4042 - val_accuracy: 0.8240\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3917 - accuracy: 0.8369 - val_loss: 0.4218 - val_accuracy: 0.8300\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.8352 - val_loss: 0.4086 - val_accuracy: 0.8200\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3720 - accuracy: 0.8382 - val_loss: 0.4135 - val_accuracy: 0.8260\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3706 - accuracy: 0.8438 - val_loss: 0.4066 - val_accuracy: 0.8220\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.8211 - val_loss: 0.4113 - val_accuracy: 0.8220\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.8391 - val_loss: 0.4052 - val_accuracy: 0.8220\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4186 - accuracy: 0.8177 - val_loss: 0.4081 - val_accuracy: 0.8220\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3853 - accuracy: 0.8409 - val_loss: 0.4085 - val_accuracy: 0.8260\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.8330 - val_loss: 0.4130 - val_accuracy: 0.8300\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4093 - accuracy: 0.8328 - val_loss: 0.4082 - val_accuracy: 0.8200\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4108 - accuracy: 0.8114 - val_loss: 0.4087 - val_accuracy: 0.8240\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 4.7522 - accuracy: 0.2664 - val_loss: 3.4063 - val_accuracy: 0.3500\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.1288 - accuracy: 0.3717 - val_loss: 3.6186 - val_accuracy: 0.3000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.2691 - accuracy: 0.3481 - val_loss: 3.3088 - val_accuracy: 0.4380\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.3506 - accuracy: 0.4617 - val_loss: 1.7876 - val_accuracy: 0.6660\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.4666 - accuracy: 0.5578 - val_loss: 1.7871 - val_accuracy: 0.6380\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.1537 - accuracy: 0.5754 - val_loss: 2.0285 - val_accuracy: 0.6180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.9850 - accuracy: 0.5979 - val_loss: 2.8608 - val_accuracy: 0.5220\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.4529 - accuracy: 0.5466 - val_loss: 1.9104 - val_accuracy: 0.6200\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.1653 - accuracy: 0.5887 - val_loss: 1.6244 - val_accuracy: 0.6420\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6564 - accuracy: 0.6166 - val_loss: 1.8755 - val_accuracy: 0.5260\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7175 - accuracy: 0.5439 - val_loss: 1.5898 - val_accuracy: 0.6560\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7342 - accuracy: 0.6047 - val_loss: 1.0541 - val_accuracy: 0.6920\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2655 - accuracy: 0.6174 - val_loss: 0.9287 - val_accuracy: 0.7080\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0388 - accuracy: 0.6718 - val_loss: 1.0009 - val_accuracy: 0.6780\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1167 - accuracy: 0.6470 - val_loss: 0.9347 - val_accuracy: 0.6800\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0533 - accuracy: 0.6401 - val_loss: 0.9089 - val_accuracy: 0.6400\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.9427 - accuracy: 0.6217 - val_loss: 0.7386 - val_accuracy: 0.6940\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8800 - accuracy: 0.6230 - val_loss: 0.7634 - val_accuracy: 0.6960\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8809 - accuracy: 0.6282 - val_loss: 0.7386 - val_accuracy: 0.6860\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8210 - accuracy: 0.6561 - val_loss: 0.7203 - val_accuracy: 0.7520\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7444 - accuracy: 0.6864 - val_loss: 0.7005 - val_accuracy: 0.7220\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7961 - accuracy: 0.6668 - val_loss: 0.6664 - val_accuracy: 0.7240\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7195 - accuracy: 0.7011 - val_loss: 0.6797 - val_accuracy: 0.7180\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7373 - accuracy: 0.7048 - val_loss: 0.6700 - val_accuracy: 0.6920\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7007 - accuracy: 0.6574 - val_loss: 0.6536 - val_accuracy: 0.7260\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6483 - accuracy: 0.7183 - val_loss: 0.6300 - val_accuracy: 0.7360\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.6836 - accuracy: 0.6761 - val_loss: 0.5982 - val_accuracy: 0.7480\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6229 - accuracy: 0.7303 - val_loss: 0.5839 - val_accuracy: 0.7320\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6076 - accuracy: 0.6996 - val_loss: 0.5913 - val_accuracy: 0.7140\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6224 - accuracy: 0.6957 - val_loss: 0.5775 - val_accuracy: 0.7440\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5975 - accuracy: 0.7273 - val_loss: 0.5763 - val_accuracy: 0.7660\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5992 - accuracy: 0.7395 - val_loss: 0.5722 - val_accuracy: 0.7660\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5856 - accuracy: 0.7248 - val_loss: 0.5662 - val_accuracy: 0.7640\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5991 - accuracy: 0.7290 - val_loss: 0.5708 - val_accuracy: 0.7380\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5920 - accuracy: 0.7063 - val_loss: 0.5641 - val_accuracy: 0.7780\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5581 - accuracy: 0.7565 - val_loss: 0.5640 - val_accuracy: 0.7640\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5709 - accuracy: 0.7485 - val_loss: 0.5707 - val_accuracy: 0.7980\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5739 - accuracy: 0.7816 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5751 - accuracy: 0.7050 - val_loss: 0.5771 - val_accuracy: 0.7980\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5867 - accuracy: 0.7619 - val_loss: 0.5822 - val_accuracy: 0.7400\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6193 - accuracy: 0.6813 - val_loss: 0.5821 - val_accuracy: 0.8260\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5911 - accuracy: 0.7857 - val_loss: 0.5878 - val_accuracy: 0.7400\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6212 - accuracy: 0.6957 - val_loss: 0.5594 - val_accuracy: 0.8100\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6077 - accuracy: 0.7580 - val_loss: 0.6139 - val_accuracy: 0.7160\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6613 - accuracy: 0.6772 - val_loss: 0.5380 - val_accuracy: 0.7840\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5789 - accuracy: 0.7485 - val_loss: 0.5525 - val_accuracy: 0.7520\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6031 - accuracy: 0.7116 - val_loss: 0.5348 - val_accuracy: 0.7820\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6093 - accuracy: 0.7129 - val_loss: 0.5664 - val_accuracy: 0.7380\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.6161 - accuracy: 0.6957 - val_loss: 0.5281 - val_accuracy: 0.7820\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6284 - accuracy: 0.6711 - val_loss: 0.6001 - val_accuracy: 0.7240\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7098 - accuracy: 0.6852 - val_loss: 0.5756 - val_accuracy: 0.7420\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6540 - accuracy: 0.6784 - val_loss: 0.5234 - val_accuracy: 0.7980\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5744 - accuracy: 0.7471 - val_loss: 0.5363 - val_accuracy: 0.7600\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5652 - accuracy: 0.7447 - val_loss: 0.5430 - val_accuracy: 0.8200\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5411 - accuracy: 0.7697 - val_loss: 0.5451 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5555 - accuracy: 0.7421 - val_loss: 0.6266 - val_accuracy: 0.7640\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6060 - accuracy: 0.7553 - val_loss: 0.5732 - val_accuracy: 0.7480\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6020 - accuracy: 0.7277 - val_loss: 0.6028 - val_accuracy: 0.7880\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5959 - accuracy: 0.7700 - val_loss: 0.5358 - val_accuracy: 0.7520\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5580 - accuracy: 0.7249 - val_loss: 0.5794 - val_accuracy: 0.8100\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5788 - accuracy: 0.7712 - val_loss: 0.5259 - val_accuracy: 0.7560\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5629 - accuracy: 0.7475 - val_loss: 0.5367 - val_accuracy: 0.8300\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5487 - accuracy: 0.7911 - val_loss: 0.5130 - val_accuracy: 0.7760\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5520 - accuracy: 0.7619 - val_loss: 0.5068 - val_accuracy: 0.8240\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5356 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7920\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5452 - accuracy: 0.7474 - val_loss: 0.4994 - val_accuracy: 0.8080\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5234 - accuracy: 0.7871 - val_loss: 0.5023 - val_accuracy: 0.8260\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4966 - accuracy: 0.7987 - val_loss: 0.4976 - val_accuracy: 0.7960\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5326 - accuracy: 0.7740 - val_loss: 0.5040 - val_accuracy: 0.8240\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5059 - accuracy: 0.7884 - val_loss: 0.4960 - val_accuracy: 0.7920\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5156 - accuracy: 0.7765 - val_loss: 0.5024 - val_accuracy: 0.8260\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5116 - accuracy: 0.7976 - val_loss: 0.4905 - val_accuracy: 0.8040\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5094 - accuracy: 0.7805 - val_loss: 0.4959 - val_accuracy: 0.8300\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5040 - accuracy: 0.7976 - val_loss: 0.4886 - val_accuracy: 0.8040\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5159 - accuracy: 0.7753 - val_loss: 0.4890 - val_accuracy: 0.8260\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5136 - accuracy: 0.7977 - val_loss: 0.4841 - val_accuracy: 0.8140\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4804 - accuracy: 0.7974 - val_loss: 0.4842 - val_accuracy: 0.8180\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5030 - accuracy: 0.7871 - val_loss: 0.4822 - val_accuracy: 0.8200\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4900 - accuracy: 0.8015 - val_loss: 0.4820 - val_accuracy: 0.8280\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4935 - accuracy: 0.8068 - val_loss: 0.4817 - val_accuracy: 0.8260\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4856 - accuracy: 0.7843 - val_loss: 0.4788 - val_accuracy: 0.8240\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4913 - accuracy: 0.7845 - val_loss: 0.4776 - val_accuracy: 0.8260\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5039 - accuracy: 0.7872 - val_loss: 0.4749 - val_accuracy: 0.8160\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4835 - accuracy: 0.7990 - val_loss: 0.4895 - val_accuracy: 0.8300\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4909 - accuracy: 0.8002 - val_loss: 0.4740 - val_accuracy: 0.8100\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4775 - accuracy: 0.7975 - val_loss: 0.4907 - val_accuracy: 0.8300\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4919 - accuracy: 0.8081 - val_loss: 0.4711 - val_accuracy: 0.8160\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4867 - accuracy: 0.7871 - val_loss: 0.4761 - val_accuracy: 0.8300\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4894 - accuracy: 0.7963 - val_loss: 0.4680 - val_accuracy: 0.8140\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4831 - accuracy: 0.7897 - val_loss: 0.4675 - val_accuracy: 0.8260\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5126 - accuracy: 0.7780 - val_loss: 0.4659 - val_accuracy: 0.8140\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4964 - accuracy: 0.7804 - val_loss: 0.4639 - val_accuracy: 0.8240\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4783 - accuracy: 0.8095 - val_loss: 0.4753 - val_accuracy: 0.8340\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4786 - accuracy: 0.8054 - val_loss: 0.4626 - val_accuracy: 0.8120\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4744 - accuracy: 0.8108 - val_loss: 0.4736 - val_accuracy: 0.8300\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4829 - accuracy: 0.7977 - val_loss: 0.4603 - val_accuracy: 0.8160\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4819 - accuracy: 0.8003 - val_loss: 0.4711 - val_accuracy: 0.8320\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4909 - accuracy: 0.7939 - val_loss: 0.4583 - val_accuracy: 0.8160\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4662 - accuracy: 0.8107 - val_loss: 0.4701 - val_accuracy: 0.8340\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4679 - accuracy: 0.8014 - val_loss: 0.4607 - val_accuracy: 0.8320\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4604 - accuracy: 0.8121 - val_loss: 0.4558 - val_accuracy: 0.8260\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4717 - accuracy: 0.8056 - val_loss: 0.4548 - val_accuracy: 0.8260\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4666 - accuracy: 0.8043 - val_loss: 0.4568 - val_accuracy: 0.8320\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4854 - accuracy: 0.8017 - val_loss: 0.4531 - val_accuracy: 0.8160\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4696 - accuracy: 0.8055 - val_loss: 0.4553 - val_accuracy: 0.8300\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4736 - accuracy: 0.8097 - val_loss: 0.4565 - val_accuracy: 0.8320\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4630 - accuracy: 0.8200 - val_loss: 0.4503 - val_accuracy: 0.8340\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4646 - accuracy: 0.8188 - val_loss: 0.4530 - val_accuracy: 0.8320\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4537 - accuracy: 0.8187 - val_loss: 0.4477 - val_accuracy: 0.8280\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4720 - accuracy: 0.8069 - val_loss: 0.4483 - val_accuracy: 0.8340\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4651 - accuracy: 0.7950 - val_loss: 0.4461 - val_accuracy: 0.8280\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4632 - accuracy: 0.8201 - val_loss: 0.4591 - val_accuracy: 0.8320\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4613 - accuracy: 0.8120 - val_loss: 0.4448 - val_accuracy: 0.8240\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4564 - accuracy: 0.8161 - val_loss: 0.4521 - val_accuracy: 0.8320\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4445 - accuracy: 0.8266 - val_loss: 0.4451 - val_accuracy: 0.8180\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4500 - accuracy: 0.8107 - val_loss: 0.4577 - val_accuracy: 0.8280\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4409 - accuracy: 0.8266 - val_loss: 0.4409 - val_accuracy: 0.8320\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4761 - accuracy: 0.7925 - val_loss: 0.4439 - val_accuracy: 0.8320\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4526 - accuracy: 0.8267 - val_loss: 0.4417 - val_accuracy: 0.8360\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4572 - accuracy: 0.8173 - val_loss: 0.4384 - val_accuracy: 0.8300\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4718 - accuracy: 0.8017 - val_loss: 0.4380 - val_accuracy: 0.8340\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4506 - accuracy: 0.8094 - val_loss: 0.4372 - val_accuracy: 0.8300\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4454 - accuracy: 0.8095 - val_loss: 0.4541 - val_accuracy: 0.8300\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4633 - accuracy: 0.8149 - val_loss: 0.4422 - val_accuracy: 0.8120\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4623 - accuracy: 0.8017 - val_loss: 0.4668 - val_accuracy: 0.8240\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4589 - accuracy: 0.8266 - val_loss: 0.4595 - val_accuracy: 0.8020\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.5035 - accuracy: 0.7790 - val_loss: 0.4337 - val_accuracy: 0.8300\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4752 - accuracy: 0.7963 - val_loss: 0.4381 - val_accuracy: 0.8320\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4805 - accuracy: 0.7842 - val_loss: 0.4464 - val_accuracy: 0.8100\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4732 - accuracy: 0.7910 - val_loss: 0.4760 - val_accuracy: 0.8180\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4436 - accuracy: 0.8333 - val_loss: 0.4493 - val_accuracy: 0.8140\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4893 - accuracy: 0.7766 - val_loss: 0.4432 - val_accuracy: 0.8340\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4422 - accuracy: 0.8201 - val_loss: 0.4347 - val_accuracy: 0.8360\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4378 - accuracy: 0.8227 - val_loss: 0.4293 - val_accuracy: 0.8260\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4281 - accuracy: 0.8240 - val_loss: 0.4542 - val_accuracy: 0.8260\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4337 - accuracy: 0.8213 - val_loss: 0.4281 - val_accuracy: 0.8280\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4606 - accuracy: 0.8044 - val_loss: 0.4317 - val_accuracy: 0.8320\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4326 - accuracy: 0.8294 - val_loss: 0.4308 - val_accuracy: 0.8320\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4284 - accuracy: 0.8241 - val_loss: 0.4262 - val_accuracy: 0.8340\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4174 - accuracy: 0.8319 - val_loss: 0.4349 - val_accuracy: 0.8340\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4301 - accuracy: 0.8293 - val_loss: 0.4281 - val_accuracy: 0.8320\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4241 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8320\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4291 - accuracy: 0.8305 - val_loss: 0.4294 - val_accuracy: 0.8340\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4346 - accuracy: 0.8241 - val_loss: 0.4318 - val_accuracy: 0.8340\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4303 - accuracy: 0.8202 - val_loss: 0.4233 - val_accuracy: 0.8340\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4422 - accuracy: 0.8175 - val_loss: 0.4246 - val_accuracy: 0.8320\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4394 - accuracy: 0.8189 - val_loss: 0.4253 - val_accuracy: 0.8320\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4269 - accuracy: 0.8267 - val_loss: 0.4247 - val_accuracy: 0.8360\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4217 - accuracy: 0.8293 - val_loss: 0.4241 - val_accuracy: 0.8300\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4277 - accuracy: 0.8240 - val_loss: 0.4228 - val_accuracy: 0.8300\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4102 - accuracy: 0.8398 - val_loss: 0.4305 - val_accuracy: 0.8320\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4247 - accuracy: 0.8294 - val_loss: 0.4208 - val_accuracy: 0.8320\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4350 - accuracy: 0.8227 - val_loss: 0.4332 - val_accuracy: 0.8300\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4235 - accuracy: 0.8280 - val_loss: 0.4189 - val_accuracy: 0.8380\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4279 - accuracy: 0.8188 - val_loss: 0.4196 - val_accuracy: 0.8320\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4301 - accuracy: 0.8268 - val_loss: 0.4357 - val_accuracy: 0.8300\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4361 - accuracy: 0.8136 - val_loss: 0.4174 - val_accuracy: 0.8340\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4410 - accuracy: 0.8177 - val_loss: 0.4232 - val_accuracy: 0.8340\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4200 - accuracy: 0.8253 - val_loss: 0.4178 - val_accuracy: 0.8320\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4244 - accuracy: 0.8121 - val_loss: 0.4239 - val_accuracy: 0.8380\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4238 - accuracy: 0.8149 - val_loss: 0.4166 - val_accuracy: 0.8300\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4332 - accuracy: 0.8241 - val_loss: 0.4192 - val_accuracy: 0.8260\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4137 - accuracy: 0.8306 - val_loss: 0.4157 - val_accuracy: 0.8320\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4318 - accuracy: 0.8149 - val_loss: 0.4230 - val_accuracy: 0.8320\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4279 - accuracy: 0.8122 - val_loss: 0.4144 - val_accuracy: 0.8340\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4264 - accuracy: 0.8162 - val_loss: 0.4285 - val_accuracy: 0.8320\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4273 - accuracy: 0.8334 - val_loss: 0.4149 - val_accuracy: 0.8300\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4330 - accuracy: 0.8255 - val_loss: 0.4167 - val_accuracy: 0.8280\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4140 - accuracy: 0.8346 - val_loss: 0.4168 - val_accuracy: 0.8260\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4274 - accuracy: 0.8268 - val_loss: 0.4205 - val_accuracy: 0.8260\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4215 - accuracy: 0.8280 - val_loss: 0.4137 - val_accuracy: 0.8300\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4149 - accuracy: 0.8266 - val_loss: 0.4150 - val_accuracy: 0.8300\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4032 - accuracy: 0.8318 - val_loss: 0.4175 - val_accuracy: 0.8340\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4149 - accuracy: 0.8241 - val_loss: 0.4116 - val_accuracy: 0.8380\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4008 - accuracy: 0.8358 - val_loss: 0.4256 - val_accuracy: 0.8240\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4062 - accuracy: 0.8320 - val_loss: 0.4119 - val_accuracy: 0.8320\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.4154 - accuracy: 0.8201 - val_loss: 0.4123 - val_accuracy: 0.8280\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4023 - accuracy: 0.8451 - val_loss: 0.4268 - val_accuracy: 0.8320\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4189 - accuracy: 0.8399 - val_loss: 0.4106 - val_accuracy: 0.8300\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4134 - accuracy: 0.8201 - val_loss: 0.4257 - val_accuracy: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4121 - accuracy: 0.8345 - val_loss: 0.4103 - val_accuracy: 0.8260\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4300 - accuracy: 0.8133 - val_loss: 0.4098 - val_accuracy: 0.8360\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4138 - accuracy: 0.8293 - val_loss: 0.4536 - val_accuracy: 0.8200\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4372 - accuracy: 0.8307 - val_loss: 0.4096 - val_accuracy: 0.8320\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4157 - accuracy: 0.8162 - val_loss: 0.4252 - val_accuracy: 0.8300\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4029 - accuracy: 0.8397 - val_loss: 0.4094 - val_accuracy: 0.8280\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4074 - accuracy: 0.8319 - val_loss: 0.4077 - val_accuracy: 0.8320\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4063 - accuracy: 0.8346 - val_loss: 0.4247 - val_accuracy: 0.8240\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4059 - accuracy: 0.8438 - val_loss: 0.4075 - val_accuracy: 0.8360\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4182 - accuracy: 0.8240 - val_loss: 0.4193 - val_accuracy: 0.8260\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4096 - accuracy: 0.8346 - val_loss: 0.4164 - val_accuracy: 0.8260\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4013 - accuracy: 0.8372 - val_loss: 0.4072 - val_accuracy: 0.8320\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3973 - accuracy: 0.8306 - val_loss: 0.4141 - val_accuracy: 0.8300\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4048 - accuracy: 0.8333 - val_loss: 0.4082 - val_accuracy: 0.8260\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4104 - accuracy: 0.8215 - val_loss: 0.4104 - val_accuracy: 0.8260\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4343 - accuracy: 0.8124 - val_loss: 0.4108 - val_accuracy: 0.8320\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4136 - accuracy: 0.8201 - val_loss: 0.4058 - val_accuracy: 0.8360\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4059 - accuracy: 0.8359 - val_loss: 0.4341 - val_accuracy: 0.8200\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.4303 - accuracy: 0.8268 - val_loss: 0.4056 - val_accuracy: 0.8320\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4215 - accuracy: 0.8163 - val_loss: 0.4071 - val_accuracy: 0.8300\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 4.5299 - accuracy: 0.2065 - val_loss: 2.7560 - val_accuracy: 0.4780\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.9705 - accuracy: 0.4787 - val_loss: 2.9230 - val_accuracy: 0.4760\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.0949 - accuracy: 0.4607 - val_loss: 1.7306 - val_accuracy: 0.4880\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7345 - accuracy: 0.4633 - val_loss: 1.3708 - val_accuracy: 0.6380\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5199 - accuracy: 0.5964 - val_loss: 2.2379 - val_accuracy: 0.5900\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.4556 - accuracy: 0.5564 - val_loss: 1.2278 - val_accuracy: 0.6840\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4015 - accuracy: 0.6127 - val_loss: 1.2409 - val_accuracy: 0.6820\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3031 - accuracy: 0.6199 - val_loss: 1.5747 - val_accuracy: 0.6380\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7496 - accuracy: 0.6117 - val_loss: 1.0913 - val_accuracy: 0.6700\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1569 - accuracy: 0.6480 - val_loss: 2.2556 - val_accuracy: 0.5160\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.1707 - accuracy: 0.5052 - val_loss: 1.1407 - val_accuracy: 0.6720\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3128 - accuracy: 0.6302 - val_loss: 1.1518 - val_accuracy: 0.6560\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.3262 - accuracy: 0.6160 - val_loss: 1.0844 - val_accuracy: 0.5940\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0754 - accuracy: 0.5950 - val_loss: 0.8081 - val_accuracy: 0.6460\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8315 - accuracy: 0.6692 - val_loss: 0.7849 - val_accuracy: 0.7120\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.8764 - accuracy: 0.6647 - val_loss: 0.7147 - val_accuracy: 0.7140\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7825 - accuracy: 0.6745 - val_loss: 0.7824 - val_accuracy: 0.6860\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.8847 - accuracy: 0.6490 - val_loss: 0.9154 - val_accuracy: 0.6760\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9978 - accuracy: 0.6479 - val_loss: 1.0680 - val_accuracy: 0.5840\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0709 - accuracy: 0.5775 - val_loss: 0.6549 - val_accuracy: 0.7300\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6924 - accuracy: 0.6953 - val_loss: 0.6787 - val_accuracy: 0.6960\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7205 - accuracy: 0.6496 - val_loss: 0.8055 - val_accuracy: 0.6460\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7890 - accuracy: 0.6579 - val_loss: 0.6643 - val_accuracy: 0.7340\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6985 - accuracy: 0.6861 - val_loss: 0.6977 - val_accuracy: 0.7220\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6981 - accuracy: 0.7261 - val_loss: 0.6295 - val_accuracy: 0.7280\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6433 - accuracy: 0.6803 - val_loss: 0.6711 - val_accuracy: 0.6920\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7032 - accuracy: 0.6641 - val_loss: 0.6570 - val_accuracy: 0.7300\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6571 - accuracy: 0.7071 - val_loss: 0.5909 - val_accuracy: 0.7520\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6024 - accuracy: 0.7296 - val_loss: 0.5996 - val_accuracy: 0.7540\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6131 - accuracy: 0.7372 - val_loss: 0.6097 - val_accuracy: 0.8080\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6166 - accuracy: 0.7721 - val_loss: 0.5852 - val_accuracy: 0.7800\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5887 - accuracy: 0.7481 - val_loss: 0.5992 - val_accuracy: 0.7300\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6066 - accuracy: 0.6910 - val_loss: 0.6755 - val_accuracy: 0.7020\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6475 - accuracy: 0.7065 - val_loss: 0.6339 - val_accuracy: 0.7300\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6541 - accuracy: 0.7036 - val_loss: 0.5777 - val_accuracy: 0.7880\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5733 - accuracy: 0.7698 - val_loss: 0.5711 - val_accuracy: 0.7840\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5663 - accuracy: 0.7520 - val_loss: 0.5763 - val_accuracy: 0.7480\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5838 - accuracy: 0.7308 - val_loss: 0.7120 - val_accuracy: 0.6520\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6879 - accuracy: 0.6307 - val_loss: 0.6790 - val_accuracy: 0.7100\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7269 - accuracy: 0.6542 - val_loss: 0.5579 - val_accuracy: 0.7840\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5666 - accuracy: 0.7474 - val_loss: 0.5878 - val_accuracy: 0.7460\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6056 - accuracy: 0.7185 - val_loss: 0.6272 - val_accuracy: 0.7260\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6500 - accuracy: 0.7087 - val_loss: 0.6836 - val_accuracy: 0.7220\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6584 - accuracy: 0.7142 - val_loss: 0.6550 - val_accuracy: 0.7260\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6917 - accuracy: 0.6843 - val_loss: 0.5344 - val_accuracy: 0.7940\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.5352 - accuracy: 0.7707 - val_loss: 0.6076 - val_accuracy: 0.7480\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5946 - accuracy: 0.7277 - val_loss: 0.7223 - val_accuracy: 0.7160\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7912 - accuracy: 0.6804 - val_loss: 0.5456 - val_accuracy: 0.7980\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5494 - accuracy: 0.7597 - val_loss: 0.5312 - val_accuracy: 0.7960\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5329 - accuracy: 0.7658 - val_loss: 0.5713 - val_accuracy: 0.7420\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5985 - accuracy: 0.7046 - val_loss: 0.5879 - val_accuracy: 0.7420\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5718 - accuracy: 0.7316 - val_loss: 0.5390 - val_accuracy: 0.7660\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5583 - accuracy: 0.7668 - val_loss: 0.5317 - val_accuracy: 0.8180\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5241 - accuracy: 0.7904 - val_loss: 0.5145 - val_accuracy: 0.8080\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5126 - accuracy: 0.7713 - val_loss: 0.5264 - val_accuracy: 0.7840\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5329 - accuracy: 0.7600 - val_loss: 0.5351 - val_accuracy: 0.8180\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5265 - accuracy: 0.7890 - val_loss: 0.5119 - val_accuracy: 0.7920\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5209 - accuracy: 0.7702 - val_loss: 0.5075 - val_accuracy: 0.8260\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5008 - accuracy: 0.7924 - val_loss: 0.5011 - val_accuracy: 0.8240\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5001 - accuracy: 0.7939 - val_loss: 0.4966 - val_accuracy: 0.8240\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5004 - accuracy: 0.7793 - val_loss: 0.4983 - val_accuracy: 0.7980\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5104 - accuracy: 0.7770 - val_loss: 0.5034 - val_accuracy: 0.7920\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5170 - accuracy: 0.7647 - val_loss: 0.5515 - val_accuracy: 0.7920\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5325 - accuracy: 0.7806 - val_loss: 0.5044 - val_accuracy: 0.8040\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5104 - accuracy: 0.7634 - val_loss: 0.5203 - val_accuracy: 0.8240\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5026 - accuracy: 0.8007 - val_loss: 0.4973 - val_accuracy: 0.8160\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4943 - accuracy: 0.7773 - val_loss: 0.4941 - val_accuracy: 0.8120\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4958 - accuracy: 0.7772 - val_loss: 0.5184 - val_accuracy: 0.8060\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.5056 - accuracy: 0.7870 - val_loss: 0.4895 - val_accuracy: 0.7940\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5083 - accuracy: 0.7744 - val_loss: 0.4833 - val_accuracy: 0.8180\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4854 - accuracy: 0.7868 - val_loss: 0.4833 - val_accuracy: 0.8120\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4855 - accuracy: 0.7917 - val_loss: 0.4783 - val_accuracy: 0.8120\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4882 - accuracy: 0.7799 - val_loss: 0.4821 - val_accuracy: 0.8120\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4842 - accuracy: 0.7861 - val_loss: 0.4864 - val_accuracy: 0.8120\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4868 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.8180\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4833 - accuracy: 0.7908 - val_loss: 0.4836 - val_accuracy: 0.8180\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4695 - accuracy: 0.7961 - val_loss: 0.4761 - val_accuracy: 0.8280\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4771 - accuracy: 0.7944 - val_loss: 0.4722 - val_accuracy: 0.8220\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4754 - accuracy: 0.7884 - val_loss: 0.5166 - val_accuracy: 0.8020\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5083 - accuracy: 0.7850 - val_loss: 0.4745 - val_accuracy: 0.8280\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4731 - accuracy: 0.7970 - val_loss: 0.4752 - val_accuracy: 0.8160\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4852 - accuracy: 0.7757 - val_loss: 0.4790 - val_accuracy: 0.8160\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4909 - accuracy: 0.7736 - val_loss: 0.4757 - val_accuracy: 0.8280\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4714 - accuracy: 0.7881 - val_loss: 0.4702 - val_accuracy: 0.8180\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4758 - accuracy: 0.7781 - val_loss: 0.4719 - val_accuracy: 0.8140\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4703 - accuracy: 0.7849 - val_loss: 0.4878 - val_accuracy: 0.8060\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4840 - accuracy: 0.7920 - val_loss: 0.4896 - val_accuracy: 0.8200\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4777 - accuracy: 0.8056 - val_loss: 0.5024 - val_accuracy: 0.8180\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4948 - accuracy: 0.8139 - val_loss: 0.4789 - val_accuracy: 0.8120\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4842 - accuracy: 0.7876 - val_loss: 0.4713 - val_accuracy: 0.8260\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4717 - accuracy: 0.7904 - val_loss: 0.5088 - val_accuracy: 0.7960\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5282 - accuracy: 0.7434 - val_loss: 0.4795 - val_accuracy: 0.8040\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4796 - accuracy: 0.7806 - val_loss: 0.5960 - val_accuracy: 0.7460\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5727 - accuracy: 0.7283 - val_loss: 0.5431 - val_accuracy: 0.7820\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5768 - accuracy: 0.7447 - val_loss: 0.4897 - val_accuracy: 0.8180\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4977 - accuracy: 0.7764 - val_loss: 0.4610 - val_accuracy: 0.8320\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4611 - accuracy: 0.8077 - val_loss: 0.4607 - val_accuracy: 0.8160\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4744 - accuracy: 0.7861 - val_loss: 0.4633 - val_accuracy: 0.8240\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4522 - accuracy: 0.8099 - val_loss: 0.4643 - val_accuracy: 0.8160\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4684 - accuracy: 0.7898 - val_loss: 0.5023 - val_accuracy: 0.8100\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4860 - accuracy: 0.8076 - val_loss: 0.4825 - val_accuracy: 0.8220\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4661 - accuracy: 0.8166 - val_loss: 0.4537 - val_accuracy: 0.8220\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4702 - accuracy: 0.7978 - val_loss: 0.4640 - val_accuracy: 0.8160\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4601 - accuracy: 0.7987 - val_loss: 0.4450 - val_accuracy: 0.8200\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4492 - accuracy: 0.7911 - val_loss: 0.4772 - val_accuracy: 0.8120\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4993 - accuracy: 0.7704 - val_loss: 0.5139 - val_accuracy: 0.8100\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4978 - accuracy: 0.8062 - val_loss: 0.4580 - val_accuracy: 0.8280\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4511 - accuracy: 0.8104 - val_loss: 0.4628 - val_accuracy: 0.8120\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4861 - accuracy: 0.7677 - val_loss: 0.4646 - val_accuracy: 0.8140\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4564 - accuracy: 0.7972 - val_loss: 0.4456 - val_accuracy: 0.8240\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4410 - accuracy: 0.8150 - val_loss: 0.4534 - val_accuracy: 0.8160\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4636 - accuracy: 0.7920 - val_loss: 0.4496 - val_accuracy: 0.8300\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4427 - accuracy: 0.8166 - val_loss: 0.4456 - val_accuracy: 0.8240\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4445 - accuracy: 0.8159 - val_loss: 0.4365 - val_accuracy: 0.8240\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4366 - accuracy: 0.8090 - val_loss: 0.5595 - val_accuracy: 0.7440\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5420 - accuracy: 0.7481 - val_loss: 0.4430 - val_accuracy: 0.8220\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.4351 - val_accuracy: 0.8340\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4319 - accuracy: 0.8117 - val_loss: 0.4935 - val_accuracy: 0.8080\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4722 - accuracy: 0.8178 - val_loss: 0.4531 - val_accuracy: 0.8260\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4709 - accuracy: 0.7800 - val_loss: 0.4321 - val_accuracy: 0.8280\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.4360 - accuracy: 0.8090 - val_loss: 0.4832 - val_accuracy: 0.8080\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4676 - accuracy: 0.7985 - val_loss: 0.4351 - val_accuracy: 0.8200\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4571 - accuracy: 0.7957 - val_loss: 0.4267 - val_accuracy: 0.8280\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4299 - accuracy: 0.8187 - val_loss: 0.4776 - val_accuracy: 0.8140\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4631 - accuracy: 0.8081 - val_loss: 0.4292 - val_accuracy: 0.8340\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4343 - accuracy: 0.8043 - val_loss: 0.4315 - val_accuracy: 0.8180\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4344 - accuracy: 0.8016 - val_loss: 0.4556 - val_accuracy: 0.8160\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4435 - accuracy: 0.8081 - val_loss: 0.4390 - val_accuracy: 0.8240\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4295 - accuracy: 0.8147 - val_loss: 0.4285 - val_accuracy: 0.8300\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4251 - accuracy: 0.8236 - val_loss: 0.4276 - val_accuracy: 0.8300\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4292 - accuracy: 0.8181 - val_loss: 0.4287 - val_accuracy: 0.8300\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4287 - accuracy: 0.8159 - val_loss: 0.4456 - val_accuracy: 0.8220\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4337 - accuracy: 0.8324 - val_loss: 0.4346 - val_accuracy: 0.8200\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4527 - accuracy: 0.7957 - val_loss: 0.4250 - val_accuracy: 0.8240\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4224 - accuracy: 0.8222 - val_loss: 0.5005 - val_accuracy: 0.7900\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4757 - accuracy: 0.8159 - val_loss: 0.4352 - val_accuracy: 0.8140\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4616 - accuracy: 0.7993 - val_loss: 0.4415 - val_accuracy: 0.8120\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4623 - accuracy: 0.7892 - val_loss: 0.4856 - val_accuracy: 0.8080\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4648 - accuracy: 0.8138 - val_loss: 0.4540 - val_accuracy: 0.8180\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4601 - accuracy: 0.7810 - val_loss: 0.4566 - val_accuracy: 0.8160\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4627 - accuracy: 0.7883 - val_loss: 0.5114 - val_accuracy: 0.7940\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4839 - accuracy: 0.7905 - val_loss: 0.4495 - val_accuracy: 0.8200\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4611 - accuracy: 0.7813 - val_loss: 0.4320 - val_accuracy: 0.8260\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4393 - accuracy: 0.8001 - val_loss: 0.4979 - val_accuracy: 0.7860\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4692 - accuracy: 0.8102 - val_loss: 0.4364 - val_accuracy: 0.8200\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4576 - accuracy: 0.7951 - val_loss: 0.4649 - val_accuracy: 0.8140\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4952 - accuracy: 0.7766 - val_loss: 0.4717 - val_accuracy: 0.8100\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4606 - accuracy: 0.8145 - val_loss: 0.4218 - val_accuracy: 0.8300\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4251 - accuracy: 0.8179 - val_loss: 0.4604 - val_accuracy: 0.8140\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4929 - accuracy: 0.7861 - val_loss: 0.4584 - val_accuracy: 0.8180\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4379 - accuracy: 0.8207 - val_loss: 0.4420 - val_accuracy: 0.8180\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4192 - accuracy: 0.8222 - val_loss: 0.4427 - val_accuracy: 0.8080\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4685 - accuracy: 0.7959 - val_loss: 0.4263 - val_accuracy: 0.8280\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4166 - accuracy: 0.8222 - val_loss: 0.4765 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4509 - accuracy: 0.8241 - val_loss: 0.4568 - val_accuracy: 0.8100\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4927 - accuracy: 0.7800 - val_loss: 0.4385 - val_accuracy: 0.8080\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4386 - accuracy: 0.8107 - val_loss: 0.4301 - val_accuracy: 0.8220\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4177 - accuracy: 0.8227 - val_loss: 0.5346 - val_accuracy: 0.7860\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5923 - accuracy: 0.7621 - val_loss: 0.4486 - val_accuracy: 0.8140\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4589 - accuracy: 0.7908 - val_loss: 0.5848 - val_accuracy: 0.7460\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5461 - accuracy: 0.7418 - val_loss: 0.4838 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5302 - accuracy: 0.7809 - val_loss: 0.4988 - val_accuracy: 0.7860\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5482 - accuracy: 0.7793 - val_loss: 0.6670 - val_accuracy: 0.6880\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6263 - accuracy: 0.6840 - val_loss: 0.4298 - val_accuracy: 0.8280\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4558 - accuracy: 0.8105 - val_loss: 0.5445 - val_accuracy: 0.7820\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6102 - accuracy: 0.7508 - val_loss: 0.4521 - val_accuracy: 0.8320\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4345 - accuracy: 0.8019 - val_loss: 0.5814 - val_accuracy: 0.7680\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5397 - accuracy: 0.7594 - val_loss: 0.5052 - val_accuracy: 0.8040\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5366 - accuracy: 0.7787 - val_loss: 0.4996 - val_accuracy: 0.8020\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5211 - accuracy: 0.7917 - val_loss: 0.5535 - val_accuracy: 0.7600\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5324 - accuracy: 0.7711 - val_loss: 0.4279 - val_accuracy: 0.8260\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4207 - accuracy: 0.8173 - val_loss: 0.4544 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4894 - accuracy: 0.7849 - val_loss: 0.4188 - val_accuracy: 0.8220\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4186 - accuracy: 0.8292 - val_loss: 0.4524 - val_accuracy: 0.8060\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4294 - accuracy: 0.8188 - val_loss: 0.4243 - val_accuracy: 0.8280\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4474 - accuracy: 0.8000 - val_loss: 0.4242 - val_accuracy: 0.8280\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4264 - accuracy: 0.8070 - val_loss: 0.4417 - val_accuracy: 0.8240\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4221 - accuracy: 0.8105 - val_loss: 0.4207 - val_accuracy: 0.8240\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4164 - accuracy: 0.8161 - val_loss: 0.4124 - val_accuracy: 0.8340\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4154 - accuracy: 0.8213 - val_loss: 0.4178 - val_accuracy: 0.8160\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4139 - accuracy: 0.8241 - val_loss: 0.4144 - val_accuracy: 0.8280\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4008 - accuracy: 0.8381 - val_loss: 0.4335 - val_accuracy: 0.8180\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4195 - accuracy: 0.8310 - val_loss: 0.4260 - val_accuracy: 0.8200\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4241 - accuracy: 0.8095 - val_loss: 0.4187 - val_accuracy: 0.8280\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4333 - accuracy: 0.8061 - val_loss: 0.4144 - val_accuracy: 0.8280\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4035 - accuracy: 0.8319 - val_loss: 0.4375 - val_accuracy: 0.8280\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4154 - accuracy: 0.8353 - val_loss: 0.4178 - val_accuracy: 0.8320\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4120 - accuracy: 0.8277 - val_loss: 0.4160 - val_accuracy: 0.8400\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4171 - accuracy: 0.8227 - val_loss: 0.4341 - val_accuracy: 0.8300\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4086 - accuracy: 0.8354 - val_loss: 0.4796 - val_accuracy: 0.8060\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4431 - accuracy: 0.8166 - val_loss: 0.4176 - val_accuracy: 0.8280\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4011 - accuracy: 0.8236 - val_loss: 0.4175 - val_accuracy: 0.8360\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4154 - accuracy: 0.8130 - val_loss: 0.4405 - val_accuracy: 0.8220\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4223 - accuracy: 0.8204 - val_loss: 0.4316 - val_accuracy: 0.8280\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4086 - accuracy: 0.8194 - val_loss: 0.4365 - val_accuracy: 0.8180\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4514 - accuracy: 0.7936 - val_loss: 0.4143 - val_accuracy: 0.8320\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4140 - accuracy: 0.8170 - val_loss: 0.4489 - val_accuracy: 0.8120\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4334 - accuracy: 0.8163 - val_loss: 0.4563 - val_accuracy: 0.8040\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4341 - accuracy: 0.8105 - val_loss: 0.4187 - val_accuracy: 0.8260\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4171 - accuracy: 0.8178 - val_loss: 0.4081 - val_accuracy: 0.8380\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = create_dataset()\n",
    "\n",
    "# create learning curves for different batch sizes\n",
    "batch_sizes = [4, 8, 16, 32, 64, 128, 256, 450]\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    # determine the plot number\n",
    "    plot_no = 420 + (i+1)\n",
    "    pyplot.subplot(plot_no)\n",
    "    \n",
    "    # fit model and plot learning curves for a batch size\n",
    "    fit_model(trainX, trainy, testX, testy, batch_sizes[i])   \n",
    "    \n",
    "# show learning curves\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be a figure with eight plots of model behavior with eight different batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a figure with eight-line plots showing the classification accuracy on the train and test sets of models with different batch sizes when using minibatch gradient descent.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "The plots show that small-batch results generally in rapid learning but a volatile learning process with higher variance in the classification accuracy. Larger batch sizes slow down the learning process (in terms of the learning curves), but the final stages result in a convergence to a more stable model exemplified by lower variance in classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extensions**\n",
    "\n",
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "* **Vary Learning Rate**. Study the effect of different learning rate values on a logarithmic scale with stochastic (online) gradient descent.\n",
    "* **Vary Epochs**. Study the number of epochs required for convergence as the batch size is increased to the training dataset size with minibatch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "In this tutorial, you discovered three different flavors of gradient descent and how to explore and diagnose the effect of batch size on the learning process. Specifically, you learned:\n",
    "* Batch size controls the accuracy of the estimate of the error gradient when training neural networks.\n",
    "* Batch, Stochastic, and Minibatch gradient descent are the three main flavors of the learning algorithm.\n",
    "* There is a tension between batch size and the speed and stability of the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
