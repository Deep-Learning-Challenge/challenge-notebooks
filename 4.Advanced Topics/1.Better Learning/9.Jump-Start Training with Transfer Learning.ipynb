{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deep-Learning-Challenge/challenge-notebooks/blob/master/4.Advanced%20Topics/1.Better%20Learning/9.Jump-Start%20Training%20with%20Transfer%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jump-Start Training with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting benefit of deep learning neural networks is that they can be reused on related problems. In deep learning, this means reusing the weights in one or more layers from a pre-trained network model in a new model and keeping the weights fixed, fine-tuning them, or adapting the weights entirely when training the model. Transfer learning refers to a technique for predictive modeling on a different but somehow similar problem that can then be reused partly or wholly to accelerate the training and improve the performance of a model on the problem of interest. In this tutorial, you will discover how to use transfer learning to improve the performance of deep learning neural networks in Python with Keras. After completing this tutorial, you will know:\n",
    "\n",
    "* Transfer learning is a method for reusing a model trained on a related predictive modeling problem.\n",
    "* Transfer learning can accelerate the training of neural networks as either a weight initialization scheme or feature extraction method.\n",
    "* How to use transfer learning to improve the performance of an MLP for a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning generally refers to a process where a model trained on one problem is used in some way on a second related problem.\n",
    "\n",
    "In deep learning, transfer learning is a technique whereby a neural network model is first trained on a problem similar to the problem that is being solved. One or more layers from the trained model are then used in a new model trained on the problem of interest.\n",
    "\n",
    "Transfer learning has the benefit of decreasing the training time for a neural network model, resulting in lower generalization error. There are two main approaches to implementing transfer learning; they are:\n",
    "\n",
    "* Weight Initialization.\n",
    "* Feature Extraction.\n",
    "\n",
    "The weights in re-used layers may be used as the starting point for the training process and adapted to the new problem. This usage treats transfer learning as a type of weight initialization scheme. This may be useful when the first related problem has a lot more labeled data than the problem of interest, and the similarity in the structure of the problem may be useful in both contexts.\n",
    "\n",
    "Alternately, the network's weights may not be adapted to the new problem, and only new layers after the reused layers may be trained to interpret their output. This usage treats transfer learning as a type of feature extraction scheme. An example of this approach is re-using deep convolutional neural network models trained for photo classification as feature extractors when developing photo captioning models. Variations on these usages may involve not initially training the model's weights on the new problem but later fine-tuning all weights of the learned model with a small learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate how to use transfer learning to develop MLP models on a multiclass classification problem. This example provides a template for applying transfer learning to your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a small multiclass classification problem as the basis to demonstrate transfer learning. The scikit-learn class provides the make blobs() function that can be used to create a multiclass classification problem with the prescribed number of samples, input variables, classes, and variance of samples within a class. We can configure the problem to have two input variables (to represent the x and y coordinates of the points) and a standard deviation of 2.0 for points within each group. We will use the same random state (seed for the pseudorandom number generator) to ensure that we always get the same data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are the input and output elements of a dataset that we can model. The random state argument can be varied to give different versions of the problem (different cluster centers). We can use this to generate samples from two different problems: train a model on one problem and re-use the weights to learn a model for a second problem better. Specifically, we will refer to random state=1 as Problem 1 and random state=2 as Problem 2.\n",
    "\n",
    "* Problem 1. Blobs problem with two input variables and three classes with the random state argument set to one.\n",
    "* Problem 2. Blobs problem with two input variables and three classes with the random state argument set to two.\n",
    "\n",
    "To get a feeling for the complexity of the problem, we can plot each point on a two-dimensional scatter plot and color each point by class value. The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of blobs multiclass classification problems 1 and 2\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate samples for blobs problem with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# create a scatter plot of points colored by class value\n",
    "def plot_samples(X, y, classes=3):\n",
    "    # plot points for each class\n",
    "    for i in range(classes):\n",
    "        # select indices of points with each class label\n",
    "        samples_ix = where(y == i)\n",
    "        \n",
    "        # plot points for this class with a given color\n",
    "        pyplot.scatter(X[samples_ix, 0], X[samples_ix, 1])\n",
    "\n",
    "# generate multiple problems\n",
    "n_problems = 2\n",
    "for i in range(1, n_problems+1):\n",
    "    # specify subplot\n",
    "    pyplot.subplot(210 + i)\n",
    "    \n",
    "    # generate samples\n",
    "    X, y = samples_for_seed(i)\n",
    "    \n",
    "    # scatter plot of samples\n",
    "    plot_samples(X, y)\n",
    "\n",
    "# plot figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example generates a sample of 1,000 examples for Problem 1 and Problem 2 and creates a scatter plot for each sample, coloring the data points by their class value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a good basis for transfer learning as each version of the problem has similar input data with a similar scale, although with different target information (e.g., cluster centers). We would expect that aspects of a model fit on one version of the blobs problem (e.g., Problem 1) to be useful when fitting a model on a new version of the blobs problem (e.g., Problem 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Model for Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will develop a Multilayer Perceptron model (MLP) for Problem 1 and save the model to file so that we can reuse the weights later. First, we will develop a function to prepare the dataset for modeling. After the make blobs() function is called with a given random seed (e.g., one in this case for Problem 1), the target variable must be one hot encoded so that we can develop a model that predicts the probability of a given sample belonging to each of the target classes. The samples for seed() function below implements this, preparing the dataset for a given random number generator seed and retuning the train and test sets split into input and output components. The prepared samples can then be split in half, with 500 examples for the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "    \n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function to prepare a dataset for Problem 1 as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define and fit a model on the training dataset. The model will expect two inputs for the two variables in the data. The model will have two hidden layers with five nodes each and the rectified linear activation function. Two layers are probably not required for this function, although we're interested in the model learning some deep structure that we can reuse across instances of this problem. The output layer has three nodes, one for each class in the target variable and the softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the problem is a multiclass classification problem, the categorical cross-entropy loss function is minimized, and the stochastic gradient descent with the default learning rate and no momentum is used to learn the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit for 100 epochs on the training dataset, and the test set is used as a validation dataset during training, evaluating the performance on both datasets at the end of each epoch to plot learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit model() function ties these elements together, taking the train and test datasets as arguments and returning the fit model and training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function with the prepared dataset to obtain a fit model and the history collected during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can summarize the performance of the model. The classification accuracy of the model on the train and test sets can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The history collected during training can be used to create line plots showing both the loss and classification accuracy for the model on the train and test sets over each training epoch, providing learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summarize model() function below implements this, taking the fit model, training history, and dataset as arguments are printing the model performance and creating a plot of model learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot loss during training\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    # plot accuracy during training\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function with the fit model and prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the run, we can save the model to file so that we may load it later and use it to transfer learning experiments. Note that saving the model to file requires that you have the h5py library installed. This library can be installed via pip as follows:\n",
    "\n",
    "`sudo pip install h5py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit model can be saved by calling the save() function on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tying these elements together, the complete example of fitting an MLP on Problem 1, summarizing the model's performance, and saving the model to file is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit mlp model on problem 1 and save model to file\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "    \n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "    \n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot loss during training\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "\n",
    "    # plot accuracy during training\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    pyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(1)\n",
    "\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example fits and evaluates the model's performance, printing the classification accuracy on the train and test sets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that the model performed well on Problem 1, achieving a classification accuracy of about 92% on both the train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figure is also created summarizing the learning curves of the model, showing both the loss (top) and accuracy (bottom) for the model on both the train (blue) and test (orange) datasets at the end of each training epoch. In this case, we can see that the model learned the problem reasonably quickly and well, perhaps converging in about 40 epochs and remaining reasonably stable on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)\n",
    "\n",
    "# save model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen how to develop a standalone MLP for the blobs Problem 1, we can do the same for Problem 2 that can be used as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone MLP Model for Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example in the previous section can be updated to fit an MLP model to Problem 2. It is important to get an idea of performance and learning dynamics on Problem 2 for a standalone model first, as this will provide a baseline in performance that can be used to compare to a model fit on the same problem using transfer learning. A single change is required that changes the call to samples for seed() to use the pseudorandom number generator seed of two instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For completeness, the full example of this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit mlp model on problem 2 and save model to file\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot loss during training\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    # plot accuracy during training\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    pyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example fits and evaluates the model's performance, printing the classification accuracy on the train and test sets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that the model performed okay on Problem 2, but not as well as was seen on Problem 1, achieving a classification accuracy of about 79% on both the train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figure is also created summarizing the learning curves of the model. In this case, we can see that the model converged more slowly than we saw in Problem 1 in the previous section. This suggests that this problem version may be slightly more challenging, at least for the chosen model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline of performance and learning dynamics for an MLP on Problem 2, we can see how transfer learning affects MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With Transfer Learning for Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that was fit on Problem 1 can be loaded, and the weights can be used as the initial weights for a model fit on Problem 2. This type of transfer learning is where learning on a different but related problem is used as a weight initialization scheme. This requires that the fit_model() function be updated to load the model and refit it on examples for Problem 2. The model saved in model.h5 can be loaded using the load_model() Keras function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, the model can be compiled and fit as per normal. The updated fit model() with this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and re-fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "    # load model\n",
    "    model = load_model('model.h5')\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # re-fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect that a model that uses the weights from a model fit on a different but related problem to learn the problem perhaps faster in terms of the learning curve and perhaps result in lower generalization error, although these aspects would be dependent on the choice of problems and model. For completeness, the full example of this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning with mlp model on problem 2\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "    \n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# load and re-fit model on a training dataset\n",
    "def fit_model(trainX, trainy, testX, testy):\n",
    "    # load model\n",
    "    model = load_model('model.h5')\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # re-fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "    \n",
    "    return model, history\n",
    "# summarize the performance of the fit model\n",
    "def summarize_model(model, history, trainX, trainy, testX, testy):\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot loss during training\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    # plot accuracy during training\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    pyplot.show()\n",
    "\n",
    "# prepare data\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "# fit model on train dataset\n",
    "model, history = fit_model(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example fits and evaluates the model's performance, printing the classification accuracy on the train and test sets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that the model achieved a lower generalization error, achieving an accuracy of about 81% on the test dataset for Problem 2 compared to the standalone model that achieved about 79% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A  figure is also created summarizing the learning curves of the model. In this case, we can see that the model does appear to have a similar learning curve, although we do see apparent improvements in the learning curve for the test set (orange line) both in terms of better performance earlier (epoch 20 onward) and above the performance of the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model behavior\n",
    "summarize_model(model, history, trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only looked at single runs of a standalone MLP model and an MLP with transfer learning. Neural network algorithms are stochastic, therefore an average of performance across multiple runs is required to see if the observed behavior is real or a statistical fluke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Models on Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine whether transfer learning for the blobs multiclass classification problem has a real effect, we must repeat each experiment multiple times and analyze the average performance across the repeats. We will compare the standalone model\n",
    "trained on Problem 2 to a model using transfer learning, averaged over 30 repeats. Further, we will investigate whether keeping the weights in some of the layers fixed improves model performance. The model trained on Problem 1 has two hidden layers. By keeping the first or the first and second hidden layers fixed, the layers with unchangeable weights will act as a feature extractor and may provide features that make learning Problem 2 easier, affecting the speed of learning and/or the model's accuracy on the test set. As the first step, we will simplify the fit_model() function to fit the model and discard any training history to focus on the final accuracy of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can develop a function that will repeatedly fit a new standalone model on Problem 2 on the training dataset and evaluate accuracy on the test set. The eval_standalone_model() function below implements this, taking the train and test sets as arguments and the number of repeats and returns a list of accuracy scores for models on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of a standalone model\n",
    "def eval_standalone_model(trainX, trainy, testX, testy, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # define and fit a new model on the train dataset\n",
    "        model = fit_model(trainX, trainy)\n",
    "        \n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the distribution of accuracy scores returned from this function will give an idea of how well the chosen standalone model performs on Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "\n",
    "# repeated evaluation of standalone model\n",
    "standalone_scores = eval_standalone_model(trainX, trainy, testX, testy, 30)\n",
    "print('Standalone %.3f (%.3f)' % (mean(standalone_scores), std(standalone_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need an equivalent function for evaluating a model using transfer learning. In each loop, the model trained on Problem 1 must be loaded from file, fit on the training dataset for Problem 2, then evaluated on the test set for Problem 2. In addition, we will configure 0, 1, or 2 of the hidden layers in the loaded model to remain fixed. Keeping 0 hidden layers fixed means that all of the weights in the model will be adapted when learning Problem 2, using transfer learning as a weight initialization scheme. Whereas, keeping both (2) of the hidden layers fixed means that only the output layer of the model will be adapted during training, using transfer learning as a feature extraction method.\n",
    "\n",
    "The eval transfer model() function below implements this, taking the train and test datasets for Problem 2 as arguments, the number of hidden layers in the loaded model to keep fixed, and the number of times to repeat the experiment. The function returns a list of test accuracy scores, and summarizing this distribution will give a reasonable idea of how well the model with the chosen type of transfer learning performs on Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of a model with transfer learning\n",
    "def eval_transfer_model(trainX, trainy, testX, testy, n_fixed, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # load model\n",
    "        model = load_model('model.h5')\n",
    "        \n",
    "        # mark layer weights as fixed or not trainable\n",
    "        for i in range(n_fixed):\n",
    "            model.layers[i].trainable = False\n",
    "        \n",
    "        # re-compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "        # fit model on train dataset\n",
    "        model.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call this function repeatedly, setting n fixed to 0, 1, 2 in a loop and summarizing performance as we go; for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated evaluation of transfer learning model, vary fixed layers\n",
    "n_fixed = 3\n",
    "for i in range(n_fixed):\n",
    "    scores = eval_transfer_model(trainX, trainy, testX, testy, i, 30)\n",
    "    print('Transfer (fixed=%d) %.3f (%.3f)' % (i, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to reporting each model's mean and standard deviation, we can collect all scores and create a box and whisker plot to summarize and compare the distributions of model scores. Tying all of these elements together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare standalone mlp model performance to transfer learning\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean, std\n",
    "\n",
    "# prepare a blobs examples with a given random seed\n",
    "def samples_for_seed(seed):\n",
    "    # generate samples\n",
    "    X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=seed)\n",
    "\n",
    "    # one hot encode output variable\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# define and fit model on a training dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=2, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(5, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "# repeated evaluation of a standalone model\n",
    "def eval_standalone_model(trainX, trainy, testX, testy, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # define and fit a new model on the train dataset\n",
    "        model = fit_model(trainX, trainy)\n",
    "\n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# repeated evaluation of a model with transfer learning\n",
    "def eval_transfer_model(trainX, trainy, testX, testy, n_fixed, n_repeats):\n",
    "    scores = list()\n",
    "    for _ in range(n_repeats):\n",
    "        # load model\n",
    "        model = load_model('model.h5')\n",
    "\n",
    "        # mark layer weights as fixed or not trainable\n",
    "        for i in range(n_fixed):\n",
    "            model.layers[i].trainable = False\n",
    "\n",
    "        # re-compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "        # fit model on train dataset\n",
    "        model.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\n",
    "        # evaluate model on test dataset\n",
    "        _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "        scores.append(test_acc)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# prepare data for problem 2\n",
    "trainX, trainy, testX, testy = samples_for_seed(2)\n",
    "n_repeats = 30\n",
    "dists, dist_labels = list(), list()\n",
    "\n",
    "# repeated evaluation of standalone model\n",
    "standalone_scores = eval_standalone_model(trainX, trainy, testX, testy, n_repeats)\n",
    "print('Standalone %.3f (%.3f)' % (mean(standalone_scores), std(standalone_scores)))\n",
    "dists.append(standalone_scores)\n",
    "dist_labels.append('standalone')\n",
    "\n",
    "# repeated evaluation of transfer learning model, vary fixed layers\n",
    "n_fixed = 3\n",
    "for i in range(n_fixed):\n",
    "    scores = eval_transfer_model(trainX, trainy, testX, testy, i, n_repeats)\n",
    "    print('Transfer (fixed=%d) %.3f (%.3f)' % (i, mean(scores), std(scores)))\n",
    "    dists.append(scores)\n",
    "    dist_labels.append('transfer f='+str(i))\n",
    "\n",
    "# box and whisker plot of score distributions\n",
    "pyplot.boxplot(dists, labels=dist_labels)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation of classification accuracy on the test dataset for each model.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that the standalone model achieved an accuracy of about 78% on Problem 2 with a large standard deviation of 10%. In contrast, we can see that the transfer learning models' spread is much smaller, ranging from about 0.05% to 1.5%.\n",
    "\n",
    "This difference in the standard deviations of the test accuracy scores shows the stability that transfer learning can bring to the model, reducing the variance in the performance of the final model introduced via the stochastic learning algorithm. Comparing the mean test accuracy of the models, we can see that transfer learning that used the model as a weight initialization scheme (fixed=0) resulted in better performance than the standalone model with about 80% accuracy. Keeping all hidden layers fixed (fixed=2) and using them as a feature extraction scheme resulted in worse performance on average than the standalone model. It suggests that the approach is too restrictive in this case.\n",
    "\n",
    "Interestingly, we see the best performance when the first hidden layer is kept fixed (fixed=1), and the second hidden layer is adapted to the problem with a test classification accuracy of about 81%. This suggests that, in this case, the problem benefits from both the feature extraction and weight initialization properties of transfer learning. It may be interesting to see how the results of this last approach compare to the same model where the weights of the second hidden layer (and perhaps the output layer) are re-initialized with random numbers. This comparison would demonstrate whether the feature extraction properties of transfer learning alone or feature extraction and weight initialization properties are beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figure is created showing four box and whisker plots. The box shows the middle 50% of each data distribution, the orange line shows the median, and the dots show outliers. The box and whisker plot for the standalone model shows a number of outliers, indicating that the model performs well on average, but there is a chance that it can perform very poorly. Conversely, we see that the behavior of the models with transfer learning is more stable, showing a tighter distribution in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "* **Reverse Experiment**. Train and save a model for Problem 2 and see if it can help with transfer learning on Problem 1.\n",
    "* **Add Hidden Layer**. Update the example to keep both hidden layers fixed, but add a new hidden layer with randomly initialized weights after the fixed layers before the output layer and compare performance.\n",
    "* **Randomly Initialize Layers**. Update the example to randomly initialize the weights of the second hidden layer and the output layer and compare performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you discovered how to use transfer learning to improve the performance of deep learning neural networks in Python with Keras. Specifically, you learned:\n",
    "\n",
    "* Transfer learning is a method for reusing a model trained on a related predictive modeling problem.\n",
    "* Transfer learning can accelerate the training of neural networks as either a weight initialization scheme or feature extraction method.\n",
    "* How to use transfer learning to improve the performance of an MLP for a multiclass classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
