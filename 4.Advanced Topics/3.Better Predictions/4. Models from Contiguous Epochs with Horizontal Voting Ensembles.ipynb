{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models from Contiguous Epochs With Horizontal Voting Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive modeling problems where the training dataset is small relative to the number of unlabeled examples are challenging. Neural networks can perform well on these types of problems, although they can suffer from high variance in model performance as measured on training or hold-out validation datasets. This makes choosing which model to use as the final model risky, as there is no clear signal as to which model is better than another toward the end of the training run. The horizontal voting ensemble is a simple method to address this issue. A collection of models saved over contiguous training epochs towards the end of a training run are saved and used as an ensemble that results in more stable and better performance on average randomly choosing a single final model. In this tutorial, you will discover how to reduce the variance of a final deep learning neural network model using a horizontal voting ensemble. After completing this tutorial, you will know:\n",
    "\n",
    "* It is challenging to choose a final neural network model with high variance on a training dataset.\n",
    "* Horizontal voting ensembles provide a way to reduce variance and improve average model performance for models with high variance using a single training run.\n",
    "* How to develop a horizontal voting ensemble in Python using Keras to improve the performance of a final Multilayer Perceptron model for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning combines the predictions from multiple models. A challenge when using ensemble learning when using deep learning methods is that given very large datasets and large models, a training run may take days, weeks, or even months. Training multiple models may not be feasible. An alternative source of models that may contribute to an ensemble is the state of a single model at different points during training. Horizontal voting is an ensemble method proposed by Jingjing Xie et al. in their 2013 paper *Horizontal and Vertical Ensemble with Deep Representation for Classification*.\n",
    "\n",
    "The method involves using multiple models from the end of a contiguous block of epochs before the end of training in an ensemble to make predictions. The approach was developed specifically for those predictive modeling problems where the training dataset is relatively small compared to the number of predictions required by the model. This results in a model that has a high variance in performance during training. In this situation, using the final model or any given model toward the end of the training process is risky given the variance in performance.\n",
    "\n",
    "Instead, the authors suggest using all models in an ensemble from a contiguous block of epochs during training, such as models from the last 200 epochs. The result is predictions by the ensemble that are as good as or better than any single model in the ensemble.\n",
    "\n",
    "As such, the horizontal voting ensemble method provides an ideal method for both cases where a given model requires vast computational resources to train and/or cases where final model selection is challenging given the high variance of training due to the use of a relatively small training dataset. Now that we are familiar with horizontal voting, we can implement the procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Voting Ensembles Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will demonstrate how to use the horizontal voting ensemble to reduce the variance of an MLP on a simple multiclass classification problem. This example provides a template for applying the horizontal voting ensemble to your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a small multiclass classification problem as the basis to demonstrate a horizontal voting ensemble. The scikit-learn class provides the `make_blobs()` function that can be used to create a multiclass classification problem with the prescribed number of samples, input variables, classes, and variance of samples within a class. We use this problem with 1,000 examples, with input variables (to represent the x and y coordinates of the points) and a standard deviation of 2.0 for points within each group. We will use the same random state (seed for the pseudorandom number generator) to ensure that we always get the same data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are the input and output elements of a dataset that we can model. In order to get a feeling for the complexity of the problem, we can graph each point on a two-dimensional scatter plot and color each point by class value. The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# scatter plot for each class value\n",
    "for class_value in range(3):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "\n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a scatter plot of the entire dataset. We can see that the standard deviation of 2.0 means that the classes are not linearly separable (separable by a line), causing many ambiguous points. This is desirable because the problem is non-trivial and will allow a neural network model to find many different *good enough* candidate solutions resulting in a high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we define a model, we need to contrive an appropriate problem for a horizontal voting ensemble. In our problem, the training dataset is relatively small. Specifically, there is a 10:1 ratio of examples in the training dataset to the holdout dataset. This mimics a situation where we may have a vast number of unlabeled examples and a small number of labeled examples with which to train a model. We will create 1,100 data points from the blobs problem. The model will be trained on the first 100 points, and the remaining 1,000 will be held back in a test dataset, unavailable to the model.\n",
    "\n",
    "The problem is a multiclass classification problem, and we will model it using a softmax activation function on the output layer. This means that the model will predict a vector with three elements with the probability that the sample belongs to each of the three classes. Therefore, the first step is to one-hot encode the class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "print(trainX.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define and compile the model. The model will expect samples with two input variables. The model then has a single hidden layer with 25 nodes and a rectified linear activation function, an output layer with three nodes to predict the probability of each of the three classes, and a softmax activation function. Because the problem is multiclass, we will use the categorical cross-entropy loss function to optimize the model and the efficient Adam flavor of stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit for 1000 training epochs, and we will evaluate each epoch on the test set, using the test set as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 99ms/step - loss: 1.1374 - accuracy: 0.3782 - val_loss: 1.0588 - val_accuracy: 0.3820\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0712 - accuracy: 0.3534 - val_loss: 1.0175 - val_accuracy: 0.4030\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9873 - accuracy: 0.4565 - val_loss: 0.9850 - val_accuracy: 0.4120\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9644 - accuracy: 0.4572 - val_loss: 0.9594 - val_accuracy: 0.4110\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9320 - accuracy: 0.4696 - val_loss: 0.9402 - val_accuracy: 0.4200\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9123 - accuracy: 0.4809 - val_loss: 0.9251 - val_accuracy: 0.4230\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9211 - accuracy: 0.4463 - val_loss: 0.9112 - val_accuracy: 0.4280\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8849 - accuracy: 0.4620 - val_loss: 0.8982 - val_accuracy: 0.4360\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8528 - accuracy: 0.4745 - val_loss: 0.8812 - val_accuracy: 0.4580\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8690 - accuracy: 0.4800 - val_loss: 0.8651 - val_accuracy: 0.4850\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8299 - accuracy: 0.5667 - val_loss: 0.8529 - val_accuracy: 0.5080\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8035 - accuracy: 0.5935 - val_loss: 0.8414 - val_accuracy: 0.5290\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8174 - accuracy: 0.5870 - val_loss: 0.8303 - val_accuracy: 0.5430\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8215 - accuracy: 0.5629 - val_loss: 0.8214 - val_accuracy: 0.5560\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7866 - accuracy: 0.6086 - val_loss: 0.8135 - val_accuracy: 0.5580\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7804 - accuracy: 0.5992 - val_loss: 0.8066 - val_accuracy: 0.5620\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7416 - accuracy: 0.6385 - val_loss: 0.7979 - val_accuracy: 0.5690\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7572 - accuracy: 0.6062 - val_loss: 0.7888 - val_accuracy: 0.5790\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7274 - accuracy: 0.6630 - val_loss: 0.7816 - val_accuracy: 0.5860\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7588 - accuracy: 0.6411 - val_loss: 0.7751 - val_accuracy: 0.5910\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7666 - accuracy: 0.6140 - val_loss: 0.7693 - val_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6951 - accuracy: 0.6942 - val_loss: 0.7630 - val_accuracy: 0.6170\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6897 - accuracy: 0.6836 - val_loss: 0.7570 - val_accuracy: 0.6270\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7240 - accuracy: 0.6564 - val_loss: 0.7504 - val_accuracy: 0.6370\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6758 - accuracy: 0.7218 - val_loss: 0.7446 - val_accuracy: 0.6430\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6691 - accuracy: 0.7185 - val_loss: 0.7386 - val_accuracy: 0.6440\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7041 - accuracy: 0.6986 - val_loss: 0.7325 - val_accuracy: 0.6520\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6965 - accuracy: 0.6821 - val_loss: 0.7282 - val_accuracy: 0.6530\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6705 - accuracy: 0.7060 - val_loss: 0.7241 - val_accuracy: 0.6550\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6638 - accuracy: 0.6925 - val_loss: 0.7208 - val_accuracy: 0.6570\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6670 - accuracy: 0.7185 - val_loss: 0.7172 - val_accuracy: 0.6590\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.6892 - val_loss: 0.7127 - val_accuracy: 0.6680\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.7340 - val_loss: 0.7085 - val_accuracy: 0.6730\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6559 - accuracy: 0.7193 - val_loss: 0.7055 - val_accuracy: 0.6770\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6573 - accuracy: 0.7318 - val_loss: 0.7029 - val_accuracy: 0.6740\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6535 - accuracy: 0.7286 - val_loss: 0.7026 - val_accuracy: 0.6670\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 0.7328 - val_loss: 0.7017 - val_accuracy: 0.6640\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6089 - accuracy: 0.7536 - val_loss: 0.6997 - val_accuracy: 0.6640\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6316 - accuracy: 0.7120 - val_loss: 0.6987 - val_accuracy: 0.6580\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6259 - accuracy: 0.7027 - val_loss: 0.6965 - val_accuracy: 0.6620\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5970 - accuracy: 0.7413 - val_loss: 0.6946 - val_accuracy: 0.6620\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6102 - accuracy: 0.7236 - val_loss: 0.6911 - val_accuracy: 0.6650\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6142 - accuracy: 0.7099 - val_loss: 0.6875 - val_accuracy: 0.6710\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6376 - accuracy: 0.7015 - val_loss: 0.6835 - val_accuracy: 0.6730\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5958 - accuracy: 0.7245 - val_loss: 0.6810 - val_accuracy: 0.6740\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6094 - accuracy: 0.7318 - val_loss: 0.6767 - val_accuracy: 0.6780\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6118 - accuracy: 0.7224 - val_loss: 0.6742 - val_accuracy: 0.6770\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5884 - accuracy: 0.7224 - val_loss: 0.6702 - val_accuracy: 0.6800\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6265 - accuracy: 0.6911 - val_loss: 0.6666 - val_accuracy: 0.6840\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6361 - accuracy: 0.6932 - val_loss: 0.6645 - val_accuracy: 0.6850\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6068 - accuracy: 0.7069 - val_loss: 0.6636 - val_accuracy: 0.6850\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6190 - accuracy: 0.6767 - val_loss: 0.6623 - val_accuracy: 0.6860\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6084 - accuracy: 0.7213 - val_loss: 0.6606 - val_accuracy: 0.6870\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5425 - accuracy: 0.7660 - val_loss: 0.6573 - val_accuracy: 0.6910\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5416 - accuracy: 0.7465 - val_loss: 0.6549 - val_accuracy: 0.6920\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5530 - accuracy: 0.7515 - val_loss: 0.6556 - val_accuracy: 0.6900\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6033 - accuracy: 0.6953 - val_loss: 0.6556 - val_accuracy: 0.6930\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5593 - accuracy: 0.7453 - val_loss: 0.6547 - val_accuracy: 0.6910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5733 - accuracy: 0.7059 - val_loss: 0.6530 - val_accuracy: 0.6910\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6082 - accuracy: 0.6684 - val_loss: 0.6481 - val_accuracy: 0.6950\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5731 - accuracy: 0.7451 - val_loss: 0.6438 - val_accuracy: 0.7000\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5816 - accuracy: 0.7285 - val_loss: 0.6404 - val_accuracy: 0.7010\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5848 - accuracy: 0.7326 - val_loss: 0.6387 - val_accuracy: 0.7040\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5572 - accuracy: 0.7483 - val_loss: 0.6368 - val_accuracy: 0.7030\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5661 - accuracy: 0.7430 - val_loss: 0.6351 - val_accuracy: 0.7060\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5705 - accuracy: 0.7378 - val_loss: 0.6334 - val_accuracy: 0.7070\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5566 - accuracy: 0.7222 - val_loss: 0.6305 - val_accuracy: 0.7090\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5949 - accuracy: 0.7128 - val_loss: 0.6275 - val_accuracy: 0.7120\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5648 - accuracy: 0.7213 - val_loss: 0.6244 - val_accuracy: 0.7150\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5614 - accuracy: 0.7380 - val_loss: 0.6205 - val_accuracy: 0.7230\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5348 - accuracy: 0.7432 - val_loss: 0.6180 - val_accuracy: 0.7300\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5523 - accuracy: 0.7140 - val_loss: 0.6165 - val_accuracy: 0.7280\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5575 - accuracy: 0.7349 - val_loss: 0.6163 - val_accuracy: 0.7250\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5258 - accuracy: 0.7370 - val_loss: 0.6179 - val_accuracy: 0.7170\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5635 - accuracy: 0.7137 - val_loss: 0.6188 - val_accuracy: 0.7150\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5578 - accuracy: 0.7377 - val_loss: 0.6197 - val_accuracy: 0.7100\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.7358 - val_loss: 0.6205 - val_accuracy: 0.7080\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6096 - accuracy: 0.6826 - val_loss: 0.6209 - val_accuracy: 0.7070\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5428 - accuracy: 0.7543 - val_loss: 0.6221 - val_accuracy: 0.7050\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5580 - accuracy: 0.7076 - val_loss: 0.6250 - val_accuracy: 0.7020\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5509 - accuracy: 0.7493 - val_loss: 0.6277 - val_accuracy: 0.6990\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 0.7514 - val_loss: 0.6290 - val_accuracy: 0.6970\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5384 - accuracy: 0.7420 - val_loss: 0.6271 - val_accuracy: 0.6990\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5218 - accuracy: 0.7670 - val_loss: 0.6264 - val_accuracy: 0.6980\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5420 - accuracy: 0.7337 - val_loss: 0.6185 - val_accuracy: 0.7030\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5265 - accuracy: 0.7512 - val_loss: 0.6079 - val_accuracy: 0.7140\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5431 - accuracy: 0.7406 - val_loss: 0.6011 - val_accuracy: 0.7210\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5313 - accuracy: 0.7429 - val_loss: 0.5953 - val_accuracy: 0.7370\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5120 - accuracy: 0.7474 - val_loss: 0.5915 - val_accuracy: 0.7480\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5127 - accuracy: 0.7637 - val_loss: 0.5897 - val_accuracy: 0.7530\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5258 - accuracy: 0.7398 - val_loss: 0.5880 - val_accuracy: 0.7560\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5566 - accuracy: 0.7127 - val_loss: 0.5871 - val_accuracy: 0.7580\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5110 - accuracy: 0.7679 - val_loss: 0.5867 - val_accuracy: 0.7550\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5565 - accuracy: 0.7233 - val_loss: 0.5865 - val_accuracy: 0.7530\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5066 - accuracy: 0.7637 - val_loss: 0.5880 - val_accuracy: 0.7490\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5467 - accuracy: 0.7189 - val_loss: 0.5909 - val_accuracy: 0.7400\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4987 - accuracy: 0.7750 - val_loss: 0.5904 - val_accuracy: 0.7390\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5118 - accuracy: 0.7667 - val_loss: 0.5874 - val_accuracy: 0.7430\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5551 - accuracy: 0.7156 - val_loss: 0.5871 - val_accuracy: 0.7400\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5029 - accuracy: 0.7677 - val_loss: 0.5858 - val_accuracy: 0.7400\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5043 - accuracy: 0.7583 - val_loss: 0.5831 - val_accuracy: 0.7450\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5042 - accuracy: 0.7615 - val_loss: 0.5801 - val_accuracy: 0.7490\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4989 - accuracy: 0.7543 - val_loss: 0.5793 - val_accuracy: 0.7500\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5239 - accuracy: 0.7377 - val_loss: 0.5783 - val_accuracy: 0.7490\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4791 - accuracy: 0.7668 - val_loss: 0.5765 - val_accuracy: 0.7520\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5307 - accuracy: 0.7146 - val_loss: 0.5744 - val_accuracy: 0.7570\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5258 - accuracy: 0.7398 - val_loss: 0.5716 - val_accuracy: 0.7590\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5014 - accuracy: 0.7604 - val_loss: 0.5703 - val_accuracy: 0.7580\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5176 - accuracy: 0.7602 - val_loss: 0.5696 - val_accuracy: 0.7620\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5322 - accuracy: 0.7314 - val_loss: 0.5695 - val_accuracy: 0.7650\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4878 - accuracy: 0.7637 - val_loss: 0.5694 - val_accuracy: 0.7680\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4635 - accuracy: 0.7731 - val_loss: 0.5696 - val_accuracy: 0.7670\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5021 - accuracy: 0.7439 - val_loss: 0.5684 - val_accuracy: 0.7690\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4862 - accuracy: 0.7481 - val_loss: 0.5665 - val_accuracy: 0.7670\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4940 - accuracy: 0.7398 - val_loss: 0.5657 - val_accuracy: 0.7630\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4771 - accuracy: 0.7729 - val_loss: 0.5663 - val_accuracy: 0.7660\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5119 - accuracy: 0.7500 - val_loss: 0.5671 - val_accuracy: 0.7640\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4965 - accuracy: 0.7345 - val_loss: 0.5663 - val_accuracy: 0.7640\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4782 - accuracy: 0.7564 - val_loss: 0.5662 - val_accuracy: 0.7620\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5128 - accuracy: 0.7479 - val_loss: 0.5663 - val_accuracy: 0.7600\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5248 - accuracy: 0.7260 - val_loss: 0.5662 - val_accuracy: 0.7580\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4977 - accuracy: 0.7467 - val_loss: 0.5673 - val_accuracy: 0.7480\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5088 - accuracy: 0.7382 - val_loss: 0.5662 - val_accuracy: 0.7500\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4942 - accuracy: 0.7623 - val_loss: 0.5655 - val_accuracy: 0.7530\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5152 - accuracy: 0.7580 - val_loss: 0.5640 - val_accuracy: 0.7570\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4781 - accuracy: 0.7778 - val_loss: 0.5613 - val_accuracy: 0.7590\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5152 - accuracy: 0.7476 - val_loss: 0.5602 - val_accuracy: 0.7570\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4496 - accuracy: 0.7924 - val_loss: 0.5605 - val_accuracy: 0.7580\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5008 - accuracy: 0.7467 - val_loss: 0.5600 - val_accuracy: 0.7600\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4864 - accuracy: 0.7634 - val_loss: 0.5595 - val_accuracy: 0.7610\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4904 - accuracy: 0.7561 - val_loss: 0.5580 - val_accuracy: 0.7620\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5067 - accuracy: 0.7590 - val_loss: 0.5551 - val_accuracy: 0.7650\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4839 - accuracy: 0.7561 - val_loss: 0.5543 - val_accuracy: 0.7690\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4843 - accuracy: 0.7653 - val_loss: 0.5561 - val_accuracy: 0.7620\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5013 - accuracy: 0.7674 - val_loss: 0.5568 - val_accuracy: 0.7600\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4732 - accuracy: 0.7913 - val_loss: 0.5557 - val_accuracy: 0.7600\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4622 - accuracy: 0.7861 - val_loss: 0.5550 - val_accuracy: 0.7590\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4687 - accuracy: 0.7922 - val_loss: 0.5536 - val_accuracy: 0.7610\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4719 - accuracy: 0.7590 - val_loss: 0.5533 - val_accuracy: 0.7630\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4728 - accuracy: 0.7766 - val_loss: 0.5533 - val_accuracy: 0.7620\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4640 - accuracy: 0.7924 - val_loss: 0.5524 - val_accuracy: 0.7610\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4742 - accuracy: 0.7931 - val_loss: 0.5493 - val_accuracy: 0.7660\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4655 - accuracy: 0.8150 - val_loss: 0.5468 - val_accuracy: 0.7740\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4707 - accuracy: 0.7973 - val_loss: 0.5446 - val_accuracy: 0.7800\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4847 - accuracy: 0.7960 - val_loss: 0.5426 - val_accuracy: 0.7820\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4971 - accuracy: 0.7816 - val_loss: 0.5409 - val_accuracy: 0.7830\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4548 - accuracy: 0.8089 - val_loss: 0.5402 - val_accuracy: 0.7830\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4565 - accuracy: 0.7985 - val_loss: 0.5404 - val_accuracy: 0.7840\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4189 - accuracy: 0.8358 - val_loss: 0.5406 - val_accuracy: 0.7810\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4574 - accuracy: 0.8035 - val_loss: 0.5396 - val_accuracy: 0.7810\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4927 - accuracy: 0.7775 - val_loss: 0.5390 - val_accuracy: 0.7790\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4637 - accuracy: 0.7953 - val_loss: 0.5389 - val_accuracy: 0.7800\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4596 - accuracy: 0.7953 - val_loss: 0.5388 - val_accuracy: 0.7830\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4548 - accuracy: 0.7962 - val_loss: 0.5392 - val_accuracy: 0.7830\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4729 - accuracy: 0.7910 - val_loss: 0.5401 - val_accuracy: 0.7780\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4739 - accuracy: 0.8002 - val_loss: 0.5403 - val_accuracy: 0.7740\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4881 - accuracy: 0.7960 - val_loss: 0.5407 - val_accuracy: 0.7710\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4490 - accuracy: 0.8087 - val_loss: 0.5403 - val_accuracy: 0.7720\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4891 - accuracy: 0.7754 - val_loss: 0.5396 - val_accuracy: 0.7760\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4600 - accuracy: 0.7867 - val_loss: 0.5388 - val_accuracy: 0.7790\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4949 - accuracy: 0.7879 - val_loss: 0.5395 - val_accuracy: 0.7800\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4788 - accuracy: 0.7867 - val_loss: 0.5411 - val_accuracy: 0.7800\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4172 - accuracy: 0.8120 - val_loss: 0.5420 - val_accuracy: 0.7790\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4613 - accuracy: 0.7964 - val_loss: 0.5417 - val_accuracy: 0.7790\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4765 - accuracy: 0.7818 - val_loss: 0.5402 - val_accuracy: 0.7780\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4513 - accuracy: 0.8002 - val_loss: 0.5398 - val_accuracy: 0.7790\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4761 - accuracy: 0.8033 - val_loss: 0.5391 - val_accuracy: 0.7790\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4655 - accuracy: 0.8054 - val_loss: 0.5379 - val_accuracy: 0.7800\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4582 - accuracy: 0.7867 - val_loss: 0.5387 - val_accuracy: 0.7780\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4944 - accuracy: 0.7443 - val_loss: 0.5404 - val_accuracy: 0.7720\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4520 - accuracy: 0.7837 - val_loss: 0.5413 - val_accuracy: 0.7690\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4949 - accuracy: 0.7556 - val_loss: 0.5399 - val_accuracy: 0.7680\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4710 - accuracy: 0.7754 - val_loss: 0.5383 - val_accuracy: 0.7710\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4811 - accuracy: 0.7712 - val_loss: 0.5363 - val_accuracy: 0.7770\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4453 - accuracy: 0.8178 - val_loss: 0.5332 - val_accuracy: 0.7830\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4448 - accuracy: 0.7929 - val_loss: 0.5287 - val_accuracy: 0.7830\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4647 - accuracy: 0.7992 - val_loss: 0.5270 - val_accuracy: 0.7830\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.5267 - val_accuracy: 0.7850\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4891 - accuracy: 0.7639 - val_loss: 0.5283 - val_accuracy: 0.7830\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4604 - accuracy: 0.8002 - val_loss: 0.5300 - val_accuracy: 0.7830\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4690 - accuracy: 0.7938 - val_loss: 0.5306 - val_accuracy: 0.7810\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4460 - accuracy: 0.8032 - val_loss: 0.5312 - val_accuracy: 0.7800\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4538 - accuracy: 0.8000 - val_loss: 0.5306 - val_accuracy: 0.7800\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4441 - accuracy: 0.8271 - val_loss: 0.5303 - val_accuracy: 0.7790\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4296 - accuracy: 0.8157 - val_loss: 0.5293 - val_accuracy: 0.7800\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4362 - accuracy: 0.8198 - val_loss: 0.5275 - val_accuracy: 0.7800\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4347 - accuracy: 0.8013 - val_loss: 0.5243 - val_accuracy: 0.7830\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4334 - accuracy: 0.8065 - val_loss: 0.5222 - val_accuracy: 0.7810\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4277 - accuracy: 0.8179 - val_loss: 0.5212 - val_accuracy: 0.7830\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4739 - accuracy: 0.7938 - val_loss: 0.5213 - val_accuracy: 0.7820\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4610 - accuracy: 0.7752 - val_loss: 0.5207 - val_accuracy: 0.7850\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4454 - accuracy: 0.8075 - val_loss: 0.5204 - val_accuracy: 0.7850\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5220 - val_accuracy: 0.7820\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4327 - accuracy: 0.8176 - val_loss: 0.5261 - val_accuracy: 0.7810\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4798 - accuracy: 0.7895 - val_loss: 0.5284 - val_accuracy: 0.7770\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4216 - accuracy: 0.8415 - val_loss: 0.5277 - val_accuracy: 0.7770\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4357 - accuracy: 0.8249 - val_loss: 0.5214 - val_accuracy: 0.7840\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4887 - accuracy: 0.7957 - val_loss: 0.5173 - val_accuracy: 0.7840\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4231 - accuracy: 0.8125 - val_loss: 0.5152 - val_accuracy: 0.7880\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4233 - accuracy: 0.8334 - val_loss: 0.5147 - val_accuracy: 0.7880\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4433 - accuracy: 0.8000 - val_loss: 0.5154 - val_accuracy: 0.7850\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4439 - accuracy: 0.8157 - val_loss: 0.5172 - val_accuracy: 0.7830\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.8094 - val_loss: 0.5195 - val_accuracy: 0.7830\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4207 - accuracy: 0.8363 - val_loss: 0.5207 - val_accuracy: 0.7820\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4420 - accuracy: 0.8145 - val_loss: 0.5211 - val_accuracy: 0.7780\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4250 - accuracy: 0.8217 - val_loss: 0.5208 - val_accuracy: 0.7780\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3892 - accuracy: 0.8436 - val_loss: 0.5186 - val_accuracy: 0.7830\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4241 - accuracy: 0.8238 - val_loss: 0.5139 - val_accuracy: 0.7820\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.7907 - val_loss: 0.5090 - val_accuracy: 0.7870\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4111 - accuracy: 0.8304 - val_loss: 0.5074 - val_accuracy: 0.7880\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4550 - accuracy: 0.7691 - val_loss: 0.5066 - val_accuracy: 0.7900\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4481 - accuracy: 0.8106 - val_loss: 0.5063 - val_accuracy: 0.7920\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4037 - accuracy: 0.8509 - val_loss: 0.5068 - val_accuracy: 0.7920\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4154 - accuracy: 0.8240 - val_loss: 0.5082 - val_accuracy: 0.7890\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4312 - accuracy: 0.8198 - val_loss: 0.5099 - val_accuracy: 0.7870\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.7717 - val_loss: 0.5105 - val_accuracy: 0.7840\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4302 - accuracy: 0.8249 - val_loss: 0.5088 - val_accuracy: 0.7820\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4091 - accuracy: 0.8396 - val_loss: 0.5070 - val_accuracy: 0.7830\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4337 - accuracy: 0.7948 - val_loss: 0.5041 - val_accuracy: 0.7910\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4184 - accuracy: 0.7990 - val_loss: 0.5026 - val_accuracy: 0.7920\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3948 - accuracy: 0.8301 - val_loss: 0.5021 - val_accuracy: 0.7900\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4214 - accuracy: 0.8124 - val_loss: 0.5017 - val_accuracy: 0.7920\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.8167 - val_loss: 0.5026 - val_accuracy: 0.7910\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8282 - val_loss: 0.5040 - val_accuracy: 0.7880\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.8249 - val_loss: 0.5054 - val_accuracy: 0.7890\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4376 - accuracy: 0.8124 - val_loss: 0.5075 - val_accuracy: 0.7880\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4257 - accuracy: 0.8061 - val_loss: 0.5096 - val_accuracy: 0.7870\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4443 - accuracy: 0.8155 - val_loss: 0.5088 - val_accuracy: 0.7870\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4239 - accuracy: 0.8176 - val_loss: 0.5073 - val_accuracy: 0.7860\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4309 - accuracy: 0.8145 - val_loss: 0.5056 - val_accuracy: 0.7860\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4120 - accuracy: 0.8188 - val_loss: 0.5029 - val_accuracy: 0.7860\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4157 - accuracy: 0.7938 - val_loss: 0.5014 - val_accuracy: 0.7890\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4196 - accuracy: 0.8250 - val_loss: 0.5016 - val_accuracy: 0.7860\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3998 - accuracy: 0.8178 - val_loss: 0.5020 - val_accuracy: 0.7840\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4195 - accuracy: 0.8053 - val_loss: 0.5024 - val_accuracy: 0.7840\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3963 - accuracy: 0.8125 - val_loss: 0.5030 - val_accuracy: 0.7860\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4283 - accuracy: 0.8155 - val_loss: 0.5039 - val_accuracy: 0.7870\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4579 - accuracy: 0.7957 - val_loss: 0.5044 - val_accuracy: 0.7850\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4064 - accuracy: 0.8280 - val_loss: 0.5029 - val_accuracy: 0.7850\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4095 - accuracy: 0.8167 - val_loss: 0.5011 - val_accuracy: 0.7860\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4100 - accuracy: 0.8282 - val_loss: 0.5004 - val_accuracy: 0.7860\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3916 - accuracy: 0.8127 - val_loss: 0.5011 - val_accuracy: 0.7830\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4310 - accuracy: 0.7971 - val_loss: 0.5014 - val_accuracy: 0.7800\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4235 - accuracy: 0.7940 - val_loss: 0.5018 - val_accuracy: 0.7800\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4391 - accuracy: 0.7627 - val_loss: 0.5019 - val_accuracy: 0.7810\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4384 - accuracy: 0.7750 - val_loss: 0.5029 - val_accuracy: 0.7780\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5034 - val_accuracy: 0.7780\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4228 - accuracy: 0.8084 - val_loss: 0.5029 - val_accuracy: 0.7790\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.7938 - val_loss: 0.5027 - val_accuracy: 0.7800\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7810\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3774 - accuracy: 0.8323 - val_loss: 0.4988 - val_accuracy: 0.7860\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4329 - accuracy: 0.7938 - val_loss: 0.4946 - val_accuracy: 0.7890\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4025 - accuracy: 0.8178 - val_loss: 0.4936 - val_accuracy: 0.7910\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4114 - accuracy: 0.8217 - val_loss: 0.4932 - val_accuracy: 0.7900\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4235 - accuracy: 0.8282 - val_loss: 0.4932 - val_accuracy: 0.7890\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4187 - accuracy: 0.8000 - val_loss: 0.4937 - val_accuracy: 0.7890\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4170 - accuracy: 0.7844 - val_loss: 0.4960 - val_accuracy: 0.7870\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4375 - accuracy: 0.7813 - val_loss: 0.5012 - val_accuracy: 0.7810\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.8417 - val_loss: 0.5050 - val_accuracy: 0.7790\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3943 - accuracy: 0.8240 - val_loss: 0.5040 - val_accuracy: 0.7800\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4311 - accuracy: 0.7936 - val_loss: 0.5029 - val_accuracy: 0.7800\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4259 - accuracy: 0.8051 - val_loss: 0.5025 - val_accuracy: 0.7820\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3877 - accuracy: 0.8270 - val_loss: 0.5013 - val_accuracy: 0.7820\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4100 - accuracy: 0.8186 - val_loss: 0.4984 - val_accuracy: 0.7840\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4142 - accuracy: 0.8082 - val_loss: 0.4950 - val_accuracy: 0.7860\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4034 - accuracy: 0.8115 - val_loss: 0.4916 - val_accuracy: 0.7910\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4073 - accuracy: 0.8209 - val_loss: 0.4898 - val_accuracy: 0.7920\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4094 - accuracy: 0.8053 - val_loss: 0.4891 - val_accuracy: 0.7940\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4046 - accuracy: 0.8146 - val_loss: 0.4893 - val_accuracy: 0.7920\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3654 - accuracy: 0.8395 - val_loss: 0.4905 - val_accuracy: 0.7920\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3865 - accuracy: 0.8209 - val_loss: 0.4899 - val_accuracy: 0.7900\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8063 - val_loss: 0.4876 - val_accuracy: 0.7920\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.8084 - val_loss: 0.4865 - val_accuracy: 0.7920\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3710 - accuracy: 0.8209 - val_loss: 0.4863 - val_accuracy: 0.7910\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4000 - accuracy: 0.8032 - val_loss: 0.4869 - val_accuracy: 0.7900\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3975 - accuracy: 0.7959 - val_loss: 0.4869 - val_accuracy: 0.7900\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3889 - accuracy: 0.7990 - val_loss: 0.4863 - val_accuracy: 0.7880\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4145 - accuracy: 0.7938 - val_loss: 0.4856 - val_accuracy: 0.7880\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4164 - accuracy: 0.8094 - val_loss: 0.4850 - val_accuracy: 0.7910\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3870 - accuracy: 0.8125 - val_loss: 0.4847 - val_accuracy: 0.7900\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.4845 - val_accuracy: 0.7890\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3946 - accuracy: 0.8219 - val_loss: 0.4836 - val_accuracy: 0.7900\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3887 - accuracy: 0.8209 - val_loss: 0.4840 - val_accuracy: 0.7880\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3879 - accuracy: 0.8240 - val_loss: 0.4854 - val_accuracy: 0.7890\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3917 - accuracy: 0.8084 - val_loss: 0.4857 - val_accuracy: 0.7880\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3922 - accuracy: 0.8270 - val_loss: 0.4843 - val_accuracy: 0.7890\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8209 - val_loss: 0.4818 - val_accuracy: 0.7940\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4031 - accuracy: 0.8042 - val_loss: 0.4802 - val_accuracy: 0.7980\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.8176 - val_loss: 0.4795 - val_accuracy: 0.7970\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4275 - accuracy: 0.7938 - val_loss: 0.4794 - val_accuracy: 0.7950\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4080 - accuracy: 0.8084 - val_loss: 0.4796 - val_accuracy: 0.7930\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4060 - accuracy: 0.7907 - val_loss: 0.4817 - val_accuracy: 0.7890\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3818 - accuracy: 0.8238 - val_loss: 0.4834 - val_accuracy: 0.7870\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3799 - accuracy: 0.8322 - val_loss: 0.4832 - val_accuracy: 0.7860\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3880 - accuracy: 0.8124 - val_loss: 0.4813 - val_accuracy: 0.7880\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3902 - accuracy: 0.8155 - val_loss: 0.4805 - val_accuracy: 0.7900\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3731 - accuracy: 0.8084 - val_loss: 0.4798 - val_accuracy: 0.7920\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3684 - accuracy: 0.8250 - val_loss: 0.4782 - val_accuracy: 0.7950\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3922 - accuracy: 0.8188 - val_loss: 0.4774 - val_accuracy: 0.7980\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3865 - accuracy: 0.8032 - val_loss: 0.4769 - val_accuracy: 0.8010\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3899 - accuracy: 0.8311 - val_loss: 0.4769 - val_accuracy: 0.8010\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.8334 - val_loss: 0.4780 - val_accuracy: 0.7960\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4308 - accuracy: 0.7834 - val_loss: 0.4787 - val_accuracy: 0.7930\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3780 - accuracy: 0.8157 - val_loss: 0.4788 - val_accuracy: 0.7930\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.8240 - val_loss: 0.4781 - val_accuracy: 0.7940\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3904 - accuracy: 0.8240 - val_loss: 0.4776 - val_accuracy: 0.7970\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3988 - accuracy: 0.7896 - val_loss: 0.4781 - val_accuracy: 0.7980\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3586 - accuracy: 0.8250 - val_loss: 0.4780 - val_accuracy: 0.7980\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3998 - accuracy: 0.7907 - val_loss: 0.4782 - val_accuracy: 0.7990\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3936 - accuracy: 0.7938 - val_loss: 0.4784 - val_accuracy: 0.7950\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3895 - accuracy: 0.8053 - val_loss: 0.4794 - val_accuracy: 0.7950\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3874 - accuracy: 0.8115 - val_loss: 0.4788 - val_accuracy: 0.7960\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4029 - accuracy: 0.8053 - val_loss: 0.4775 - val_accuracy: 0.7980\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.8000 - val_loss: 0.4765 - val_accuracy: 0.7950\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3725 - accuracy: 0.8178 - val_loss: 0.4762 - val_accuracy: 0.7960\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3998 - accuracy: 0.7907 - val_loss: 0.4772 - val_accuracy: 0.7960\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3810 - accuracy: 0.7928 - val_loss: 0.4793 - val_accuracy: 0.7940\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3757 - accuracy: 0.8249 - val_loss: 0.4804 - val_accuracy: 0.7950\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3978 - accuracy: 0.8134 - val_loss: 0.4800 - val_accuracy: 0.7950\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3952 - accuracy: 0.8155 - val_loss: 0.4772 - val_accuracy: 0.7950\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.8145 - val_loss: 0.4765 - val_accuracy: 0.7960\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3895 - accuracy: 0.8155 - val_loss: 0.4756 - val_accuracy: 0.7970\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3597 - accuracy: 0.8217 - val_loss: 0.4754 - val_accuracy: 0.7960\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3738 - accuracy: 0.8021 - val_loss: 0.4755 - val_accuracy: 0.7970\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8020 - val_loss: 0.4756 - val_accuracy: 0.7960\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3667 - accuracy: 0.8322 - val_loss: 0.4756 - val_accuracy: 0.7960\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3691 - accuracy: 0.8414 - val_loss: 0.4748 - val_accuracy: 0.7960\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3777 - accuracy: 0.8197 - val_loss: 0.4736 - val_accuracy: 0.7970\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.8342 - val_loss: 0.4729 - val_accuracy: 0.7980\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3692 - accuracy: 0.8374 - val_loss: 0.4729 - val_accuracy: 0.7980\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8082 - val_loss: 0.4725 - val_accuracy: 0.7990\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3754 - accuracy: 0.8207 - val_loss: 0.4726 - val_accuracy: 0.8020\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3987 - accuracy: 0.8113 - val_loss: 0.4734 - val_accuracy: 0.7990\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3874 - accuracy: 0.8197 - val_loss: 0.4750 - val_accuracy: 0.7950\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4028 - accuracy: 0.8028 - val_loss: 0.4757 - val_accuracy: 0.7950\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3592 - accuracy: 0.8487 - val_loss: 0.4758 - val_accuracy: 0.7970\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3765 - accuracy: 0.8362 - val_loss: 0.4754 - val_accuracy: 0.7960\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3877 - accuracy: 0.8080 - val_loss: 0.4765 - val_accuracy: 0.7950\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3762 - accuracy: 0.8362 - val_loss: 0.4780 - val_accuracy: 0.7960\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3958 - accuracy: 0.8112 - val_loss: 0.4782 - val_accuracy: 0.7930\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3372 - accuracy: 0.8674 - val_loss: 0.4769 - val_accuracy: 0.7940\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3930 - accuracy: 0.8247 - val_loss: 0.4756 - val_accuracy: 0.7960\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.8186 - val_loss: 0.4754 - val_accuracy: 0.7960\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.8249 - val_loss: 0.4751 - val_accuracy: 0.7960\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3523 - accuracy: 0.8240 - val_loss: 0.4733 - val_accuracy: 0.7990\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3783 - accuracy: 0.8002 - val_loss: 0.4723 - val_accuracy: 0.8040\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3818 - accuracy: 0.7929 - val_loss: 0.4722 - val_accuracy: 0.8050\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3520 - accuracy: 0.8263 - val_loss: 0.4729 - val_accuracy: 0.8000\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3942 - accuracy: 0.7875 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3988 - accuracy: 0.7865 - val_loss: 0.4750 - val_accuracy: 0.7970\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3817 - accuracy: 0.8217 - val_loss: 0.4752 - val_accuracy: 0.7950\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4062 - accuracy: 0.7936 - val_loss: 0.4754 - val_accuracy: 0.7930\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 0.8259 - val_loss: 0.4747 - val_accuracy: 0.7930\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3515 - accuracy: 0.8280 - val_loss: 0.4737 - val_accuracy: 0.7990\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3842 - accuracy: 0.8020 - val_loss: 0.4729 - val_accuracy: 0.7980\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3518 - accuracy: 0.7988 - val_loss: 0.4716 - val_accuracy: 0.8020\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3765 - accuracy: 0.8092 - val_loss: 0.4696 - val_accuracy: 0.8100\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3676 - accuracy: 0.8311 - val_loss: 0.4688 - val_accuracy: 0.8110\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3654 - accuracy: 0.8238 - val_loss: 0.4680 - val_accuracy: 0.8130\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3465 - accuracy: 0.8332 - val_loss: 0.4683 - val_accuracy: 0.8140\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3970 - accuracy: 0.7999 - val_loss: 0.4685 - val_accuracy: 0.8160\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3719 - accuracy: 0.8216 - val_loss: 0.4691 - val_accuracy: 0.8120\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3559 - accuracy: 0.8195 - val_loss: 0.4695 - val_accuracy: 0.8140\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3366 - accuracy: 0.8436 - val_loss: 0.4697 - val_accuracy: 0.8100\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3485 - accuracy: 0.8301 - val_loss: 0.4697 - val_accuracy: 0.8080\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3463 - accuracy: 0.8301 - val_loss: 0.4693 - val_accuracy: 0.8060\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3577 - accuracy: 0.8238 - val_loss: 0.4680 - val_accuracy: 0.8120\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3863 - accuracy: 0.8134 - val_loss: 0.4676 - val_accuracy: 0.8100\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3923 - accuracy: 0.8061 - val_loss: 0.4682 - val_accuracy: 0.8050\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3617 - accuracy: 0.8249 - val_loss: 0.4692 - val_accuracy: 0.8020\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3606 - accuracy: 0.8332 - val_loss: 0.4710 - val_accuracy: 0.7970\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3506 - accuracy: 0.8497 - val_loss: 0.4737 - val_accuracy: 0.7950\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3456 - accuracy: 0.8558 - val_loss: 0.4778 - val_accuracy: 0.7920\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.8589 - val_loss: 0.4803 - val_accuracy: 0.7880\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3907 - accuracy: 0.8213 - val_loss: 0.4798 - val_accuracy: 0.7880\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.8515 - val_loss: 0.4773 - val_accuracy: 0.7900\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3794 - accuracy: 0.8431 - val_loss: 0.4741 - val_accuracy: 0.7950\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3664 - accuracy: 0.8402 - val_loss: 0.4717 - val_accuracy: 0.8020\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3671 - accuracy: 0.8310 - val_loss: 0.4699 - val_accuracy: 0.8010\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3409 - accuracy: 0.8518 - val_loss: 0.4687 - val_accuracy: 0.8080\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3407 - accuracy: 0.8447 - val_loss: 0.4677 - val_accuracy: 0.8080\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3777 - accuracy: 0.8115 - val_loss: 0.4669 - val_accuracy: 0.8110\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 0.8063 - val_loss: 0.4662 - val_accuracy: 0.8140\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3355 - accuracy: 0.8362 - val_loss: 0.4653 - val_accuracy: 0.8200\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3621 - accuracy: 0.8339 - val_loss: 0.4649 - val_accuracy: 0.8190\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3868 - accuracy: 0.8214 - val_loss: 0.4651 - val_accuracy: 0.8180\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3717 - accuracy: 0.8245 - val_loss: 0.4661 - val_accuracy: 0.8150\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3869 - accuracy: 0.8400 - val_loss: 0.4674 - val_accuracy: 0.8120\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3588 - accuracy: 0.8330 - val_loss: 0.4687 - val_accuracy: 0.8070\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.8080 - val_loss: 0.4694 - val_accuracy: 0.8050\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3484 - accuracy: 0.8495 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3732 - accuracy: 0.8329 - val_loss: 0.4697 - val_accuracy: 0.8040\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3857 - accuracy: 0.8122 - val_loss: 0.4680 - val_accuracy: 0.8090\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3456 - accuracy: 0.8466 - val_loss: 0.4666 - val_accuracy: 0.8090\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3499 - accuracy: 0.8516 - val_loss: 0.4661 - val_accuracy: 0.8100\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3480 - accuracy: 0.8145 - val_loss: 0.4656 - val_accuracy: 0.8120\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3514 - accuracy: 0.8412 - val_loss: 0.4659 - val_accuracy: 0.8120\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3236 - accuracy: 0.8551 - val_loss: 0.4663 - val_accuracy: 0.8100\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3833 - accuracy: 0.8205 - val_loss: 0.4673 - val_accuracy: 0.8090\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3506 - accuracy: 0.8339 - val_loss: 0.4708 - val_accuracy: 0.8030\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3625 - accuracy: 0.8329 - val_loss: 0.4726 - val_accuracy: 0.8020\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.8225 - val_loss: 0.4722 - val_accuracy: 0.8010\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3715 - accuracy: 0.8381 - val_loss: 0.4702 - val_accuracy: 0.8070\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3886 - accuracy: 0.8214 - val_loss: 0.4699 - val_accuracy: 0.8070\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3799 - accuracy: 0.8567 - val_loss: 0.4695 - val_accuracy: 0.8090\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3379 - accuracy: 0.8588 - val_loss: 0.4681 - val_accuracy: 0.8090\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3370 - accuracy: 0.8629 - val_loss: 0.4669 - val_accuracy: 0.8110\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3654 - accuracy: 0.8516 - val_loss: 0.4657 - val_accuracy: 0.8140\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3338 - accuracy: 0.8528 - val_loss: 0.4646 - val_accuracy: 0.8170\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3664 - accuracy: 0.8174 - val_loss: 0.4644 - val_accuracy: 0.8180\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3522 - accuracy: 0.8360 - val_loss: 0.4645 - val_accuracy: 0.8180\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3469 - accuracy: 0.8341 - val_loss: 0.4655 - val_accuracy: 0.8170\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3626 - accuracy: 0.8143 - val_loss: 0.4669 - val_accuracy: 0.8150\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3721 - accuracy: 0.8216 - val_loss: 0.4679 - val_accuracy: 0.8110\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3660 - accuracy: 0.8122 - val_loss: 0.4697 - val_accuracy: 0.8110\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3490 - accuracy: 0.8339 - val_loss: 0.4705 - val_accuracy: 0.8100\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3627 - accuracy: 0.8299 - val_loss: 0.4690 - val_accuracy: 0.8100\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3668 - accuracy: 0.8278 - val_loss: 0.4669 - val_accuracy: 0.8170\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3359 - accuracy: 0.8278 - val_loss: 0.4658 - val_accuracy: 0.8190\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3688 - accuracy: 0.8330 - val_loss: 0.4643 - val_accuracy: 0.8200\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 0.8435 - val_loss: 0.4636 - val_accuracy: 0.8200\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3493 - accuracy: 0.8301 - val_loss: 0.4636 - val_accuracy: 0.8200\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3299 - accuracy: 0.8487 - val_loss: 0.4642 - val_accuracy: 0.8200\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3509 - accuracy: 0.8247 - val_loss: 0.4661 - val_accuracy: 0.8180\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3569 - accuracy: 0.8362 - val_loss: 0.4679 - val_accuracy: 0.8110\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3552 - accuracy: 0.8183 - val_loss: 0.4693 - val_accuracy: 0.8110\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 0.8400 - val_loss: 0.4691 - val_accuracy: 0.8110\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3357 - accuracy: 0.8547 - val_loss: 0.4688 - val_accuracy: 0.8120\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3588 - accuracy: 0.8214 - val_loss: 0.4680 - val_accuracy: 0.8110\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3428 - accuracy: 0.8558 - val_loss: 0.4673 - val_accuracy: 0.8130\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3197 - accuracy: 0.8570 - val_loss: 0.4673 - val_accuracy: 0.8130\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3312 - accuracy: 0.8393 - val_loss: 0.4684 - val_accuracy: 0.8100\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3645 - accuracy: 0.8268 - val_loss: 0.4691 - val_accuracy: 0.8090\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3607 - accuracy: 0.8185 - val_loss: 0.4692 - val_accuracy: 0.8090\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3428 - accuracy: 0.8237 - val_loss: 0.4681 - val_accuracy: 0.8080\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3554 - accuracy: 0.8080 - val_loss: 0.4655 - val_accuracy: 0.8120\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3953 - accuracy: 0.8091 - val_loss: 0.4645 - val_accuracy: 0.8120\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3573 - accuracy: 0.8360 - val_loss: 0.4642 - val_accuracy: 0.8090\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3275 - accuracy: 0.8475 - val_loss: 0.4647 - val_accuracy: 0.8030\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3476 - accuracy: 0.8527 - val_loss: 0.4655 - val_accuracy: 0.8050\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.8518 - val_loss: 0.4661 - val_accuracy: 0.8060\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3418 - accuracy: 0.8445 - val_loss: 0.4642 - val_accuracy: 0.8130\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3301 - accuracy: 0.8497 - val_loss: 0.4633 - val_accuracy: 0.8160\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3283 - accuracy: 0.8640 - val_loss: 0.4632 - val_accuracy: 0.8150\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3654 - accuracy: 0.7903 - val_loss: 0.4632 - val_accuracy: 0.8170\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.8422 - val_loss: 0.4641 - val_accuracy: 0.8180\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3553 - accuracy: 0.8235 - val_loss: 0.4648 - val_accuracy: 0.8220\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3607 - accuracy: 0.8245 - val_loss: 0.4649 - val_accuracy: 0.8180\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3279 - accuracy: 0.8735 - val_loss: 0.4656 - val_accuracy: 0.8160\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3239 - accuracy: 0.8485 - val_loss: 0.4676 - val_accuracy: 0.8150\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3410 - accuracy: 0.8546 - val_loss: 0.4701 - val_accuracy: 0.8090\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3541 - accuracy: 0.8174 - val_loss: 0.4731 - val_accuracy: 0.8050\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3555 - accuracy: 0.8235 - val_loss: 0.4746 - val_accuracy: 0.7960\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.8516 - val_loss: 0.4746 - val_accuracy: 0.7950\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3466 - accuracy: 0.8422 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3032 - accuracy: 0.8653 - val_loss: 0.4699 - val_accuracy: 0.8040\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3199 - accuracy: 0.8424 - val_loss: 0.4682 - val_accuracy: 0.8020\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3269 - accuracy: 0.8516 - val_loss: 0.4674 - val_accuracy: 0.8000\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3419 - accuracy: 0.8308 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3472 - accuracy: 0.8370 - val_loss: 0.4677 - val_accuracy: 0.8020\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3255 - accuracy: 0.8560 - val_loss: 0.4689 - val_accuracy: 0.8010\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3452 - accuracy: 0.8278 - val_loss: 0.4716 - val_accuracy: 0.7980\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3319 - accuracy: 0.8610 - val_loss: 0.4754 - val_accuracy: 0.7950\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3387 - accuracy: 0.8339 - val_loss: 0.4781 - val_accuracy: 0.7950\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3386 - accuracy: 0.8245 - val_loss: 0.4780 - val_accuracy: 0.8020\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3313 - accuracy: 0.8558 - val_loss: 0.4760 - val_accuracy: 0.8050\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3290 - accuracy: 0.8515 - val_loss: 0.4737 - val_accuracy: 0.8090\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3535 - accuracy: 0.8483 - val_loss: 0.4698 - val_accuracy: 0.8140\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3717 - accuracy: 0.8367 - val_loss: 0.4666 - val_accuracy: 0.8170\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3201 - accuracy: 0.8577 - val_loss: 0.4650 - val_accuracy: 0.8190\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3268 - accuracy: 0.8516 - val_loss: 0.4638 - val_accuracy: 0.8190\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8610 - val_loss: 0.4639 - val_accuracy: 0.8160\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3364 - accuracy: 0.8402 - val_loss: 0.4652 - val_accuracy: 0.8110\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3396 - accuracy: 0.8332 - val_loss: 0.4664 - val_accuracy: 0.8100\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3350 - accuracy: 0.8092 - val_loss: 0.4672 - val_accuracy: 0.8060\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3412 - accuracy: 0.8217 - val_loss: 0.4681 - val_accuracy: 0.8040\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3326 - accuracy: 0.8157 - val_loss: 0.4678 - val_accuracy: 0.8050\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3683 - accuracy: 0.8124 - val_loss: 0.4671 - val_accuracy: 0.8070\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3336 - accuracy: 0.8455 - val_loss: 0.4668 - val_accuracy: 0.8070\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3124 - accuracy: 0.8372 - val_loss: 0.4675 - val_accuracy: 0.8120\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3215 - accuracy: 0.8374 - val_loss: 0.4693 - val_accuracy: 0.8100\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3128 - accuracy: 0.8414 - val_loss: 0.4693 - val_accuracy: 0.8120\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2929 - accuracy: 0.8683 - val_loss: 0.4664 - val_accuracy: 0.8170\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3162 - accuracy: 0.8702 - val_loss: 0.4651 - val_accuracy: 0.8180\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3345 - accuracy: 0.8464 - val_loss: 0.4652 - val_accuracy: 0.8180\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3333 - accuracy: 0.8422 - val_loss: 0.4656 - val_accuracy: 0.8180\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3384 - accuracy: 0.8485 - val_loss: 0.4669 - val_accuracy: 0.8180\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3625 - accuracy: 0.8327 - val_loss: 0.4695 - val_accuracy: 0.8160\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3326 - accuracy: 0.8671 - val_loss: 0.4722 - val_accuracy: 0.8090\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3486 - accuracy: 0.8464 - val_loss: 0.4733 - val_accuracy: 0.8030\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3546 - accuracy: 0.8362 - val_loss: 0.4735 - val_accuracy: 0.8010\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3343 - accuracy: 0.8435 - val_loss: 0.4728 - val_accuracy: 0.8000\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3324 - accuracy: 0.8278 - val_loss: 0.4727 - val_accuracy: 0.8020\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3528 - accuracy: 0.8120 - val_loss: 0.4725 - val_accuracy: 0.8020\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3459 - accuracy: 0.8185 - val_loss: 0.4722 - val_accuracy: 0.8020\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3181 - accuracy: 0.8249 - val_loss: 0.4727 - val_accuracy: 0.8020\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3487 - accuracy: 0.8155 - val_loss: 0.4723 - val_accuracy: 0.8020\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3474 - accuracy: 0.7928 - val_loss: 0.4713 - val_accuracy: 0.8040\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3168 - accuracy: 0.8395 - val_loss: 0.4721 - val_accuracy: 0.8040\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3151 - accuracy: 0.8249 - val_loss: 0.4726 - val_accuracy: 0.8040\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3317 - accuracy: 0.8238 - val_loss: 0.4737 - val_accuracy: 0.8030\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3227 - accuracy: 0.8311 - val_loss: 0.4746 - val_accuracy: 0.8010\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3148 - accuracy: 0.8353 - val_loss: 0.4745 - val_accuracy: 0.8010\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3350 - accuracy: 0.8249 - val_loss: 0.4736 - val_accuracy: 0.8030\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3202 - accuracy: 0.8322 - val_loss: 0.4739 - val_accuracy: 0.8030\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3194 - accuracy: 0.8301 - val_loss: 0.4755 - val_accuracy: 0.8010\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2914 - accuracy: 0.8560 - val_loss: 0.4762 - val_accuracy: 0.8010\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3561 - accuracy: 0.8060 - val_loss: 0.4768 - val_accuracy: 0.7990\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3370 - accuracy: 0.8403 - val_loss: 0.4778 - val_accuracy: 0.7970\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3191 - accuracy: 0.8560 - val_loss: 0.4780 - val_accuracy: 0.7960\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3308 - accuracy: 0.8362 - val_loss: 0.4771 - val_accuracy: 0.7990\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.8351 - val_loss: 0.4744 - val_accuracy: 0.8040\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3232 - accuracy: 0.8186 - val_loss: 0.4690 - val_accuracy: 0.8140\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2975 - accuracy: 0.8705 - val_loss: 0.4668 - val_accuracy: 0.8190\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3256 - accuracy: 0.8422 - val_loss: 0.4664 - val_accuracy: 0.8190\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3285 - accuracy: 0.8516 - val_loss: 0.4664 - val_accuracy: 0.8180\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 0.8494 - val_loss: 0.4674 - val_accuracy: 0.8150\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 0.8702 - val_loss: 0.4676 - val_accuracy: 0.8140\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3588 - accuracy: 0.8297 - val_loss: 0.4687 - val_accuracy: 0.8090\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3520 - accuracy: 0.8226 - val_loss: 0.4700 - val_accuracy: 0.8070\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3160 - accuracy: 0.8268 - val_loss: 0.4706 - val_accuracy: 0.8020\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3449 - accuracy: 0.8391 - val_loss: 0.4715 - val_accuracy: 0.8020\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3470 - accuracy: 0.8214 - val_loss: 0.4712 - val_accuracy: 0.8020\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3382 - accuracy: 0.8245 - val_loss: 0.4714 - val_accuracy: 0.8020\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3221 - accuracy: 0.8516 - val_loss: 0.4717 - val_accuracy: 0.8030\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3048 - accuracy: 0.8487 - val_loss: 0.4693 - val_accuracy: 0.8030\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3153 - accuracy: 0.8464 - val_loss: 0.4686 - val_accuracy: 0.8030\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3079 - accuracy: 0.8641 - val_loss: 0.4685 - val_accuracy: 0.8020\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3383 - accuracy: 0.8277 - val_loss: 0.4683 - val_accuracy: 0.8010\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3521 - accuracy: 0.8152 - val_loss: 0.4695 - val_accuracy: 0.8020\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3438 - accuracy: 0.8350 - val_loss: 0.4700 - val_accuracy: 0.8010\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3291 - accuracy: 0.8247 - val_loss: 0.4700 - val_accuracy: 0.8050\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3348 - accuracy: 0.7926 - val_loss: 0.4692 - val_accuracy: 0.8070\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3473 - accuracy: 0.8183 - val_loss: 0.4662 - val_accuracy: 0.8130\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3136 - accuracy: 0.8692 - val_loss: 0.4650 - val_accuracy: 0.8150\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3382 - accuracy: 0.8297 - val_loss: 0.4641 - val_accuracy: 0.8190\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3481 - accuracy: 0.8089 - val_loss: 0.4638 - val_accuracy: 0.8190\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3123 - accuracy: 0.8650 - val_loss: 0.4635 - val_accuracy: 0.8180\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3373 - accuracy: 0.8339 - val_loss: 0.4636 - val_accuracy: 0.8170\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3364 - accuracy: 0.8494 - val_loss: 0.4643 - val_accuracy: 0.8160\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3390 - accuracy: 0.8306 - val_loss: 0.4650 - val_accuracy: 0.8140\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3319 - accuracy: 0.8494 - val_loss: 0.4663 - val_accuracy: 0.8090\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3208 - accuracy: 0.8402 - val_loss: 0.4687 - val_accuracy: 0.8100\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3300 - accuracy: 0.8289 - val_loss: 0.4698 - val_accuracy: 0.8070\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3293 - accuracy: 0.8113 - val_loss: 0.4701 - val_accuracy: 0.8070\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2813 - accuracy: 0.8747 - val_loss: 0.4711 - val_accuracy: 0.8090\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3318 - accuracy: 0.8310 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3152 - accuracy: 0.8598 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8556 - val_loss: 0.4705 - val_accuracy: 0.8090\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3460 - accuracy: 0.8433 - val_loss: 0.4699 - val_accuracy: 0.8070\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3071 - accuracy: 0.8589 - val_loss: 0.4700 - val_accuracy: 0.8050\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3169 - accuracy: 0.8422 - val_loss: 0.4706 - val_accuracy: 0.8040\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3084 - accuracy: 0.8433 - val_loss: 0.4713 - val_accuracy: 0.8010\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3276 - accuracy: 0.8391 - val_loss: 0.4718 - val_accuracy: 0.8030\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3140 - accuracy: 0.8579 - val_loss: 0.4719 - val_accuracy: 0.8030\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3155 - accuracy: 0.8547 - val_loss: 0.4716 - val_accuracy: 0.8030\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.8028 - val_loss: 0.4714 - val_accuracy: 0.8010\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.8485 - val_loss: 0.4717 - val_accuracy: 0.8010\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3240 - accuracy: 0.8277 - val_loss: 0.4734 - val_accuracy: 0.7990\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3525 - accuracy: 0.8028 - val_loss: 0.4743 - val_accuracy: 0.7990\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2961 - accuracy: 0.8714 - val_loss: 0.4750 - val_accuracy: 0.8010\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3102 - accuracy: 0.8495 - val_loss: 0.4749 - val_accuracy: 0.8010\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3387 - accuracy: 0.8091 - val_loss: 0.4742 - val_accuracy: 0.8010\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2968 - accuracy: 0.8341 - val_loss: 0.4745 - val_accuracy: 0.8010\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3302 - accuracy: 0.8402 - val_loss: 0.4762 - val_accuracy: 0.7990\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3183 - accuracy: 0.8464 - val_loss: 0.4775 - val_accuracy: 0.8000\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3056 - accuracy: 0.8714 - val_loss: 0.4787 - val_accuracy: 0.7990\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3144 - accuracy: 0.8454 - val_loss: 0.4790 - val_accuracy: 0.7990\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3414 - accuracy: 0.8310 - val_loss: 0.4794 - val_accuracy: 0.7970\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3678 - accuracy: 0.8028 - val_loss: 0.4789 - val_accuracy: 0.7980\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3495 - accuracy: 0.8091 - val_loss: 0.4790 - val_accuracy: 0.7980\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3264 - accuracy: 0.8341 - val_loss: 0.4793 - val_accuracy: 0.7990\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3485 - accuracy: 0.8174 - val_loss: 0.4790 - val_accuracy: 0.7990\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3122 - accuracy: 0.8527 - val_loss: 0.4773 - val_accuracy: 0.8000\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2942 - accuracy: 0.8558 - val_loss: 0.4758 - val_accuracy: 0.7990\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3397 - accuracy: 0.8297 - val_loss: 0.4747 - val_accuracy: 0.8000\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3182 - accuracy: 0.8360 - val_loss: 0.4734 - val_accuracy: 0.8020\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3320 - accuracy: 0.8310 - val_loss: 0.4726 - val_accuracy: 0.8030\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3469 - accuracy: 0.8091 - val_loss: 0.4725 - val_accuracy: 0.8060\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3247 - accuracy: 0.8197 - val_loss: 0.4725 - val_accuracy: 0.8090\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2847 - accuracy: 0.8487 - val_loss: 0.4729 - val_accuracy: 0.8100\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3192 - accuracy: 0.8515 - val_loss: 0.4749 - val_accuracy: 0.8080\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2971 - accuracy: 0.8744 - val_loss: 0.4789 - val_accuracy: 0.8050\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3188 - accuracy: 0.8433 - val_loss: 0.4834 - val_accuracy: 0.8030\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3151 - accuracy: 0.8475 - val_loss: 0.4862 - val_accuracy: 0.7990\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.8216 - val_loss: 0.4883 - val_accuracy: 0.7970\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3124 - accuracy: 0.8568 - val_loss: 0.4872 - val_accuracy: 0.7950\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3588 - accuracy: 0.8120 - val_loss: 0.4840 - val_accuracy: 0.7990\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3602 - accuracy: 0.8089 - val_loss: 0.4813 - val_accuracy: 0.8010\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2995 - accuracy: 0.8640 - val_loss: 0.4784 - val_accuracy: 0.8020\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3298 - accuracy: 0.8185 - val_loss: 0.4767 - val_accuracy: 0.8050\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3053 - accuracy: 0.8341 - val_loss: 0.4761 - val_accuracy: 0.8050\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3302 - accuracy: 0.8476 - val_loss: 0.4760 - val_accuracy: 0.8040\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3174 - accuracy: 0.8207 - val_loss: 0.4757 - val_accuracy: 0.8040\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3077 - accuracy: 0.8186 - val_loss: 0.4759 - val_accuracy: 0.8010\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2954 - accuracy: 0.8539 - val_loss: 0.4755 - val_accuracy: 0.8020\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3375 - accuracy: 0.8176 - val_loss: 0.4738 - val_accuracy: 0.8130\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2961 - accuracy: 0.8457 - val_loss: 0.4732 - val_accuracy: 0.8150\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3242 - accuracy: 0.8278 - val_loss: 0.4737 - val_accuracy: 0.8120\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3230 - accuracy: 0.8433 - val_loss: 0.4747 - val_accuracy: 0.8090\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3399 - accuracy: 0.8329 - val_loss: 0.4755 - val_accuracy: 0.8060\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3066 - accuracy: 0.8547 - val_loss: 0.4775 - val_accuracy: 0.8060\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3253 - accuracy: 0.8268 - val_loss: 0.4797 - val_accuracy: 0.8060\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3444 - accuracy: 0.8431 - val_loss: 0.4789 - val_accuracy: 0.8060\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3334 - accuracy: 0.8463 - val_loss: 0.4779 - val_accuracy: 0.8080\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3089 - accuracy: 0.8577 - val_loss: 0.4765 - val_accuracy: 0.8080\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3049 - accuracy: 0.8463 - val_loss: 0.4756 - val_accuracy: 0.8120\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2963 - accuracy: 0.8681 - val_loss: 0.4755 - val_accuracy: 0.8120\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2895 - accuracy: 0.8619 - val_loss: 0.4761 - val_accuracy: 0.8140\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3087 - accuracy: 0.8681 - val_loss: 0.4764 - val_accuracy: 0.8130\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3273 - accuracy: 0.8327 - val_loss: 0.4771 - val_accuracy: 0.8120\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3005 - accuracy: 0.8515 - val_loss: 0.4774 - val_accuracy: 0.8150\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3368 - accuracy: 0.8327 - val_loss: 0.4787 - val_accuracy: 0.8140\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3379 - accuracy: 0.8327 - val_loss: 0.4791 - val_accuracy: 0.8140\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3341 - accuracy: 0.8422 - val_loss: 0.4796 - val_accuracy: 0.8140\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3349 - accuracy: 0.8400 - val_loss: 0.4817 - val_accuracy: 0.8130\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3122 - accuracy: 0.8773 - val_loss: 0.4850 - val_accuracy: 0.8100\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2801 - accuracy: 0.8878 - val_loss: 0.4857 - val_accuracy: 0.8080\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3050 - accuracy: 0.8638 - val_loss: 0.4823 - val_accuracy: 0.8120\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3435 - accuracy: 0.8398 - val_loss: 0.4765 - val_accuracy: 0.8140\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3061 - accuracy: 0.8588 - val_loss: 0.4742 - val_accuracy: 0.8160\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.8575 - val_loss: 0.4733 - val_accuracy: 0.8160\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3366 - accuracy: 0.8327 - val_loss: 0.4732 - val_accuracy: 0.8130\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8640 - val_loss: 0.4735 - val_accuracy: 0.8140\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3230 - accuracy: 0.8296 - val_loss: 0.4744 - val_accuracy: 0.8130\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3459 - accuracy: 0.8244 - val_loss: 0.4749 - val_accuracy: 0.8140\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3395 - accuracy: 0.8336 - val_loss: 0.4760 - val_accuracy: 0.8110\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3228 - accuracy: 0.8513 - val_loss: 0.4778 - val_accuracy: 0.8100\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3334 - accuracy: 0.8277 - val_loss: 0.4775 - val_accuracy: 0.8120\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3352 - accuracy: 0.8422 - val_loss: 0.4774 - val_accuracy: 0.8120\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3019 - accuracy: 0.8516 - val_loss: 0.4779 - val_accuracy: 0.8090\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3138 - accuracy: 0.8464 - val_loss: 0.4797 - val_accuracy: 0.8090\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3356 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.8090\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3423 - accuracy: 0.8494 - val_loss: 0.4802 - val_accuracy: 0.8090\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3476 - accuracy: 0.8296 - val_loss: 0.4794 - val_accuracy: 0.8080\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3159 - accuracy: 0.8483 - val_loss: 0.4793 - val_accuracy: 0.8060\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.8683 - val_loss: 0.4788 - val_accuracy: 0.8060\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3155 - accuracy: 0.8556 - val_loss: 0.4788 - val_accuracy: 0.8060\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3273 - accuracy: 0.8297 - val_loss: 0.4784 - val_accuracy: 0.8080\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3067 - accuracy: 0.8433 - val_loss: 0.4785 - val_accuracy: 0.8090\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2942 - accuracy: 0.8610 - val_loss: 0.4795 - val_accuracy: 0.8090\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.8421 - val_loss: 0.4808 - val_accuracy: 0.8060\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3449 - accuracy: 0.8523 - val_loss: 0.4830 - val_accuracy: 0.8060\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3219 - accuracy: 0.8422 - val_loss: 0.4847 - val_accuracy: 0.8050\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2935 - accuracy: 0.8579 - val_loss: 0.4842 - val_accuracy: 0.8030\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2822 - accuracy: 0.8846 - val_loss: 0.4810 - val_accuracy: 0.8070\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3578 - accuracy: 0.8398 - val_loss: 0.4785 - val_accuracy: 0.8090\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3178 - accuracy: 0.8400 - val_loss: 0.4769 - val_accuracy: 0.8090\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3248 - accuracy: 0.8390 - val_loss: 0.4761 - val_accuracy: 0.8110\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3132 - accuracy: 0.8546 - val_loss: 0.4756 - val_accuracy: 0.8100\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3102 - accuracy: 0.8640 - val_loss: 0.4747 - val_accuracy: 0.8100\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3023 - accuracy: 0.8711 - val_loss: 0.4747 - val_accuracy: 0.8150\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3174 - accuracy: 0.8461 - val_loss: 0.4759 - val_accuracy: 0.8150\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3465 - accuracy: 0.8398 - val_loss: 0.4770 - val_accuracy: 0.8170\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3387 - accuracy: 0.8419 - val_loss: 0.4778 - val_accuracy: 0.8150\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3517 - accuracy: 0.8419 - val_loss: 0.4798 - val_accuracy: 0.8070\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 0.8492 - val_loss: 0.4819 - val_accuracy: 0.8060\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3103 - accuracy: 0.8659 - val_loss: 0.4843 - val_accuracy: 0.8050\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3042 - accuracy: 0.8700 - val_loss: 0.4858 - val_accuracy: 0.8030\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3048 - accuracy: 0.8596 - val_loss: 0.4841 - val_accuracy: 0.8050\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3382 - accuracy: 0.8461 - val_loss: 0.4784 - val_accuracy: 0.8070\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3072 - accuracy: 0.8700 - val_loss: 0.4765 - val_accuracy: 0.8140\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3168 - accuracy: 0.8525 - val_loss: 0.4760 - val_accuracy: 0.8150\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2921 - accuracy: 0.8495 - val_loss: 0.4770 - val_accuracy: 0.8140\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3055 - accuracy: 0.8422 - val_loss: 0.4783 - val_accuracy: 0.8070\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3276 - accuracy: 0.8421 - val_loss: 0.4807 - val_accuracy: 0.8060\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3424 - accuracy: 0.8504 - val_loss: 0.4836 - val_accuracy: 0.8060\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3058 - accuracy: 0.8516 - val_loss: 0.4856 - val_accuracy: 0.8050\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2931 - accuracy: 0.8713 - val_loss: 0.4857 - val_accuracy: 0.8050\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2788 - accuracy: 0.8827 - val_loss: 0.4858 - val_accuracy: 0.8070\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3305 - accuracy: 0.8482 - val_loss: 0.4859 - val_accuracy: 0.8080\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2998 - accuracy: 0.8648 - val_loss: 0.4861 - val_accuracy: 0.8080\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3087 - accuracy: 0.8711 - val_loss: 0.4854 - val_accuracy: 0.8130\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2892 - accuracy: 0.8483 - val_loss: 0.4860 - val_accuracy: 0.8130\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3213 - accuracy: 0.8523 - val_loss: 0.4874 - val_accuracy: 0.8140\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3391 - accuracy: 0.8419 - val_loss: 0.4878 - val_accuracy: 0.8100\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3408 - accuracy: 0.8367 - val_loss: 0.4891 - val_accuracy: 0.8050\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3138 - accuracy: 0.8482 - val_loss: 0.4896 - val_accuracy: 0.8040\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3304 - accuracy: 0.8555 - val_loss: 0.4896 - val_accuracy: 0.8050\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3509 - accuracy: 0.8275 - val_loss: 0.4889 - val_accuracy: 0.8020\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3109 - accuracy: 0.8454 - val_loss: 0.4886 - val_accuracy: 0.8040\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3229 - accuracy: 0.8266 - val_loss: 0.4894 - val_accuracy: 0.8040\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3525 - accuracy: 0.8141 - val_loss: 0.4892 - val_accuracy: 0.8040\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3106 - accuracy: 0.8185 - val_loss: 0.4891 - val_accuracy: 0.8030\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3185 - accuracy: 0.8216 - val_loss: 0.4888 - val_accuracy: 0.8030\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2885 - accuracy: 0.8341 - val_loss: 0.4887 - val_accuracy: 0.8050\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3387 - accuracy: 0.8329 - val_loss: 0.4886 - val_accuracy: 0.8040\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3066 - accuracy: 0.8308 - val_loss: 0.4898 - val_accuracy: 0.8030\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3345 - accuracy: 0.8185 - val_loss: 0.4902 - val_accuracy: 0.8030\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3059 - accuracy: 0.8393 - val_loss: 0.4894 - val_accuracy: 0.8030\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2758 - accuracy: 0.8610 - val_loss: 0.4887 - val_accuracy: 0.8040\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2953 - accuracy: 0.8558 - val_loss: 0.4900 - val_accuracy: 0.8040\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3059 - accuracy: 0.8249 - val_loss: 0.4909 - val_accuracy: 0.8050\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2989 - accuracy: 0.8341 - val_loss: 0.4921 - val_accuracy: 0.8030\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3339 - accuracy: 0.8153 - val_loss: 0.4929 - val_accuracy: 0.8070\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3188 - accuracy: 0.8278 - val_loss: 0.4937 - val_accuracy: 0.8080\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3103 - accuracy: 0.8226 - val_loss: 0.4953 - val_accuracy: 0.8070\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3334 - accuracy: 0.8297 - val_loss: 0.4952 - val_accuracy: 0.8040\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3347 - accuracy: 0.8152 - val_loss: 0.4954 - val_accuracy: 0.8060\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3397 - accuracy: 0.8245 - val_loss: 0.4947 - val_accuracy: 0.8080\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3211 - accuracy: 0.8060 - val_loss: 0.4937 - val_accuracy: 0.8070\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 0.8341 - val_loss: 0.4948 - val_accuracy: 0.8060\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3171 - accuracy: 0.8237 - val_loss: 0.4961 - val_accuracy: 0.8020\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3096 - accuracy: 0.8433 - val_loss: 0.4955 - val_accuracy: 0.8040\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3416 - accuracy: 0.8152 - val_loss: 0.4959 - val_accuracy: 0.8030\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3088 - accuracy: 0.8245 - val_loss: 0.4966 - val_accuracy: 0.8040\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2807 - accuracy: 0.8765 - val_loss: 0.4975 - val_accuracy: 0.8040\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3073 - accuracy: 0.8556 - val_loss: 0.4973 - val_accuracy: 0.8050\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3160 - accuracy: 0.8402 - val_loss: 0.4955 - val_accuracy: 0.8040\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2872 - accuracy: 0.8641 - val_loss: 0.4923 - val_accuracy: 0.8080\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3380 - accuracy: 0.8016 - val_loss: 0.4890 - val_accuracy: 0.8070\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3255 - accuracy: 0.8297 - val_loss: 0.4854 - val_accuracy: 0.8040\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3128 - accuracy: 0.8174 - val_loss: 0.4852 - val_accuracy: 0.8050\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3176 - accuracy: 0.8330 - val_loss: 0.4865 - val_accuracy: 0.8040\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3220 - accuracy: 0.8216 - val_loss: 0.4874 - val_accuracy: 0.8050\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3166 - accuracy: 0.8518 - val_loss: 0.4885 - val_accuracy: 0.8050\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3059 - accuracy: 0.8280 - val_loss: 0.4898 - val_accuracy: 0.8020\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2827 - accuracy: 0.8405 - val_loss: 0.4906 - val_accuracy: 0.8020\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3376 - accuracy: 0.8061 - val_loss: 0.4910 - val_accuracy: 0.8010\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3154 - accuracy: 0.8113 - val_loss: 0.4914 - val_accuracy: 0.8020\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2763 - accuracy: 0.8384 - val_loss: 0.4917 - val_accuracy: 0.8030\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3173 - accuracy: 0.8318 - val_loss: 0.4928 - val_accuracy: 0.8040\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2962 - accuracy: 0.8495 - val_loss: 0.4936 - val_accuracy: 0.8030\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3375 - accuracy: 0.8018 - val_loss: 0.4940 - val_accuracy: 0.8020\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3209 - accuracy: 0.8091 - val_loss: 0.4937 - val_accuracy: 0.8020\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2903 - accuracy: 0.8528 - val_loss: 0.4926 - val_accuracy: 0.8030\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2830 - accuracy: 0.8527 - val_loss: 0.4914 - val_accuracy: 0.8050\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3064 - accuracy: 0.8589 - val_loss: 0.4905 - val_accuracy: 0.8040\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2935 - accuracy: 0.8704 - val_loss: 0.4896 - val_accuracy: 0.8080\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3115 - accuracy: 0.8431 - val_loss: 0.4886 - val_accuracy: 0.8080\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3085 - accuracy: 0.8390 - val_loss: 0.4884 - val_accuracy: 0.8080\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3256 - accuracy: 0.8358 - val_loss: 0.4896 - val_accuracy: 0.8090\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3058 - accuracy: 0.8421 - val_loss: 0.4911 - val_accuracy: 0.8110\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3341 - accuracy: 0.8275 - val_loss: 0.4940 - val_accuracy: 0.8080\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3147 - accuracy: 0.8400 - val_loss: 0.4982 - val_accuracy: 0.8070\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2950 - accuracy: 0.8577 - val_loss: 0.5029 - val_accuracy: 0.8050\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3426 - accuracy: 0.8369 - val_loss: 0.5072 - val_accuracy: 0.7990\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3352 - accuracy: 0.8473 - val_loss: 0.5085 - val_accuracy: 0.7990\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 0.8681 - val_loss: 0.5084 - val_accuracy: 0.7990\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2859 - accuracy: 0.8610 - val_loss: 0.5062 - val_accuracy: 0.8010\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3024 - accuracy: 0.8463 - val_loss: 0.5031 - val_accuracy: 0.8050\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3182 - accuracy: 0.8296 - val_loss: 0.5002 - val_accuracy: 0.8040\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2844 - accuracy: 0.8702 - val_loss: 0.4976 - val_accuracy: 0.8060\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3173 - accuracy: 0.8360 - val_loss: 0.4950 - val_accuracy: 0.8070\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3556 - accuracy: 0.7997 - val_loss: 0.4920 - val_accuracy: 0.8080\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3081 - accuracy: 0.8546 - val_loss: 0.4902 - val_accuracy: 0.8090\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3157 - accuracy: 0.8494 - val_loss: 0.4895 - val_accuracy: 0.8090\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3305 - accuracy: 0.8338 - val_loss: 0.4893 - val_accuracy: 0.8070\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3047 - accuracy: 0.8608 - val_loss: 0.4895 - val_accuracy: 0.8070\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3177 - accuracy: 0.8421 - val_loss: 0.4898 - val_accuracy: 0.8070\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3192 - accuracy: 0.8546 - val_loss: 0.4915 - val_accuracy: 0.8080\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.8733 - val_loss: 0.4926 - val_accuracy: 0.8060\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3372 - accuracy: 0.8214 - val_loss: 0.4930 - val_accuracy: 0.8040\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3009 - accuracy: 0.8516 - val_loss: 0.4932 - val_accuracy: 0.8060\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3162 - accuracy: 0.8464 - val_loss: 0.4930 - val_accuracy: 0.8100\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2940 - accuracy: 0.8577 - val_loss: 0.4923 - val_accuracy: 0.8110\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3056 - accuracy: 0.8546 - val_loss: 0.4913 - val_accuracy: 0.8120\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3116 - accuracy: 0.8461 - val_loss: 0.4898 - val_accuracy: 0.8090\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3341 - accuracy: 0.8348 - val_loss: 0.4890 - val_accuracy: 0.8060\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2929 - accuracy: 0.8494 - val_loss: 0.4892 - val_accuracy: 0.8060\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2975 - accuracy: 0.8754 - val_loss: 0.4895 - val_accuracy: 0.8050\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.8402 - val_loss: 0.4897 - val_accuracy: 0.8040\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3039 - accuracy: 0.8539 - val_loss: 0.4899 - val_accuracy: 0.8050\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2827 - accuracy: 0.8591 - val_loss: 0.4902 - val_accuracy: 0.8030\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3083 - accuracy: 0.8205 - val_loss: 0.4904 - val_accuracy: 0.8030\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2966 - accuracy: 0.8330 - val_loss: 0.4891 - val_accuracy: 0.8050\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2902 - accuracy: 0.8475 - val_loss: 0.4894 - val_accuracy: 0.8030\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3120 - accuracy: 0.8237 - val_loss: 0.4901 - val_accuracy: 0.8030\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2877 - accuracy: 0.8497 - val_loss: 0.4903 - val_accuracy: 0.8020\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2816 - accuracy: 0.8476 - val_loss: 0.4912 - val_accuracy: 0.8020\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3285 - accuracy: 0.8308 - val_loss: 0.4923 - val_accuracy: 0.8050\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3154 - accuracy: 0.8402 - val_loss: 0.4929 - val_accuracy: 0.8040\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2651 - accuracy: 0.8662 - val_loss: 0.4929 - val_accuracy: 0.8040\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3094 - accuracy: 0.8360 - val_loss: 0.4917 - val_accuracy: 0.8010\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3013 - accuracy: 0.8247 - val_loss: 0.4913 - val_accuracy: 0.8010\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3423 - accuracy: 0.7903 - val_loss: 0.4915 - val_accuracy: 0.8020\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2981 - accuracy: 0.8422 - val_loss: 0.4929 - val_accuracy: 0.8050\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2927 - accuracy: 0.8329 - val_loss: 0.4941 - val_accuracy: 0.8050\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3071 - accuracy: 0.8433 - val_loss: 0.4955 - val_accuracy: 0.8030\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3169 - accuracy: 0.8152 - val_loss: 0.4972 - val_accuracy: 0.8050\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3284 - accuracy: 0.8185 - val_loss: 0.4981 - val_accuracy: 0.8040\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2992 - accuracy: 0.8092 - val_loss: 0.4984 - val_accuracy: 0.8040\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3290 - accuracy: 0.8237 - val_loss: 0.4983 - val_accuracy: 0.8030\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2831 - accuracy: 0.8207 - val_loss: 0.4991 - val_accuracy: 0.8020\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3110 - accuracy: 0.8214 - val_loss: 0.4963 - val_accuracy: 0.8040\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3116 - accuracy: 0.8245 - val_loss: 0.4943 - val_accuracy: 0.8020\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.8600 - val_loss: 0.4935 - val_accuracy: 0.8030\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3019 - accuracy: 0.8278 - val_loss: 0.4926 - val_accuracy: 0.8040\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2987 - accuracy: 0.8330 - val_loss: 0.4922 - val_accuracy: 0.8010\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2772 - accuracy: 0.8641 - val_loss: 0.4915 - val_accuracy: 0.8040\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.8297 - val_loss: 0.4906 - val_accuracy: 0.8040\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3031 - accuracy: 0.8391 - val_loss: 0.4885 - val_accuracy: 0.8080\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3223 - accuracy: 0.8513 - val_loss: 0.4880 - val_accuracy: 0.8160\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3272 - accuracy: 0.8513 - val_loss: 0.4874 - val_accuracy: 0.8170\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8430 - val_loss: 0.4874 - val_accuracy: 0.8160\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3209 - accuracy: 0.8523 - val_loss: 0.4867 - val_accuracy: 0.8160\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3265 - accuracy: 0.8544 - val_loss: 0.4861 - val_accuracy: 0.8200\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3282 - accuracy: 0.8544 - val_loss: 0.4859 - val_accuracy: 0.8200\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2953 - accuracy: 0.8575 - val_loss: 0.4867 - val_accuracy: 0.8140\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3166 - accuracy: 0.8358 - val_loss: 0.4884 - val_accuracy: 0.8110\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3083 - accuracy: 0.8555 - val_loss: 0.4899 - val_accuracy: 0.8140\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3129 - accuracy: 0.8461 - val_loss: 0.4906 - val_accuracy: 0.8140\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2977 - accuracy: 0.8607 - val_loss: 0.4897 - val_accuracy: 0.8140\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2783 - accuracy: 0.8796 - val_loss: 0.4876 - val_accuracy: 0.8140\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3057 - accuracy: 0.8515 - val_loss: 0.4875 - val_accuracy: 0.8150\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 0.8400 - val_loss: 0.4876 - val_accuracy: 0.8150\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3089 - accuracy: 0.8390 - val_loss: 0.4880 - val_accuracy: 0.8140\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3237 - accuracy: 0.8431 - val_loss: 0.4884 - val_accuracy: 0.8150\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3078 - accuracy: 0.8525 - val_loss: 0.4884 - val_accuracy: 0.8200\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3117 - accuracy: 0.8338 - val_loss: 0.4886 - val_accuracy: 0.8190\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2936 - accuracy: 0.8515 - val_loss: 0.4893 - val_accuracy: 0.8190\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3107 - accuracy: 0.8452 - val_loss: 0.4897 - val_accuracy: 0.8160\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3086 - accuracy: 0.8461 - val_loss: 0.4893 - val_accuracy: 0.8180\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3067 - accuracy: 0.8430 - val_loss: 0.4893 - val_accuracy: 0.8200\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2792 - accuracy: 0.8588 - val_loss: 0.4896 - val_accuracy: 0.8210\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3123 - accuracy: 0.8525 - val_loss: 0.4899 - val_accuracy: 0.8210\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3185 - accuracy: 0.8327 - val_loss: 0.4906 - val_accuracy: 0.8180\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.8089 - val_loss: 0.4928 - val_accuracy: 0.8130\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.8327 - val_loss: 0.4954 - val_accuracy: 0.8140\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3108 - accuracy: 0.8419 - val_loss: 0.4985 - val_accuracy: 0.8070\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3398 - accuracy: 0.8305 - val_loss: 0.5000 - val_accuracy: 0.8070\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3377 - accuracy: 0.8388 - val_loss: 0.5020 - val_accuracy: 0.8060\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2903 - accuracy: 0.8669 - val_loss: 0.5032 - val_accuracy: 0.8050\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3086 - accuracy: 0.8669 - val_loss: 0.5021 - val_accuracy: 0.8060\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2714 - accuracy: 0.8805 - val_loss: 0.5029 - val_accuracy: 0.8040\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3383 - accuracy: 0.8336 - val_loss: 0.5035 - val_accuracy: 0.8050\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3153 - accuracy: 0.8648 - val_loss: 0.5034 - val_accuracy: 0.8050\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2799 - accuracy: 0.8803 - val_loss: 0.5018 - val_accuracy: 0.8050\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3175 - accuracy: 0.8636 - val_loss: 0.5001 - val_accuracy: 0.8090\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.8584 - val_loss: 0.4985 - val_accuracy: 0.8120\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3269 - accuracy: 0.8709 - val_loss: 0.4972 - val_accuracy: 0.8120\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2758 - accuracy: 0.8732 - val_loss: 0.4950 - val_accuracy: 0.8130\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3007 - accuracy: 0.8680 - val_loss: 0.4919 - val_accuracy: 0.8170\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.8671 - val_loss: 0.4919 - val_accuracy: 0.8180\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3091 - accuracy: 0.8431 - val_loss: 0.4924 - val_accuracy: 0.8170\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3053 - accuracy: 0.8431 - val_loss: 0.4930 - val_accuracy: 0.8130\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3216 - accuracy: 0.8338 - val_loss: 0.4936 - val_accuracy: 0.8140\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2816 - accuracy: 0.8702 - val_loss: 0.4945 - val_accuracy: 0.8120\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3167 - accuracy: 0.8275 - val_loss: 0.4961 - val_accuracy: 0.8120\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2987 - accuracy: 0.8659 - val_loss: 0.4968 - val_accuracy: 0.8120\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 0.8638 - val_loss: 0.4977 - val_accuracy: 0.8060\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3036 - accuracy: 0.8608 - val_loss: 0.4982 - val_accuracy: 0.8080\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2875 - accuracy: 0.8556 - val_loss: 0.4988 - val_accuracy: 0.8050\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3025 - accuracy: 0.8358 - val_loss: 0.5008 - val_accuracy: 0.8070\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3041 - accuracy: 0.8494 - val_loss: 0.5031 - val_accuracy: 0.8020\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3110 - accuracy: 0.8431 - val_loss: 0.5040 - val_accuracy: 0.8020\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2763 - accuracy: 0.8794 - val_loss: 0.5035 - val_accuracy: 0.8040\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3043 - accuracy: 0.8680 - val_loss: 0.5023 - val_accuracy: 0.8040\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2798 - accuracy: 0.8702 - val_loss: 0.5004 - val_accuracy: 0.8080\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3105 - accuracy: 0.8297 - val_loss: 0.4970 - val_accuracy: 0.8080\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2630 - accuracy: 0.8742 - val_loss: 0.4964 - val_accuracy: 0.8060\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2889 - accuracy: 0.8588 - val_loss: 0.4964 - val_accuracy: 0.8060\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2938 - accuracy: 0.8556 - val_loss: 0.4967 - val_accuracy: 0.8020\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3022 - accuracy: 0.8431 - val_loss: 0.4967 - val_accuracy: 0.8020\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3025 - accuracy: 0.8547 - val_loss: 0.4965 - val_accuracy: 0.8050\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2892 - accuracy: 0.8422 - val_loss: 0.4971 - val_accuracy: 0.8010\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2856 - accuracy: 0.8650 - val_loss: 0.4974 - val_accuracy: 0.8040\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3021 - accuracy: 0.8483 - val_loss: 0.4978 - val_accuracy: 0.8040\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3039 - accuracy: 0.8358 - val_loss: 0.4981 - val_accuracy: 0.8070\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2924 - accuracy: 0.8588 - val_loss: 0.4996 - val_accuracy: 0.8080\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3161 - accuracy: 0.8367 - val_loss: 0.5006 - val_accuracy: 0.8060\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2848 - accuracy: 0.8410 - val_loss: 0.5025 - val_accuracy: 0.8050\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3099 - accuracy: 0.8669 - val_loss: 0.5027 - val_accuracy: 0.8080\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3184 - accuracy: 0.8615 - val_loss: 0.5007 - val_accuracy: 0.8120\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3044 - accuracy: 0.8482 - val_loss: 0.4996 - val_accuracy: 0.8120\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2851 - accuracy: 0.8805 - val_loss: 0.4995 - val_accuracy: 0.8120\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3230 - accuracy: 0.8450 - val_loss: 0.4997 - val_accuracy: 0.8120\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2887 - accuracy: 0.8761 - val_loss: 0.4996 - val_accuracy: 0.8100\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3134 - accuracy: 0.8638 - val_loss: 0.4996 - val_accuracy: 0.8110\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2992 - accuracy: 0.8680 - val_loss: 0.4991 - val_accuracy: 0.8120\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2905 - accuracy: 0.8680 - val_loss: 0.4990 - val_accuracy: 0.8120\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3158 - accuracy: 0.8586 - val_loss: 0.4983 - val_accuracy: 0.8110\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3184 - accuracy: 0.8430 - val_loss: 0.4983 - val_accuracy: 0.8110\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3165 - accuracy: 0.8503 - val_loss: 0.4983 - val_accuracy: 0.8100\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3431 - accuracy: 0.8367 - val_loss: 0.4997 - val_accuracy: 0.8100\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2962 - accuracy: 0.8575 - val_loss: 0.5006 - val_accuracy: 0.8080\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3329 - accuracy: 0.8305 - val_loss: 0.4986 - val_accuracy: 0.8070\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2946 - accuracy: 0.8659 - val_loss: 0.4982 - val_accuracy: 0.8060\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.8494 - val_loss: 0.4984 - val_accuracy: 0.8050\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2965 - accuracy: 0.8360 - val_loss: 0.4989 - val_accuracy: 0.8050\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2937 - accuracy: 0.8558 - val_loss: 0.4995 - val_accuracy: 0.8060\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2941 - accuracy: 0.8454 - val_loss: 0.5005 - val_accuracy: 0.8070\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2924 - accuracy: 0.8485 - val_loss: 0.5009 - val_accuracy: 0.8080\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3216 - accuracy: 0.8422 - val_loss: 0.5008 - val_accuracy: 0.8080\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3108 - accuracy: 0.8402 - val_loss: 0.5008 - val_accuracy: 0.8100\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3084 - accuracy: 0.8402 - val_loss: 0.5013 - val_accuracy: 0.8070\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.8214 - val_loss: 0.5018 - val_accuracy: 0.8050\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2804 - accuracy: 0.8485 - val_loss: 0.5021 - val_accuracy: 0.8050\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3340 - accuracy: 0.8058 - val_loss: 0.5016 - val_accuracy: 0.8070\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3130 - accuracy: 0.8339 - val_loss: 0.5017 - val_accuracy: 0.8060\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3264 - accuracy: 0.8183 - val_loss: 0.5021 - val_accuracy: 0.8040\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3281 - accuracy: 0.8214 - val_loss: 0.5027 - val_accuracy: 0.8030\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2676 - accuracy: 0.8620 - val_loss: 0.5035 - val_accuracy: 0.8010\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3152 - accuracy: 0.8297 - val_loss: 0.5043 - val_accuracy: 0.8010\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3270 - accuracy: 0.8256 - val_loss: 0.5043 - val_accuracy: 0.8030\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2763 - accuracy: 0.8558 - val_loss: 0.5033 - val_accuracy: 0.8060\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3147 - accuracy: 0.8266 - val_loss: 0.5024 - val_accuracy: 0.8060\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2810 - accuracy: 0.8577 - val_loss: 0.5017 - val_accuracy: 0.8090\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3000 - accuracy: 0.8463 - val_loss: 0.5020 - val_accuracy: 0.8060\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3051 - accuracy: 0.8245 - val_loss: 0.5027 - val_accuracy: 0.8070\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2915 - accuracy: 0.8370 - val_loss: 0.5040 - val_accuracy: 0.8020\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3023 - accuracy: 0.8329 - val_loss: 0.5050 - val_accuracy: 0.8040\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3038 - accuracy: 0.8402 - val_loss: 0.5060 - val_accuracy: 0.8060\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3069 - accuracy: 0.8308 - val_loss: 0.5067 - val_accuracy: 0.8070\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3032 - accuracy: 0.8256 - val_loss: 0.5075 - val_accuracy: 0.8060\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3076 - accuracy: 0.8402 - val_loss: 0.5083 - val_accuracy: 0.8060\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2721 - accuracy: 0.8487 - val_loss: 0.5088 - val_accuracy: 0.8070\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2641 - accuracy: 0.8714 - val_loss: 0.5093 - val_accuracy: 0.8060\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2783 - accuracy: 0.8568 - val_loss: 0.5094 - val_accuracy: 0.8050\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3036 - accuracy: 0.8504 - val_loss: 0.5102 - val_accuracy: 0.8080\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3040 - accuracy: 0.8412 - val_loss: 0.5100 - val_accuracy: 0.8040\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2985 - accuracy: 0.8461 - val_loss: 0.5082 - val_accuracy: 0.8080\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2803 - accuracy: 0.8723 - val_loss: 0.5060 - val_accuracy: 0.8080\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2916 - accuracy: 0.8765 - val_loss: 0.5050 - val_accuracy: 0.8040\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2899 - accuracy: 0.8454 - val_loss: 0.5047 - val_accuracy: 0.8040\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3185 - accuracy: 0.8391 - val_loss: 0.5053 - val_accuracy: 0.8020\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2988 - accuracy: 0.8360 - val_loss: 0.5056 - val_accuracy: 0.8030\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2916 - accuracy: 0.8412 - val_loss: 0.5050 - val_accuracy: 0.8040\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3039 - accuracy: 0.8422 - val_loss: 0.5036 - val_accuracy: 0.8060\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2783 - accuracy: 0.8558 - val_loss: 0.5031 - val_accuracy: 0.8050\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2948 - accuracy: 0.8339 - val_loss: 0.5027 - val_accuracy: 0.8070\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2969 - accuracy: 0.8339 - val_loss: 0.5026 - val_accuracy: 0.8090\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3061 - accuracy: 0.8422 - val_loss: 0.5029 - val_accuracy: 0.8080\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2950 - accuracy: 0.8339 - val_loss: 0.5041 - val_accuracy: 0.8050\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2866 - accuracy: 0.8433 - val_loss: 0.5049 - val_accuracy: 0.8040\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2931 - accuracy: 0.8558 - val_loss: 0.5052 - val_accuracy: 0.8040\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3066 - accuracy: 0.8339 - val_loss: 0.5054 - val_accuracy: 0.8050\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2730 - accuracy: 0.8643 - val_loss: 0.5064 - val_accuracy: 0.8060\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3114 - accuracy: 0.8153 - val_loss: 0.5070 - val_accuracy: 0.8070\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2996 - accuracy: 0.8247 - val_loss: 0.5078 - val_accuracy: 0.8050\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2833 - accuracy: 0.8549 - val_loss: 0.5089 - val_accuracy: 0.8040\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2903 - accuracy: 0.8464 - val_loss: 0.5094 - val_accuracy: 0.8080\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2738 - accuracy: 0.8527 - val_loss: 0.5095 - val_accuracy: 0.8080\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2731 - accuracy: 0.8589 - val_loss: 0.5094 - val_accuracy: 0.8070\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2953 - accuracy: 0.8402 - val_loss: 0.5084 - val_accuracy: 0.8040\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.8431 - val_loss: 0.5085 - val_accuracy: 0.8040\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2994 - accuracy: 0.8400 - val_loss: 0.5092 - val_accuracy: 0.8040\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3201 - accuracy: 0.8369 - val_loss: 0.5109 - val_accuracy: 0.8050\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3216 - accuracy: 0.8494 - val_loss: 0.5120 - val_accuracy: 0.8040\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2827 - accuracy: 0.8660 - val_loss: 0.5133 - val_accuracy: 0.8050\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2885 - accuracy: 0.8525 - val_loss: 0.5156 - val_accuracy: 0.8060\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2864 - accuracy: 0.8732 - val_loss: 0.5171 - val_accuracy: 0.8070\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2674 - accuracy: 0.8950 - val_loss: 0.5175 - val_accuracy: 0.8080\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3107 - accuracy: 0.8608 - val_loss: 0.5177 - val_accuracy: 0.8070\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3033 - accuracy: 0.8452 - val_loss: 0.5167 - val_accuracy: 0.8060\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3193 - accuracy: 0.8153 - val_loss: 0.5149 - val_accuracy: 0.8080\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2944 - accuracy: 0.8310 - val_loss: 0.5138 - val_accuracy: 0.8070\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2743 - accuracy: 0.8600 - val_loss: 0.5136 - val_accuracy: 0.8070\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2957 - accuracy: 0.8237 - val_loss: 0.5148 - val_accuracy: 0.8070\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2986 - accuracy: 0.8485 - val_loss: 0.5144 - val_accuracy: 0.8060\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2897 - accuracy: 0.8475 - val_loss: 0.5129 - val_accuracy: 0.8070\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2745 - accuracy: 0.8546 - val_loss: 0.5096 - val_accuracy: 0.8030\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3358 - accuracy: 0.8119 - val_loss: 0.5067 - val_accuracy: 0.8100\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2881 - accuracy: 0.8857 - val_loss: 0.5052 - val_accuracy: 0.8110\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2894 - accuracy: 0.8400 - val_loss: 0.5046 - val_accuracy: 0.8120\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2919 - accuracy: 0.8494 - val_loss: 0.5047 - val_accuracy: 0.8120\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3016 - accuracy: 0.8546 - val_loss: 0.5053 - val_accuracy: 0.8110\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2785 - accuracy: 0.8742 - val_loss: 0.5072 - val_accuracy: 0.8070\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2748 - accuracy: 0.8669 - val_loss: 0.5079 - val_accuracy: 0.8080\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2924 - accuracy: 0.8586 - val_loss: 0.5055 - val_accuracy: 0.8110\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2906 - accuracy: 0.8556 - val_loss: 0.5045 - val_accuracy: 0.8160\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2762 - accuracy: 0.8617 - val_loss: 0.5043 - val_accuracy: 0.8170\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2856 - accuracy: 0.8607 - val_loss: 0.5044 - val_accuracy: 0.8180\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3054 - accuracy: 0.8492 - val_loss: 0.5048 - val_accuracy: 0.8180\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2742 - accuracy: 0.8898 - val_loss: 0.5054 - val_accuracy: 0.8170\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2905 - accuracy: 0.8671 - val_loss: 0.5054 - val_accuracy: 0.8160\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2987 - accuracy: 0.8525 - val_loss: 0.5046 - val_accuracy: 0.8170\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2868 - accuracy: 0.8619 - val_loss: 0.5038 - val_accuracy: 0.8180\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 0.8433 - val_loss: 0.5034 - val_accuracy: 0.8190\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3141 - accuracy: 0.8183 - val_loss: 0.5032 - val_accuracy: 0.8200\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2974 - accuracy: 0.8494 - val_loss: 0.5036 - val_accuracy: 0.8170\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2815 - accuracy: 0.8525 - val_loss: 0.5038 - val_accuracy: 0.8170\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3068 - accuracy: 0.8358 - val_loss: 0.5040 - val_accuracy: 0.8150\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3099 - accuracy: 0.8523 - val_loss: 0.5034 - val_accuracy: 0.8160\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3143 - accuracy: 0.8450 - val_loss: 0.5032 - val_accuracy: 0.8150\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2855 - accuracy: 0.8617 - val_loss: 0.5034 - val_accuracy: 0.8150\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2819 - accuracy: 0.8640 - val_loss: 0.5039 - val_accuracy: 0.8170\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3084 - accuracy: 0.8482 - val_loss: 0.5048 - val_accuracy: 0.8140\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3010 - accuracy: 0.8327 - val_loss: 0.5056 - val_accuracy: 0.8140\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3225 - accuracy: 0.8150 - val_loss: 0.5059 - val_accuracy: 0.8150\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2813 - accuracy: 0.8650 - val_loss: 0.5067 - val_accuracy: 0.8120\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2725 - accuracy: 0.8669 - val_loss: 0.5077 - val_accuracy: 0.8120\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 0.8867 - val_loss: 0.5089 - val_accuracy: 0.8100\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2517 - accuracy: 0.8785 - val_loss: 0.5101 - val_accuracy: 0.8080\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2824 - accuracy: 0.8660 - val_loss: 0.5131 - val_accuracy: 0.8030\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2776 - accuracy: 0.8681 - val_loss: 0.5160 - val_accuracy: 0.8060\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3124 - accuracy: 0.8555 - val_loss: 0.5172 - val_accuracy: 0.8050\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3253 - accuracy: 0.8431 - val_loss: 0.5169 - val_accuracy: 0.8050\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3056 - accuracy: 0.8327 - val_loss: 0.5162 - val_accuracy: 0.8060\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2941 - accuracy: 0.8556 - val_loss: 0.5154 - val_accuracy: 0.8030\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2799 - accuracy: 0.8765 - val_loss: 0.5155 - val_accuracy: 0.8060\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3196 - accuracy: 0.8265 - val_loss: 0.5140 - val_accuracy: 0.8060\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2866 - accuracy: 0.8669 - val_loss: 0.5135 - val_accuracy: 0.8070\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2670 - accuracy: 0.8723 - val_loss: 0.5117 - val_accuracy: 0.8060\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2942 - accuracy: 0.8506 - val_loss: 0.5113 - val_accuracy: 0.8040\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2923 - accuracy: 0.8610 - val_loss: 0.5113 - val_accuracy: 0.8060\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2940 - accuracy: 0.8433 - val_loss: 0.5121 - val_accuracy: 0.8070\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2816 - accuracy: 0.8445 - val_loss: 0.5125 - val_accuracy: 0.8090\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.8610 - val_loss: 0.5123 - val_accuracy: 0.8090\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2996 - accuracy: 0.8391 - val_loss: 0.5119 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the run, we will evaluate the model's performance on both the train and the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.840, Test: 0.808\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then finally, we will plot model loss and accuracy learning curves over each training epoch on both the training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.840, Test: 0.813\n"
     ]
    }
   ],
   "source": [
    "# develop an mlp for blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=1000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example, it first prints the performance of the final model on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see that the model achieved about 85% accuracy on the training dataset, which we know is optimistic, and about 81% on the test dataset, which we would expect to be more realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot also shows the learning curves for the model accuracy on the train and test sets over each training epoch. We can see that training accuracy is more optimistic over the whole run, as we noted with the final scores. We can see that the model's accuracy has high variance on the training dataset compared to the test set, as we would expect. The variance in the model highlights the fact that choosing the model at the end of the run or any model from about epoch 400 is challenging as the accuracy on the training dataset has a high variance. We also see a muted version of the variance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Horizontal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be many ways to implement a horizontal voting ensemble. Perhaps the simplest is to drive the training process manually, one epoch at a time, then save models at the end of the epoch if we have exceeded an upper limit on the number of epochs. For example, we will train the model for 1,000 epochs with our test problem and perhaps save models from epoch 950 onwards (e.g., between and including epochs 950 and 999)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "n_epochs, n_save_after = 1000, 950\n",
    "for i in range(n_epochs):\n",
    "    # fit model for a single epoch\n",
    "    model.fit(trainX, trainy, epochs=1, verbose=0)\n",
    "\n",
    "    # check if we should save the model\n",
    "    if i >= n_save_after:\n",
    "        model.save('models/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models can be saved to a file using the save() function on the model and specifying a filename that includes the epoch number. We will save all models under a new models/ folder in the current working directory to avoid clutter with our source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "\n",
    "# create directory for models\n",
    "makedirs('models', exist_ok =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, saving and loading neural network models in Keras requires that you have the h5py library installed. You can install this library using pip as follows:\n",
    "\n",
    "```\n",
    "pip install h5py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tying all of this together, the complete example of fitting the model on the training dataset and saving all models from the last 50 epochs is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save horizontal voting ensemble members during training\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from os import makedirs\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# one hot encode output variable\n",
    "y = to_categorical(y)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# create directory for models\n",
    "makedirs('models',exist_ok =True)\n",
    "\n",
    "# fit model\n",
    "n_epochs, n_save_after = 1000, 950\n",
    "for i in range(n_epochs):\n",
    "    # fit model for a single epoch\n",
    "    model.fit(trainX, trainy, epochs=1, verbose=0)\n",
    "    \n",
    "    # check if we should save the model\n",
    "    if i >= n_save_after:\n",
    "        model.save('models/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates the models/ folder and saves 50 models into the directory. Note, to re-run this example, you must delete the models/ directory so that the script can recreate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Horizontal Ensemble Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the models, we can use them in a horizontal voting ensemble. First, we need to load the models into memory. This is reasonable as the models are small. If you are developing a horizontal voting ensemble with very large models, it might be easier to load models one at a time, make a prediction, then load the next model and repeat the process. The function `load_all_models()` below will load models from the models/ directory. It takes the start and end epochs as arguments so that you can experiment with different groups of models saved over contiguous epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "def load_all_models(n_start, n_end):\n",
    "    all_models = list()\n",
    "    for epoch in range(n_start, n_end):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(epoch) + '.h5'\n",
    "\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the function to load all of the models. We can then reverse the list of models so that the models at the end of the run are at the beginning of the list. This will be helpful later when we test voting ensembles of different sizes, including models sequentially from the end of the run backward through training epochs, in case the best models really were at the end of the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "# load models in order\n",
    "members = load_all_models(950, 1000)\n",
    "print('Loaded %d models' % len(members))\n",
    "\n",
    "# reverse loaded models so we build the ensemble with the last models first\n",
    "members = list(reversed(members))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can evaluate each saved model on the test dataset and a voting ensemble of the last n contiguous models from training. We want to know how well each model actually performed on the test dataset and, importantly, the distribution of model performance on the test dataset so that we know how well (or poorly) an average model chosen from the end of the run would perform in practice. We don't know how many members to include in the horizontal voting ensemble. Therefore, we can test different numbers of contiguous members, working backward from the final model.\n",
    "\n",
    "First, we need a function to make a prediction with a list of ensemble members. Each member predicts the probabilities for each of the three output classes. The probabilities are added, and we use an argmax to select the class with the most support. The `ensemble_predictions()` function below implements this voting-based prediction scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multiclass classification\n",
    "def ensemble_predictions(members, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = array(yhats)\n",
    "\n",
    "    # sum across ensemble members\n",
    "    summed = numpy.sum(yhats, axis=0)\n",
    "\n",
    "    # argmax across classes\n",
    "    result = argmax(summed, axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function to evaluate a subset of the ensemble members of a given size. The subset needs to be selected, predictions made, and the ensemble's performance estimated by comparing the predictions to the expected values. The `evaluate_n_members()` function below implements this ensemble size evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "    # select a subset of members\n",
    "    subset = members[:n_members]\n",
    "\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(subset, testX)\n",
    "\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now enumerate through different sized horizontal voting ensembles from 1 to 50. Each member is evaluated alone, then the ensemble of that size is evaluated, and scores are recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "# evaluate different numbers of ensembles on hold out set\n",
    "single_scores, ensemble_scores = list(), list()\n",
    "for i in range(1, len(members)+1):\n",
    "    # evaluate model with i members\n",
    "    ensemble_score = evaluate_n_members(members, i, testX, testy)\n",
    "\n",
    "    # evaluate the i'th model standalone\n",
    "    testy_enc = to_categorical(testy)\n",
    "    _, single_score = members[i-1].evaluate(testX, testy_enc, verbose=0)\n",
    "\n",
    "    # summarize this step\n",
    "    print('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
    "    ensemble_scores.append(ensemble_score)\n",
    "    single_scores.append(single_score)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the evaluations, we report the distribution of scores of single models on the test dataset. The average score is what we would expect on average if we picked any of the saved models as a final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# summarize average accuracy of a single final model\n",
    "print('Accuracy %.3f (%.3f)' % (mean(single_scores), std(single_scores)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the scores. The scores of each standalone model are plotted as blue dots, and a line plot is created for each ensemble of contiguous models (orange)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, len(members)+1)]\n",
    "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
    "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
    "pyplot.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our expectation is that a fair-sized ensemble will outperform a randomly selected model and that there is a point of diminishing returns in choosing the ensemble size. The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and make predictions using a horizontal voting ensemble\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from numpy import mean, std, array, argmax\n",
    "import numpy\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_start, n_end):\n",
    "    all_models = list()\n",
    "    for epoch in range(n_start, n_end):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'models/model_' + str(epoch) + '.h5'\n",
    "\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "\n",
    "    return all_models\n",
    "\n",
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(testX) for model in members]\n",
    "    yhats = array(yhats)\n",
    "\n",
    "    # sum across ensemble members\n",
    "    summed = numpy.sum(yhats, axis=0)\n",
    "\n",
    "    # argmax across classes\n",
    "    result = argmax(summed, axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "# evaluate a specific number of members in an ensemble\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "    # select a subset of members\n",
    "    subset = members[:n_members]\n",
    "\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(subset, testX)\n",
    "\n",
    "    # calculate accuracy\n",
    "    return accuracy_score(testy, yhat)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 100\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the 50 saved models are loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded models/model_950.h5\n",
      ">loaded models/model_951.h5\n",
      ">loaded models/model_952.h5\n",
      ">loaded models/model_953.h5\n",
      ">loaded models/model_954.h5\n",
      ">loaded models/model_955.h5\n",
      ">loaded models/model_956.h5\n",
      ">loaded models/model_957.h5\n",
      ">loaded models/model_958.h5\n",
      ">loaded models/model_959.h5\n",
      ">loaded models/model_960.h5\n",
      ">loaded models/model_961.h5\n",
      ">loaded models/model_962.h5\n",
      ">loaded models/model_963.h5\n",
      ">loaded models/model_964.h5\n",
      ">loaded models/model_965.h5\n",
      ">loaded models/model_966.h5\n",
      ">loaded models/model_967.h5\n",
      ">loaded models/model_968.h5\n",
      ">loaded models/model_969.h5\n",
      ">loaded models/model_970.h5\n",
      ">loaded models/model_971.h5\n",
      ">loaded models/model_972.h5\n",
      ">loaded models/model_973.h5\n",
      ">loaded models/model_974.h5\n",
      ">loaded models/model_975.h5\n",
      ">loaded models/model_976.h5\n",
      ">loaded models/model_977.h5\n",
      ">loaded models/model_978.h5\n",
      ">loaded models/model_979.h5\n",
      ">loaded models/model_980.h5\n",
      ">loaded models/model_981.h5\n",
      ">loaded models/model_982.h5\n",
      ">loaded models/model_983.h5\n",
      ">loaded models/model_984.h5\n",
      ">loaded models/model_985.h5\n",
      ">loaded models/model_986.h5\n",
      ">loaded models/model_987.h5\n",
      ">loaded models/model_988.h5\n",
      ">loaded models/model_989.h5\n",
      ">loaded models/model_990.h5\n",
      ">loaded models/model_991.h5\n",
      ">loaded models/model_992.h5\n",
      ">loaded models/model_993.h5\n",
      ">loaded models/model_994.h5\n",
      ">loaded models/model_995.h5\n",
      ">loaded models/model_996.h5\n",
      ">loaded models/model_997.h5\n",
      ">loaded models/model_998.h5\n",
      ">loaded models/model_999.h5\n",
      "Loaded 50 models\n"
     ]
    }
   ],
   "source": [
    "# load models in order\n",
    "members = load_all_models(950, 1000)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the performance of every single model is evaluated on the holdout test dataset, and the ensemble of that size (1, 2, 3, etc.) is created and evaluated on the holdout test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 1: single=0.808, ensemble=0.808\n",
      "> 2: single=0.808, ensemble=0.807\n",
      "> 3: single=0.810, ensemble=0.808\n",
      "> 4: single=0.810, ensemble=0.808\n",
      "> 5: single=0.809, ensemble=0.808\n",
      "> 6: single=0.806, ensemble=0.808\n",
      "> 7: single=0.806, ensemble=0.809\n",
      "> 8: single=0.807, ensemble=0.807\n",
      "> 9: single=0.810, ensemble=0.806\n",
      "> 10: single=0.810, ensemble=0.808\n",
      "> 11: single=0.809, ensemble=0.810\n",
      "> 12: single=0.810, ensemble=0.810\n",
      "> 13: single=0.809, ensemble=0.809\n",
      "> 14: single=0.809, ensemble=0.810\n",
      "> 15: single=0.809, ensemble=0.809\n",
      "> 16: single=0.809, ensemble=0.809\n",
      "> 17: single=0.808, ensemble=0.810\n",
      "> 18: single=0.806, ensemble=0.810\n",
      "> 19: single=0.806, ensemble=0.810\n",
      "> 20: single=0.807, ensemble=0.810\n",
      "> 21: single=0.806, ensemble=0.810\n",
      "> 22: single=0.807, ensemble=0.810\n",
      "> 23: single=0.808, ensemble=0.810\n",
      "> 24: single=0.807, ensemble=0.810\n",
      "> 25: single=0.809, ensemble=0.810\n",
      "> 26: single=0.807, ensemble=0.809\n",
      "> 27: single=0.808, ensemble=0.810\n",
      "> 28: single=0.807, ensemble=0.810\n",
      "> 29: single=0.806, ensemble=0.810\n",
      "> 30: single=0.808, ensemble=0.810\n",
      "> 31: single=0.809, ensemble=0.810\n",
      "> 32: single=0.811, ensemble=0.810\n",
      "> 33: single=0.810, ensemble=0.810\n",
      "> 34: single=0.814, ensemble=0.810\n",
      "> 35: single=0.813, ensemble=0.810\n",
      "> 36: single=0.813, ensemble=0.810\n",
      "> 37: single=0.812, ensemble=0.810\n",
      "> 38: single=0.812, ensemble=0.809\n",
      "> 39: single=0.808, ensemble=0.811\n",
      "> 40: single=0.807, ensemble=0.811\n",
      "> 41: single=0.805, ensemble=0.811\n",
      "> 42: single=0.804, ensemble=0.810\n",
      "> 43: single=0.804, ensemble=0.810\n",
      "> 44: single=0.809, ensemble=0.809\n",
      "> 45: single=0.810, ensemble=0.809\n",
      "> 46: single=0.810, ensemble=0.809\n",
      "> 47: single=0.810, ensemble=0.810\n",
      "> 48: single=0.810, ensemble=0.811\n",
      "> 49: single=0.811, ensemble=0.811\n",
      "> 50: single=0.815, ensemble=0.811\n"
     ]
    }
   ],
   "source": [
    "# reverse loaded models so we build the ensemble with the last models first\n",
    "members = list(reversed(members))\n",
    "\n",
    "# evaluate different numbers of ensembles on hold out set\n",
    "single_scores, ensemble_scores = list(), list()\n",
    "for i in range(1, len(members)+1):\n",
    "    # evaluate model with i members\n",
    "    ensemble_score = evaluate_n_members(members, i, testX, testy)\n",
    "\n",
    "    # evaluate the i'th model standalone\n",
    "    testy_enc = to_categorical(testy)\n",
    "    _, single_score = members[i-1].evaluate(testX, testy_enc, verbose=0)\n",
    "\n",
    "    # summarize this step\n",
    "    print('> %d: single=%.3f, ensemble=%.3f' % (i, single_score, ensemble_score))\n",
    "    ensemble_scores.append(ensemble_score)\n",
    "    single_scores.append(single_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly, we can see that the ensemble appears to outperform most single models, consistently achieving an accuracy of around 81.8%. Next, the distribution of the accuracy of single models is reported. We can see that picking any of the saved models at random would result in a model with an accuracy of 81.6% on average with a reasonably tight standard deviation of 0.3%. We would require that a horizontal ensemble outperform this average to be useful.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.809 (0.002)\n"
     ]
    }
   ],
   "source": [
    "# summarize average accuracy of a single final model\n",
    "print('Accuracy %.3f (%.3f)' % (mean(single_scores), std(single_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a graph is created summarizing the performance of every single model (blue dot) and the ensemble of each size from 1 to 50 members. We can see from the blue dots that there is no structure to the models over the epochs, e.g., if the last models during training were better, there would be a downward trend in the accuracy from left to right. We can see that as we add more ensemble members, the better the performance of the horizontal voting ensemble in the orange line. We can see a flattening of performance on this problem, perhaps between 23 and 33 epochs; that might be a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, len(members)+1)]\n",
    "pyplot.plot(x_axis, single_scores, marker='o', linestyle='None')\n",
    "pyplot.plot(x_axis, ensemble_scores, marker='o')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "* **Dataset Size**. Repeat the experiments with a smaller or larger-sized dataset with a similar ratio of training to test examples.\n",
    "* **Larger Ensemble**. Re-run the example with hundreds of final models and report the impact of the large ensemble sizes of accuracy on the test set.\n",
    "* **Random Sampling of Models**. Re-run the example and compare the performance of ensembles of the same size with models saved over contiguous epochs to a random selection of saved models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you discovered how to reduce the variance of a final deep learning neural network model using a horizontal voting ensemble. Specifically, you learned:\n",
    "\n",
    "* It is challenging to choose a final neural network model that has high variance on a training dataset.\n",
    "* Horizontal voting ensembles provide a way to reduce variance and improve average model performance for models with high variance using a single training run.\n",
    "* How to develop a horizontal voting ensemble in Python using Keras to improve the performance of a final  Multilayer Perceptron model for multiclass classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
