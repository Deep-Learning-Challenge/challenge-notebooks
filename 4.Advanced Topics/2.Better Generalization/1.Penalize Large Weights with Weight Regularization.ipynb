{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deep-Learning-Challenge/challenge-notebooks/blob/master/4.Advanced%20Topics/2.Better%20Generalization/1.Penalize%20Large%20Weights%20with%20Weight%20Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalize Large Weights With Weight Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks learn a set of weights that best map inputs to outputs. A network with large network weights can be a sign of an unstable network where small changes in the input can lead to large changes in the output. This can signify that the network has overfitted the training dataset and will likely perform poorly when making predictions on new data. A solution to this problem is to update the learning algorithm to encourage the network to keep the weights small. This is called weight regularization, and it can be used as a general technique to reduce the overfitting of the training dataset and improve the generalization of the model. \n",
    "\n",
    "In this tutorial, you will discover weight regularization as an approach to reduce overfitting for neural networks.  After reading this tutorial, you will know:\n",
    "* Large weights in a neural network signify a more complex network that has overfit the training data.\n",
    "* Penalizing a network based on the size of the network weights during training can reduce overfitting.\n",
    "* An L1 or L2 vector norm penalty can be added to the optimization of the network to encourage smaller weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will discover the problem with neural networks with large weights, a technique that you can use to encourage the development of models with smaller weights called weight regularization, and tips for using this technique in your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem With Large Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting a neural network model, we must learn the weights of the network (i.e., the model parameters) using stochastic gradient descent and the training dataset. The longer we train the network, the more specialized the weights will become to the training data, overfitting the training data. The weights will grow in size to handle the specifics of the examples seen in the training data. Large weights make the network unstable. Although the weights will be specialized to the training dataset, minor variation or statistical noise on the expected inputs will result in large differences in the output.\n",
    "\n",
    "Generally, we refer to this model as having a large variance and a small bias. The model is sensitive to the specific examples, the statistical noise, in the training dataset. A model with large weights is more complex than a model with smaller weights. It is a sign of a network that may be overly specialized to the training data. In practice, we prefer to choose the simpler models to solve a problem (e.g., Occam's razor). We prefer models with smaller weights.\n",
    "\n",
    "Another possible issue is that there may be many input variables, each with different levels of relevance to the output variable. Sometimes we can use methods to select input variables, but the interrelationships between variables are often not obvious. Having small weights or even zero weights for less relevant or irrelevant inputs to the network will allow the model to focus on learning. This, too, will result in a simpler model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encourage Small Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning algorithm can be updated to encourage the network to use small weights. One way to do this is to change the calculation of loss used in optimizing the network and consider the weights' size. Remember that when we train a neural network, we minimize a loss function, such as the log loss in classification or mean squared error in regression. In calculating the loss between the predicted and expected values in a batch, we can add the current size of all weights in the network or add a layer to this calculation. This is called a penalty because we are penalizing the model proportional to the size of the weights in the model.\n",
    "\n",
    "The optimization algorithm will then push the model to have smaller weights, i.e., weights no larger than needed to perform well on the training dataset. Larger weights result in a larger penalty in the form of a larger loss score. Smaller weights are considered more regular or less specialized, and as such, we refer to this penalty as weight regularization. When this approach of penalizing model coefficients is used in other machine learning models such as linear regression or logistic regression, it may be referred to as shrinkage because the penalty encourages the coefficients to shrink during the optimization process.\n",
    "\n",
    "Adding a weight size penalty or weight regularization to a neural network reduces generalization error and allows the model to pay less attention to less relevant input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Penalize Large Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two parts to penalizing the model based on the size of the weights. The first is the calculation of the size of the weights, and the second is the amount of attention that the optimization process should pay to the penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Weight Size**\n",
    "\n",
    "Neural network weights are real values that can be positive or negative, as such, simply adding the weights is not sufficient. There are two main approaches used to calculate the size of the weights, they are:\n",
    "\n",
    "* Calculate the sum of the absolute values of the weights, called the L1 norm (or L<sup>1</sup>).\n",
    "* Calculate the sum of the squared values of the weights, called the L2 norm (or L<sup>2</sup>).\n",
    "\n",
    "The use of L2 in linear and logistic regression is often referred to as Ridge Regression. L1 encourages weights to 0.0 if possible, resulting in more sparse weights (with more 0.0 values). L2 offers more nuance, both penalizing larger weights more severely but resulting in less sparse weights. This is useful to know when developing an intuition for the penalty or examples of its usage.\n",
    "\n",
    "The weights may be considered a vector, and the magnitude of a vector is called its norm from linear algebra. As such, penalizing the model based on the size of the weights is also referred to as a weight or parameter norm penalty. It is possible to include both L1 and L2 approaches to calculating the size of the weights as the penalty. This is akin to using both penalties used in the Elastic Net algorithm for linear and logistic regression. The L2 approach is perhaps the most used and is traditionally referred to as weight decay in neural networks. It is called shrinkage in statistics, a name that encourages you to think of the impact of the penalty on the model weights during the learning process.\n",
    "\n",
    "Recall that each node has input weights and a bias weight. The bias weight is generally not included in the penalty because the input is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Control Impact of the Penalty**\n",
    "\n",
    "The calculated size of the weights is added to the loss objective function when training the network. Rather than adding each weight to the penalty directly, they can be weighted using a new hyperparameter called alpha (\\alpha) or sometimes lambda. This controls the amount of attention that the learning process should pay to the penalty. Alternatively, put another way, the amount to penalize the model is based on the size of the weights. The alpha hyperparameter has a value between 0.0 (no penalty) and 1.0 (full penalty). This hyperparameter controls the amount of bias in the model from 0.0, or low bias (high variance), to 1.0, or high bias (low variance).\n",
    "\n",
    "If the penalty is too strong, the model will underestimate the weights and underfit the problem. If the penalty is too weak, the model will be allowed to overfit the training data. The vector norm of the weights is often calculated per layer rather than across the entire network. This allows more flexibility in choosing the type of regularization used (e.g., L1 for inputs, L2 elsewhere) and flexibility in the alpha value, although it is common to use the same alpha value on each layer by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Using Weight Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides some tips for using weight regularization with your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use With All Network Types**\n",
    "\n",
    "Weight regularization is a generic approach. It can be used with most, perhaps all, types of neural network models, not least the most common network types of Multilayer Perceptrons, Convolutional Neural Networks, and Long Short-Term Memory Recurrent Neural Networks. In LSTMs, it may be desirable to use different penalties or penalty configurations for the input and recurrent connections.\n",
    "\n",
    "**Standardize Input Data**\n",
    "\n",
    "It is generally good practice to update input variables to have the same scale. When input variables have different scales, the scale of the network's weights will, in turn, vary accordingly. This introduces a problem when using weight regularization because the absolute or squared values of the weights must be added for use in the penalty. This problem can be addressed by either normalizing or standardizing input variables.\n",
    "\n",
    "**Use a Larger Network**\n",
    "\n",
    "It is common for larger networks (more layers or more nodes) to overfit the training data more easily. When using weight regularization, it is possible to use larger networks with less risk of overfitting. A good configuration strategy may be to start with larger networks and use weight decay.\n",
    "\n",
    "**Grid Search Parameters**\n",
    "\n",
    "It is common to use small values for the regularization hyperparameter that controls the contribution of each weight to the penalty. Perhaps start by testing values on a log scale, such as 0.1, 0.001, and 0.0001. Then use a grid search at the order of magnitude that shows the most promise.\n",
    "\n",
    "**Use L1 + L2 Together**\n",
    "\n",
    "Rather than trying to choose between L1 and L2 penalties, use both. Modern and effective linear regression methods such as the Elastic Net use both L1 and L2 penalties at the same time, and this can be a useful approach to try. This gives you both the nuance of L2 and the sparsity encouraged by L1.\n",
    "\n",
    "**Use on a Trained Network**\n",
    "\n",
    "The use of weight regularization may allow more elaborate training schemes. For example, a model may be fit on training data first without any regularization, then updated later with the use of a weight penalty to reduce the size of the weights of the already well-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Regularization Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will demonstrate how to use weight regularization to reduce the overfitting of an MLP on a simple binary classification problem. This example provides a template for applying weight regularization to your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a standard binary classification problem that defines two semi-circles of observations: one semi-circle for each class. Each observation has two input variables with the same scale and a class output value of 0 or 1. This dataset is called the `moons` dataset because of the shape of the observations in each class when plotted. We can use the `make_moons()` function to generate observations from this problem. We will add noise to the data and seed the random number generator to generate the same samples each time the code is run.\n",
    "\n",
    "```\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the dataset where the two variables are taken as `x` and `y` coordinates on a graph, and the class value is taken as the color of the observation. The complete example of generating the dataset and plotting it is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# scatter plot for each class value\n",
    "for class_value in range(2):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "    \n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a scatter plot showing the semi-circle or moon shape of the observations in each class. We can see the noise in the dispersal of the points, making the moons less obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good test problem because a line cannot separate the classes, e.g., are not linearly separable, requiring a nonlinear method such as a neural network to address. We have only generated 100 samples, which is small for a neural network, providing the opportunity to overfit the training dataset and have a higher error on the test dataset: a good case for using regularization. Further, the samples have noise, allowing the model to learn aspects of the samples that do not generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can develop an MLP model to address this binary classification problem. The model will have one hidden layer with more nodes that may be required to solve this problem, providing an opportunity to overfit. We will also train the model for longer than is required to ensure the model overfits. Before we define the model, we will split the dataset into train and test sets, using 30 examples to train the model and 70 to evaluate the fit model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the model. The model uses 500 nodes in the hidden layer and the rectified linear activation function. A sigmoid activation function is used in the output layer to predict class values of 0 or 1. The model is optimized using the binary cross-entropy loss function, suitable for binary classification problems and the efficient Adam version of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined model is then fit on the training data for 4,000 epochs and the default batch size of 32. We will use the test set as the validation dataset to get an idea of the model performance on a holdout dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will evaluate the performance of the model on the test dataset and report the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will plot learning curves of model performance in terms of cross-entropy loss and classification accuracy on the train and test datasets for each epoch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie all of these pieces together; the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the model performance on the train and test datasets. We can see that the model has better performance on the training dataset than the test dataset, one possible sign of overfitting.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line plots are also created showing learning curves of cross-entropy loss and classification accuracy on the train and test sets for each training epoch. The learning curve for loss shows a clear pattern of overfitting, mirrored in the learning curve for the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model With Weight Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add weight regularization to the hidden layer to reduce the overfitting of the model to the training dataset and improve the performance on the holdout set. We will use the L2 vector norm, also called weight decay, chosen arbitrarily with a regularization parameter (called alpha or lambda) of 0.001. This can be done by adding the `kernel_regularizer` argument to the layer and setting it to an instance of `l2`.\n",
    "\n",
    "```\n",
    "model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated example of fitting and evaluating the model on the moons dataset with weight regularization is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp with weight regularization for the moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the performance of the model on the train and test datasets.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we see no change in the accuracy on the training dataset and an improvement on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect that the telltale learning curve for overfitting would also have been changed through weight regularization. Instead of the model's accuracy on the test set increasing and then decreasing again, we should see it continually rise during training. As expected, we see the learning curves for loss and accuracy on the test dataset plateau, indicating that the model has no longer overfit the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Regularization Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you can confirm that weight regularization may improve your overfit model, you can test different regularization parameter values. It is a good practice to first grid search through some orders of magnitude between 0.0 and 0.1, once a level is found, it is a grid search on that level. We can grid search through the orders of magnitude by defining the values to test, looping through each, and recording the train and test performance.\n",
    "\n",
    "```\n",
    "...\n",
    "# grid search values\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "all_train, all_test = list(), list()\n",
    "for param in values:\n",
    "...\n",
    "model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(param)))\n",
    "...\n",
    "all_train.append(train_acc)\n",
    "all_test.append(test_acc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all of the values, we can graph the results as a line plot to help spot any patterns in the configurations to the train and test accuracies. Because parameters jump orders of magnitude (powers of 10), we can use a logarithmic scale to create a line plot of the results. The Matplotlib library allows this via the `semilogx()` function. For example:\n",
    "\n",
    "```\n",
    "pyplot.semilogx(values, all_train, label='train', marker='o')\n",
    "pyplot.semilogx(values, all_test, label='test', marker='o')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example for grid searching weight regularization values on the moon dataset is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp with weight regularization for the moons dataset\n",
    "from sklearn.datasets import make_moons\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# grid search values\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "all_train, all_test = list(), list()\n",
    "for param in values:\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(param)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=4000, verbose=0)\n",
    "\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "\n",
    "    print('Param: %f, Train: %.3f, Test: %.3f' % (param, train_acc, test_acc))\n",
    "    all_train.append(train_acc)\n",
    "    all_test.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the parameter value and the accuracy on the train and test sets for each evaluated model.\n",
    "\n",
    "**Note**: Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, the results suggest that 0.01 or 0.001 may be sufficient and may provide good bounds for further grid searching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot of the results is also created, showing the increase in test accuracy with larger weight regularization parameter values, at least to a point. We can see that using the largest value of 0.1 results in a large drop in both train and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test means\n",
    "pyplot.semilogx(values, all_train, label='train', marker='o')\n",
    "pyplot.semilogx(values, all_test, label='test', marker='o')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Try Alternates**. Update the example to use L1 or the combined L1L2 methods instead of L2 regularization.\n",
    "* **Report Weight Norm**. Update the example to calculate the magnitude of the network weights and demonstrate that regularization made the magnitude smaller.\n",
    "* **Regularize Output Layer**. Update the example to regularize the output layer of the model and compare the results.\n",
    "* **Regularize Bias**. Update the example to regularize the bias weight and compare the results.\n",
    "* **Repeated Model Evaluation**. Update the example to fit and evaluate the model multiple times and report the mean and standard deviation of model performance.\n",
    "* **Grid Search Along Order of Magnitude**. Update the grid search example to grid search within the best-performing order of magnitude of parameter values.\n",
    "* **Repeated Regularization of Model**. Create a new example to continue the training of a fit model with increasing levels of regularization (e.g., 1E-6, 1E-5, etc.) and see if it results in a better performing model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you discovered weight regularization as an approach to reduce overfitting for neural networks. Specifically, you learned:\n",
    "\n",
    "* Large weights in a neural network signify a more complex network that has overfit the training data.\n",
    "* Penalizing a network based on the size of the network weights during training can reduce overfitting.\n",
    "* An L1 or L2 vector norm penalty can be added to the optimization of the network to encourage smaller weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
