{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Deep-Learning-Challenge/challenge-notebooks/blob/master/4.Advanced%20Topics/2.Better%20Generalization/5.%20Promote%20Robustness%20with%20Noise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promote Robustness with Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network with a small dataset can cause the network to memorize all training examples, leading to poor performance on a holdout dataset. Given the patchy or sparse sampling of points in the high-dimensional input space, small datasets may also represent a harder mapping problem for neural networks to learn. One approach to making the input space smoother and easier to learn is to add noise to inputs during training. In this tutorial, you will discover that adding noise to a neural network during training can improve the robustness of the network, resulting in better generalization and faster learning. After reading this tutorial, you will know:\n",
    "\n",
    "* Small datasets can make learning challenging for neural nets, and the examples can be memorized.\n",
    "* Adding noise during training can make the training process more robust and reduce generalization error.\n",
    "* Noise is traditionally added to the inputs but can also be added to weights, gradients, and even activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will discover the brittleness of large network weights and how the addition of statistical noise can provide a regularizing effect, as well as tips to help when adding noise to your neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge of Small Training Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small datasets can introduce problems when training large neural networks. The first problem is that the network may effectively memorize the training dataset. Instead of learning a general mapping from inputs to outputs, the model may learn the specific input examples and their associated outputs. This will result in a model that performs well on the training dataset and poor on new data, such as a holdout dataset. The second problem is that a small dataset provides less opportunity to describe the structure of the input space and its relationship to the output. More training data provides a richer description of the problem from which the model may learn. Fewer data points mean that rather than a smooth input space, the points may represent a jarring and disjointed structure that may result in a difficult, if not unlearnable, the mapping function. It is not always possible to acquire more data. Further, getting a hold of more data may not address these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Random Noise During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach to improving generalization error and improving the mapping problem's structure is to add random noise.\n",
    "\n",
    "At first, this sounds like a recipe for making learning more challenging. It is a counter-intuitive suggestion to improving performance because one would expect noise to degrade the model's performance during training.\n",
    "\n",
    "The addition of noise during the training of a neural network model has a regularization effect and, in turn, improves the robustness of the model. It has been shown to have a similar impact on the loss function as the addition of a penalty term, as in the case of weight regularization\n",
    "methods.\n",
    "\n",
    "Each time a training sample is exposed to the model, random noise is added to the input variables making them different every time it is exposed. In this way, adding noise to input samples is a simple form of data augmentation. In effect, adding noise expands the size of the training dataset.\n",
    "\n",
    "Adding noise means that the network cannot memorize training samples because they are changing all of the time, resulting in smaller network weights and a more robust network with lower generalization error. The noise means that it is as though new samples are being drawn from the domain in the vicinity of known samples, smoothing the structure of the input space. This smoothing may mean that the mapping function is easier for the network to learn, resulting in better and faster learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How and Where to Add noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common type of noise used during training is the addition of Gaussian noise to input variables. Gaussian noise, or white noise, has a mean of zero and a standard deviation of one and can be generated as needed using a pseudorandom number generator. The addition of Gaussian noise to the inputs to a neural network was traditionally referred to as jitter or random jitter after using the term in signal processing to refer to the uncorrelated random noise in electrical circuits. The amount of noise added (e.g., the spread or standard deviation) is a configurable hyperparameter. Too little noise has no effect, whereas too much noise makes the mapping function challenging to learn.\n",
    "\n",
    "The standard deviation of the random noise controls the amount of spread and can be adjusted based on the scale of each input variable. It can be easier to configure if the scale of the input variables has first been normalized. Noise is only added during training. No noise is added during the evaluation of the model or when the model is used to make predictions on new data. The addition of noise is also an important part of automatic feature learning, such as in autoencoders, so-called denoising autoencoders that explicitly require models to learn robust features in the presence of noise added to inputs.\n",
    "\n",
    "Although additional noise to the inputs is the most common and widely studied approach, random noise can be added to other network parts during training. Some examples include:\n",
    "\n",
    "* Add noise to activations, i.e., the outputs of each layer.\n",
    "* Add noise to weights, i.e., an alternative to the inputs.\n",
    "* Add noise to the gradients, i.e., the direction to update weights.\n",
    "* Add noise to the outputs, i.e., the labels or target variables.\n",
    "\n",
    "The addition of noise to the layer activations allows noise to be used at any point in the network. This can be beneficial for very deep networks. Noise can be added to the layer outputs themselves, but this is more likely achieved via a noisy activation function. The addition of noise to weights allows the approach to be used throughout the network in a consistent way instead of adding noise to inputs and layer activations. This is particularly useful in recurrent neural networks.\n",
    "\n",
    "The addition of noise to gradients focuses more on improving the robustness of the optimization process itself rather than the structure of the input domain. The noise can start high at the beginning of training and decrease over time, much like a decaying learning rate.\n",
    "This approach has proven to be an effective method for very deep networks and various network types.\n",
    "\n",
    "Adding noise to the activations, weights, or gradients provides a more generic approach to adding noise that is invariant to the input variables provided to the model. If the problem domain is believed or expected to have mislabeled examples, then adding noise to the class label can improve the model's robustness to this type of error. Although, it can be easy to derail the learning process. Adding noise to a continuous target variable in the case of regression or time series forecasting is much like the addition of noise to the input variables and\n",
    "maybe a better use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Adding Noise During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides some tips for adding noise during training with your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Types for Adding Noise**\n",
    "\n",
    "Noise can be added to training regardless of the type of problem that is being addressed. It is appropriate to try adding noise to both classification and regression type problems. The type of noise can be specialized to the types of data used as input to the model, for example, two-dimensional noise in images and signal noise in audio data.\n",
    "\n",
    "**Add Noise to Different Network Types**\n",
    "\n",
    "Adding noise during training is a generic method that can be used regardless of the neural network used. It was a method used primarily with Multilayer Perceptrons given their prior dominance, but it can be used with Convolutional and Recurrent Neural Networks.\n",
    "\n",
    "**Rescale Data First**\n",
    "\n",
    "It is important that the addition of noise has a consistent effect on the model. This requires that the input data is rescaled so that all variables have the same scale so that when noise is added to the inputs with a fixed variance, it has the same effect. It also applies to adding noise to weights and gradients as they are affected by the scale of the inputs. This can be achieved via standardization or normalization of input variables. If random noise is added after data scaling, the variables may need to be rescaled, perhaps per minibatch.\n",
    "\n",
    "**Test the Amount of Noise**\n",
    "You cannot know how much noise will benefit your specific model on your training dataset. Experiment with different amounts, and even different types of noise, to discover what works best. Be systematic and use controlled experiments, perhaps on smaller datasets across a range of values.\n",
    "\n",
    "**Noisy Training Only**\n",
    "\n",
    "Noise is only added during the training of your model. Be sure that any source of noise is not added during the evaluation of your model or when your model is used to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Regularization Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will demonstrate how to use noise regularization to reduce the overfitting of an MLP on a simple binary classification problem. This example provides a template for applying noise regularization to your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a standard binary classification problem that defines two two-dimensional concentric circles of observations: one circle for each class. Each observation has two input variables with the same scale and a class output value of 0 or 1. This dataset is called the `circles` dataset because of the shape of the observations in each class when plotted. We can use the `make_circles()` function to generate observations from this problem. We will add noise to the data and seed the random number generator to generate the same samples each time the code is run.\n",
    "\n",
    "```\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the dataset where the two variables are taken as `x` and `y` coordinates on a graph, and the class value is taken as the color of the observation. The complete example of generating the dataset and plotting it is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# scatter plot for each class value\n",
    "for class_value in range(2):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "    \n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a scatter plot showing the concentric circles shape of the observations in each class. We can see the noise in the dispersal of the points, making the circles less obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good test problem because a line cannot separate the classes, e.g., are not linearly separable, requiring a nonlinear method such as a neural network to address. We have only generated 100 samples, which is small for a neural network, providing the opportunity to overfit the training dataset and have a higher error on the test dataset: a good case for using regularization. Further, the samples have noise, allowing the model to learn aspects of the samples that do not generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can develop an MLP model to address this binary classification problem. The model will have one hidden layer with more nodes that may be required to solve this problem, providing an opportunity to overfit. We will also train the model for longer than is required to ensure the model overfits. Before we define the model, we will split the dataset into train and test sets, using 30 examples to train the model and 70 to evaluate the fit model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the model. The model uses 500 nodes in the hidden layer and the rectified linear activation function. A sigmoid activation function is used in the output layer to predict class values of 0 or 1. The model is optimized using the binary cross-entropy loss function, suitable for binary classification problems and the efficient Adam version of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined model is then fit on the training data for 4,000 epochs and the default batch size of 32. We will use the test set as the validation dataset to get an idea of the model performance on a holdout dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the performance of the model on the test dataset and report the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will plot the model's performance on both the train and test set for each epoch. If the model does indeed overfit the training dataset, we would expect the line plot of cross-entropy loss and classification accuracy to show the pattern of overfitting. That is an improvement on both train and test sets until an inflection point, after which performance continues to improve for the train set and begins to get worse for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie all of these pieces together; the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the model performance on the train and test datasets. We can see that the model has better performance on the training dataset than the test dataset, one possible sign of overfitting.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figure is created showing line plots of the model loss and accuracy on the train and test sets. We can see the expected shape of an overfit model where test accuracy increases to a point and then begins to decrease again. The effect is even more dramatic with loss, showing a large increase in test set loss as training continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With Input Layer Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is defined by points that have a controlled amount of statistical noise. Nevertheless, we may wish to add further noise to the input values because the dataset is small. This will create more samples or resampling the domain, making the structure of the input space artificially smoother. This may make the problem easier to learn and improve generalization performance. We can add a GaussianNoise layer as the input layer, and the amount of noise must be small. Given that the input values are within the range [0, 1], we will add Gaussian noise with a mean of 0.0 and a standard deviation of 0.01, chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.01, input_shape=(2,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example of this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp overfit on the two circles dataset with input noise\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.01, input_shape=(2,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we may see a slight lift in the model's performance on the test dataset, with no negative impact on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the impact of the added noise on the evaluation of the model during training as graphed on the line plot. The noise causes the model's accuracy to jump around during training, possibly due to the noise introducing points that conflict with true points from the training dataset. Perhaps a lower input noise standard deviation would be more appropriate. The model still shows a pattern of overfitting, with a rise and then fall in test accuracy over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With Hidden Layer Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to adding noise to the input values is to add noise between the hidden layers. This can be done by adding noise to the linear output of the layer (weighted sum) before the activation function is applied, in this case, a rectified linear activation function. We can also use a larger standard deviation for the noise as the model is less sensitive to noise at this level, given the presumably larger weights from overfitting. We will use a standard deviation of 0.1, again, chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example with Gaussian noise between the hidden layers is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp overfit on the two circles dataset with hidden layer noise\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see a marked increase in the model's performance on the hold-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see from the line plot of accuracy over training epochs that the model no longer appears to show the properties of overfitting with regard to classification accuracy. The learning curves for loss do still show a pattern of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also experiment and add the noise after the outputs of the first hidden layer pass through the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp overfit on the two circles dataset with hidden layer noise (alternate)\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "Surprisingly, we see little difference in the model's performance, perhaps a tiny lift in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see from the line plot of accuracy over training epochs that the model no longer shows signs of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "* **Repeated Evaluation**. Update the example to use repeated model evaluation with and without noise and report performance as the mean and standard deviation over repeats.\n",
    "* **Grid Search Standard Deviation**. Develop a grid search to discover the amount of noise that reliably results in the best-performing model.\n",
    "* **Input and Hidden Noise**. Update the example to introduce noise at both the input and hidden layers of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you discovered that adding noise to a neural network during training can improve the robustness of the network resulting in better generalization and faster learning. Specifically, you learned:\n",
    "\n",
    "* Small datasets can make learning challenging for neural nets, and the examples can be memorized.\n",
    "* Adding noise during training can make the training process more robust and reduce generalization error.\n",
    "* Noise is traditionally added to the inputs but can also be added to weights, gradients, and even activation functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
