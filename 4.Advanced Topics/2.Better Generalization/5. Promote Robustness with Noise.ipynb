{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promote Robustness with Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network with a small dataset can cause the network to memorize all training examples, leading to poor performance on a holdout dataset. Given the patchy or sparse sampling of points in the high-dimensional input space, small datasets may also represent a harder mapping problem for neural networks to learn. One approach to making the input space smoother and easier to learn is to add noise to inputs during training. In this tutorial, you will discover that adding noise to a neural network during training can improve the robustness of the network, resulting in better generalization and faster learning. After reading this tutorial, you will know:\n",
    "\n",
    "* Small datasets can make learning challenging for neural nets, and the examples can be memorized.\n",
    "* Adding noise during training can make the training process more robust and reduce generalization error.\n",
    "* Noise is traditionally added to the inputs but can also be added to weights, gradients, and even activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will discover the brittleness of large network weights and how the addition of statistical noise can provide a regularizing effect, as well as tips to help when adding noise to your neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge of Small Training Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small datasets can introduce problems when training large neural networks. The first problem is that the network may effectively memorize the training dataset. Instead of learning a general mapping from inputs to outputs, the model may learn the specific input examples and their associated outputs. This will result in a model that performs well on the training dataset and poor on new data, such as a holdout dataset. The second problem is that a small dataset provides less opportunity to describe the structure of the input space and its relationship to the output. More training data provides a richer description of the problem from which the model may learn. Fewer data points mean that rather than a smooth input space, the points may represent a jarring and disjointed structure that may result in a difficult, if not unlearnable, the mapping function. It is not always possible to acquire more data. Further, getting a hold of more data may not address these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Random Noise During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach to improving generalization error and improving the mapping problem's structure is to add random noise.\n",
    "\n",
    "At first, this sounds like a recipe for making learning more challenging. It is a counter-intuitive suggestion to improving performance because one would expect noise to degrade the model's performance during training.\n",
    "\n",
    "The addition of noise during the training of a neural network model has a regularization effect and, in turn, improves the robustness of the model. It has been shown to have a similar impact on the loss function as the addition of a penalty term, as in the case of weight regularization\n",
    "methods.\n",
    "\n",
    "Each time a training sample is exposed to the model, random noise is added to the input variables making them different every time it is exposed. In this way, adding noise to input samples is a simple form of data augmentation. In effect, adding noise expands the size of the training dataset.\n",
    "\n",
    "Adding noise means that the network cannot memorize training samples because they are changing all of the time, resulting in smaller network weights and a more robust network with lower generalization error. The noise means that it is as though new samples are being drawn from the domain in the vicinity of known samples, smoothing the structure of the input space. This smoothing may mean that the mapping function is easier for the network to learn, resulting in better and faster learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How and Where to Add noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common type of noise used during training is the addition of Gaussian noise to input variables. Gaussian noise, or white noise, has a mean of zero and a standard deviation of one and can be generated as needed using a pseudorandom number generator. The addition of Gaussian noise to the inputs to a neural network was traditionally referred to as jitter or random jitter after using the term in signal processing to refer to the uncorrelated random noise in electrical circuits. The amount of noise added (e.g., the spread or standard deviation) is a configurable hyperparameter. Too little noise has no effect, whereas too much noise makes the mapping function challenging to learn.\n",
    "\n",
    "The standard deviation of the random noise controls the amount of spread and can be adjusted based on the scale of each input variable. It can be easier to configure if the scale of the input variables has first been normalized. Noise is only added during training. No noise is added during the evaluation of the model or when the model is used to make predictions on new data. The addition of noise is also an important part of automatic feature learning, such as in autoencoders, so-called denoising autoencoders that explicitly require models to learn robust features in the presence of noise added to inputs.\n",
    "\n",
    "Although additional noise to the inputs is the most common and widely studied approach, random noise can be added to other network parts during training. Some examples include:\n",
    "\n",
    "* Add noise to activations, i.e., the outputs of each layer.\n",
    "* Add noise to weights, i.e., an alternative to the inputs.\n",
    "* Add noise to the gradients, i.e., the direction to update weights.\n",
    "* Add noise to the outputs, i.e., the labels or target variables.\n",
    "\n",
    "The addition of noise to the layer activations allows noise to be used at any point in the network. This can be beneficial for very deep networks. Noise can be added to the layer outputs themselves, but this is more likely achieved via a noisy activation function. The addition of noise to weights allows the approach to be used throughout the network in a consistent way instead of adding noise to inputs and layer activations. This is particularly useful in recurrent neural networks.\n",
    "\n",
    "The addition of noise to gradients focuses more on improving the robustness of the optimization process itself rather than the structure of the input domain. The noise can start high at the beginning of training and decrease over time, much like a decaying learning rate.\n",
    "This approach has proven to be an effective method for very deep networks and various network types.\n",
    "\n",
    "Adding noise to the activations, weights, or gradients provides a more generic approach to adding noise that is invariant to the input variables provided to the model. If the problem domain is believed or expected to have mislabeled examples, then adding noise to the class label can improve the model's robustness to this type of error. Although, it can be easy to derail the learning process. Adding noise to a continuous target variable in the case of regression or time series forecasting is much like the addition of noise to the input variables and\n",
    "maybe a better use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Adding Noise During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides some tips for adding noise during training with your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Types for Adding Noise**\n",
    "\n",
    "Noise can be added to training regardless of the type of problem that is being addressed. It is appropriate to try adding noise to both classification and regression type problems. The type of noise can be specialized to the types of data used as input to the model, for example, two-dimensional noise in images and signal noise in audio data.\n",
    "\n",
    "**Add Noise to Different Network Types**\n",
    "\n",
    "Adding noise during training is a generic method that can be used regardless of the neural network used. It was a method used primarily with Multilayer Perceptrons given their prior dominance, but it can be used with Convolutional and Recurrent Neural Networks.\n",
    "\n",
    "**Rescale Data First**\n",
    "\n",
    "It is important that the addition of noise has a consistent effect on the model. This requires that the input data is rescaled so that all variables have the same scale so that when noise is added to the inputs with a fixed variance, it has the same effect. It also applies to adding noise to weights and gradients as they are affected by the scale of the inputs. This can be achieved via standardization or normalization of input variables. If random noise is added after data scaling, the variables may need to be rescaled, perhaps per minibatch.\n",
    "\n",
    "**Test the Amount of Noise**\n",
    "You cannot know how much noise will benefit your specific model on your training dataset. Experiment with different amounts, and even different types of noise, to discover what works best. Be systematic and use controlled experiments, perhaps on smaller datasets across a range of values.\n",
    "\n",
    "**Noisy Training Only**\n",
    "\n",
    "Noise is only added during the training of your model. Be sure that any source of noise is not added during the evaluation of your model or when your model is used to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Regularization Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will demonstrate how to use noise regularization to reduce the overfitting of an MLP on a simple binary classification problem. This example provides a template for applying noise regularization to your neural network for classification and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a standard binary classification problem that defines two two-dimensional concentric circles of observations: one circle for each class. Each observation has two input variables with the same scale and a class output value of 0 or 1. This dataset is called the `circles` dataset because of the shape of the observations in each class when plotted. We can use the `make_circles()` function to generate observations from this problem. We will add noise to the data and seed the random number generator to generate the same samples each time the code is run.\n",
    "\n",
    "```\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the dataset where the two variables are taken as `x` and `y` coordinates on a graph, and the class value is taken as the color of the observation. The complete example of generating the dataset and plotting it is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot of moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# scatter plot for each class value\n",
    "for class_value in range(2):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "    \n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "\n",
    "# show plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a scatter plot showing the concentric circles shape of the observations in each class. We can see the noise in the dispersal of the points, making the circles less obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good test problem because a line cannot separate the classes, e.g., are not linearly separable, requiring a nonlinear method such as a neural network to address. We have only generated 100 samples, which is small for a neural network, providing the opportunity to overfit the training dataset and have a higher error on the test dataset: a good case for using regularization. Further, the samples have noise, allowing the model to learn aspects of the samples that do not generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can develop an MLP model to address this binary classification problem. The model will have one hidden layer with more nodes that may be required to solve this problem, providing an opportunity to overfit. We will also train the model for longer than is required to ensure the model overfits. Before we define the model, we will split the dataset into train and test sets, using 30 examples to train the model and 70 to evaluate the fit model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the model. The model uses 500 nodes in the hidden layer and the rectified linear activation function. A sigmoid activation function is used in the output layer to predict class values of 0 or 1. The model is optimized using the binary cross-entropy loss function, suitable for binary classification problems and the efficient Adam version of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined model is then fit on the training data for 4,000 epochs and the default batch size of 32. We will use the test set as the validation dataset to get an idea of the model performance on a holdout dataset during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.6943 - accuracy: 0.5333 - val_loss: 0.6961 - val_accuracy: 0.4429\n",
      "Epoch 2/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6911 - accuracy: 0.6667 - val_loss: 0.6978 - val_accuracy: 0.4571\n",
      "Epoch 3/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6880 - accuracy: 0.6000 - val_loss: 0.6996 - val_accuracy: 0.4571\n",
      "Epoch 4/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6850 - accuracy: 0.6000 - val_loss: 0.7014 - val_accuracy: 0.4429\n",
      "Epoch 5/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6823 - accuracy: 0.6000 - val_loss: 0.7034 - val_accuracy: 0.4429\n",
      "Epoch 6/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6796 - accuracy: 0.6000 - val_loss: 0.7054 - val_accuracy: 0.4286\n",
      "Epoch 7/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6771 - accuracy: 0.6000 - val_loss: 0.7074 - val_accuracy: 0.4286\n",
      "Epoch 8/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6747 - accuracy: 0.6000 - val_loss: 0.7095 - val_accuracy: 0.4286\n",
      "Epoch 9/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6725 - accuracy: 0.6000 - val_loss: 0.7116 - val_accuracy: 0.4286\n",
      "Epoch 10/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6703 - accuracy: 0.6000 - val_loss: 0.7137 - val_accuracy: 0.4429\n",
      "Epoch 11/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6682 - accuracy: 0.6000 - val_loss: 0.7158 - val_accuracy: 0.4429\n",
      "Epoch 12/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6662 - accuracy: 0.6000 - val_loss: 0.7179 - val_accuracy: 0.4571\n",
      "Epoch 13/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6643 - accuracy: 0.6000 - val_loss: 0.7200 - val_accuracy: 0.4571\n",
      "Epoch 14/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6625 - accuracy: 0.6000 - val_loss: 0.7220 - val_accuracy: 0.4571\n",
      "Epoch 15/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6607 - accuracy: 0.6000 - val_loss: 0.7240 - val_accuracy: 0.4571\n",
      "Epoch 16/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6591 - accuracy: 0.6000 - val_loss: 0.7260 - val_accuracy: 0.4571\n",
      "Epoch 17/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6574 - accuracy: 0.6000 - val_loss: 0.7279 - val_accuracy: 0.4571\n",
      "Epoch 18/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6558 - accuracy: 0.6000 - val_loss: 0.7299 - val_accuracy: 0.4571\n",
      "Epoch 19/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6542 - accuracy: 0.6000 - val_loss: 0.7318 - val_accuracy: 0.4571\n",
      "Epoch 20/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6527 - accuracy: 0.6000 - val_loss: 0.7337 - val_accuracy: 0.4571\n",
      "Epoch 21/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6512 - accuracy: 0.6000 - val_loss: 0.7356 - val_accuracy: 0.4571\n",
      "Epoch 22/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6497 - accuracy: 0.6000 - val_loss: 0.7374 - val_accuracy: 0.4571\n",
      "Epoch 23/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6483 - accuracy: 0.6000 - val_loss: 0.7393 - val_accuracy: 0.4571\n",
      "Epoch 24/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6468 - accuracy: 0.6000 - val_loss: 0.7411 - val_accuracy: 0.4571\n",
      "Epoch 25/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6455 - accuracy: 0.6000 - val_loss: 0.7429 - val_accuracy: 0.4571\n",
      "Epoch 26/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6441 - accuracy: 0.6000 - val_loss: 0.7447 - val_accuracy: 0.4571\n",
      "Epoch 27/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6428 - accuracy: 0.6000 - val_loss: 0.7464 - val_accuracy: 0.4571\n",
      "Epoch 28/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6415 - accuracy: 0.6000 - val_loss: 0.7480 - val_accuracy: 0.4571\n",
      "Epoch 29/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6402 - accuracy: 0.6000 - val_loss: 0.7496 - val_accuracy: 0.4714\n",
      "Epoch 30/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6390 - accuracy: 0.6000 - val_loss: 0.7511 - val_accuracy: 0.4714\n",
      "Epoch 31/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6377 - accuracy: 0.6000 - val_loss: 0.7525 - val_accuracy: 0.4714\n",
      "Epoch 32/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6365 - accuracy: 0.6000 - val_loss: 0.7539 - val_accuracy: 0.4714\n",
      "Epoch 33/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6353 - accuracy: 0.5667 - val_loss: 0.7551 - val_accuracy: 0.4714\n",
      "Epoch 34/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6341 - accuracy: 0.5667 - val_loss: 0.7563 - val_accuracy: 0.4714\n",
      "Epoch 35/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6329 - accuracy: 0.5667 - val_loss: 0.7573 - val_accuracy: 0.4714\n",
      "Epoch 36/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6318 - accuracy: 0.5667 - val_loss: 0.7582 - val_accuracy: 0.4714\n",
      "Epoch 37/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6306 - accuracy: 0.6000 - val_loss: 0.7591 - val_accuracy: 0.4714\n",
      "Epoch 38/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6295 - accuracy: 0.6000 - val_loss: 0.7598 - val_accuracy: 0.4714\n",
      "Epoch 39/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6284 - accuracy: 0.6000 - val_loss: 0.7605 - val_accuracy: 0.4571\n",
      "Epoch 40/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6272 - accuracy: 0.6000 - val_loss: 0.7610 - val_accuracy: 0.4571\n",
      "Epoch 41/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6261 - accuracy: 0.6333 - val_loss: 0.7615 - val_accuracy: 0.4571\n",
      "Epoch 42/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6250 - accuracy: 0.6333 - val_loss: 0.7618 - val_accuracy: 0.4571\n",
      "Epoch 43/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6239 - accuracy: 0.6333 - val_loss: 0.7621 - val_accuracy: 0.4571\n",
      "Epoch 44/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6228 - accuracy: 0.6667 - val_loss: 0.7624 - val_accuracy: 0.4571\n",
      "Epoch 45/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6217 - accuracy: 0.6667 - val_loss: 0.7625 - val_accuracy: 0.4571\n",
      "Epoch 46/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6205 - accuracy: 0.6667 - val_loss: 0.7627 - val_accuracy: 0.4571\n",
      "Epoch 47/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6194 - accuracy: 0.6667 - val_loss: 0.7628 - val_accuracy: 0.4571\n",
      "Epoch 48/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6183 - accuracy: 0.6667 - val_loss: 0.7629 - val_accuracy: 0.4571\n",
      "Epoch 49/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6172 - accuracy: 0.6667 - val_loss: 0.7630 - val_accuracy: 0.4571\n",
      "Epoch 50/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6161 - accuracy: 0.6667 - val_loss: 0.7631 - val_accuracy: 0.4571\n",
      "Epoch 51/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6150 - accuracy: 0.6667 - val_loss: 0.7632 - val_accuracy: 0.4571\n",
      "Epoch 52/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6139 - accuracy: 0.6667 - val_loss: 0.7633 - val_accuracy: 0.4571\n",
      "Epoch 53/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6128 - accuracy: 0.6667 - val_loss: 0.7635 - val_accuracy: 0.4571\n",
      "Epoch 54/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6117 - accuracy: 0.6667 - val_loss: 0.7636 - val_accuracy: 0.4571\n",
      "Epoch 55/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6667 - val_loss: 0.7638 - val_accuracy: 0.4714\n",
      "Epoch 56/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6096 - accuracy: 0.6667 - val_loss: 0.7639 - val_accuracy: 0.4571\n",
      "Epoch 57/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6085 - accuracy: 0.6667 - val_loss: 0.7642 - val_accuracy: 0.4571\n",
      "Epoch 58/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6074 - accuracy: 0.6667 - val_loss: 0.7644 - val_accuracy: 0.4571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6064 - accuracy: 0.6667 - val_loss: 0.7646 - val_accuracy: 0.4571\n",
      "Epoch 60/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6053 - accuracy: 0.6667 - val_loss: 0.7648 - val_accuracy: 0.4571\n",
      "Epoch 61/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6042 - accuracy: 0.6667 - val_loss: 0.7650 - val_accuracy: 0.4571\n",
      "Epoch 62/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6031 - accuracy: 0.6667 - val_loss: 0.7652 - val_accuracy: 0.4571\n",
      "Epoch 63/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6021 - accuracy: 0.6667 - val_loss: 0.7654 - val_accuracy: 0.4571\n",
      "Epoch 64/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6010 - accuracy: 0.6667 - val_loss: 0.7655 - val_accuracy: 0.4571\n",
      "Epoch 65/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5999 - accuracy: 0.6667 - val_loss: 0.7657 - val_accuracy: 0.4571\n",
      "Epoch 66/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5988 - accuracy: 0.6667 - val_loss: 0.7659 - val_accuracy: 0.4571\n",
      "Epoch 67/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5978 - accuracy: 0.6667 - val_loss: 0.7661 - val_accuracy: 0.4571\n",
      "Epoch 68/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5967 - accuracy: 0.6667 - val_loss: 0.7662 - val_accuracy: 0.4571\n",
      "Epoch 69/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5956 - accuracy: 0.6667 - val_loss: 0.7664 - val_accuracy: 0.4571\n",
      "Epoch 70/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5946 - accuracy: 0.6667 - val_loss: 0.7665 - val_accuracy: 0.4571\n",
      "Epoch 71/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5935 - accuracy: 0.6667 - val_loss: 0.7667 - val_accuracy: 0.4571\n",
      "Epoch 72/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5925 - accuracy: 0.6667 - val_loss: 0.7668 - val_accuracy: 0.4571\n",
      "Epoch 73/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5914 - accuracy: 0.6667 - val_loss: 0.7669 - val_accuracy: 0.4571\n",
      "Epoch 74/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5904 - accuracy: 0.6667 - val_loss: 0.7671 - val_accuracy: 0.4571\n",
      "Epoch 75/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5894 - accuracy: 0.6667 - val_loss: 0.7672 - val_accuracy: 0.4571\n",
      "Epoch 76/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5883 - accuracy: 0.6667 - val_loss: 0.7673 - val_accuracy: 0.4571\n",
      "Epoch 77/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5873 - accuracy: 0.7000 - val_loss: 0.7675 - val_accuracy: 0.4571\n",
      "Epoch 78/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5862 - accuracy: 0.7000 - val_loss: 0.7676 - val_accuracy: 0.4571\n",
      "Epoch 79/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5852 - accuracy: 0.7000 - val_loss: 0.7677 - val_accuracy: 0.4571\n",
      "Epoch 80/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5842 - accuracy: 0.7000 - val_loss: 0.7678 - val_accuracy: 0.4571\n",
      "Epoch 81/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5831 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4571\n",
      "Epoch 82/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5821 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4571\n",
      "Epoch 83/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5810 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4571\n",
      "Epoch 84/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5800 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4571\n",
      "Epoch 85/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5789 - accuracy: 0.7000 - val_loss: 0.7678 - val_accuracy: 0.4571\n",
      "Epoch 86/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5779 - accuracy: 0.7000 - val_loss: 0.7677 - val_accuracy: 0.4571\n",
      "Epoch 87/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5769 - accuracy: 0.7000 - val_loss: 0.7676 - val_accuracy: 0.4571\n",
      "Epoch 88/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5758 - accuracy: 0.7000 - val_loss: 0.7675 - val_accuracy: 0.4571\n",
      "Epoch 89/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5747 - accuracy: 0.7000 - val_loss: 0.7673 - val_accuracy: 0.4571\n",
      "Epoch 90/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5737 - accuracy: 0.7000 - val_loss: 0.7672 - val_accuracy: 0.4571\n",
      "Epoch 91/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5726 - accuracy: 0.7000 - val_loss: 0.7670 - val_accuracy: 0.4571\n",
      "Epoch 92/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5716 - accuracy: 0.7000 - val_loss: 0.7667 - val_accuracy: 0.4571\n",
      "Epoch 93/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5705 - accuracy: 0.7000 - val_loss: 0.7665 - val_accuracy: 0.4571\n",
      "Epoch 94/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5694 - accuracy: 0.7000 - val_loss: 0.7662 - val_accuracy: 0.4571\n",
      "Epoch 95/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5684 - accuracy: 0.7000 - val_loss: 0.7658 - val_accuracy: 0.4571\n",
      "Epoch 96/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5673 - accuracy: 0.7000 - val_loss: 0.7654 - val_accuracy: 0.4571\n",
      "Epoch 97/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5662 - accuracy: 0.7000 - val_loss: 0.7651 - val_accuracy: 0.4571\n",
      "Epoch 98/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5651 - accuracy: 0.7000 - val_loss: 0.7647 - val_accuracy: 0.4571\n",
      "Epoch 99/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5640 - accuracy: 0.7000 - val_loss: 0.7643 - val_accuracy: 0.4571\n",
      "Epoch 100/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5629 - accuracy: 0.7000 - val_loss: 0.7639 - val_accuracy: 0.4571\n",
      "Epoch 101/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5618 - accuracy: 0.7333 - val_loss: 0.7634 - val_accuracy: 0.4571\n",
      "Epoch 102/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5607 - accuracy: 0.7333 - val_loss: 0.7629 - val_accuracy: 0.4571\n",
      "Epoch 103/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5596 - accuracy: 0.7333 - val_loss: 0.7624 - val_accuracy: 0.4714\n",
      "Epoch 104/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5585 - accuracy: 0.7333 - val_loss: 0.7618 - val_accuracy: 0.4714\n",
      "Epoch 105/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5573 - accuracy: 0.7333 - val_loss: 0.7612 - val_accuracy: 0.4714\n",
      "Epoch 106/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5562 - accuracy: 0.7333 - val_loss: 0.7606 - val_accuracy: 0.4714\n",
      "Epoch 107/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5551 - accuracy: 0.7333 - val_loss: 0.7599 - val_accuracy: 0.4714\n",
      "Epoch 108/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5540 - accuracy: 0.7333 - val_loss: 0.7594 - val_accuracy: 0.4714\n",
      "Epoch 109/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5528 - accuracy: 0.7333 - val_loss: 0.7588 - val_accuracy: 0.4714\n",
      "Epoch 110/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5517 - accuracy: 0.7333 - val_loss: 0.7582 - val_accuracy: 0.4714\n",
      "Epoch 111/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5506 - accuracy: 0.7333 - val_loss: 0.7576 - val_accuracy: 0.4857\n",
      "Epoch 112/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5495 - accuracy: 0.7333 - val_loss: 0.7569 - val_accuracy: 0.4857\n",
      "Epoch 113/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5483 - accuracy: 0.7333 - val_loss: 0.7562 - val_accuracy: 0.4857\n",
      "Epoch 114/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5472 - accuracy: 0.7333 - val_loss: 0.7554 - val_accuracy: 0.4857\n",
      "Epoch 115/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5460 - accuracy: 0.7333 - val_loss: 0.7547 - val_accuracy: 0.4857\n",
      "Epoch 116/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5448 - accuracy: 0.7333 - val_loss: 0.7539 - val_accuracy: 0.4857\n",
      "Epoch 117/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5437 - accuracy: 0.7333 - val_loss: 0.7532 - val_accuracy: 0.4857\n",
      "Epoch 118/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5425 - accuracy: 0.7333 - val_loss: 0.7525 - val_accuracy: 0.4857\n",
      "Epoch 119/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5414 - accuracy: 0.7333 - val_loss: 0.7519 - val_accuracy: 0.4857\n",
      "Epoch 120/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5402 - accuracy: 0.7333 - val_loss: 0.7512 - val_accuracy: 0.4857\n",
      "Epoch 121/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5391 - accuracy: 0.7333 - val_loss: 0.7505 - val_accuracy: 0.4857\n",
      "Epoch 122/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5380 - accuracy: 0.7333 - val_loss: 0.7498 - val_accuracy: 0.4857\n",
      "Epoch 123/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5368 - accuracy: 0.7333 - val_loss: 0.7490 - val_accuracy: 0.4857\n",
      "Epoch 124/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5356 - accuracy: 0.7333 - val_loss: 0.7483 - val_accuracy: 0.4857\n",
      "Epoch 125/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5344 - accuracy: 0.7333 - val_loss: 0.7475 - val_accuracy: 0.4857\n",
      "Epoch 126/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5331 - accuracy: 0.7333 - val_loss: 0.7466 - val_accuracy: 0.4857\n",
      "Epoch 127/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5319 - accuracy: 0.7333 - val_loss: 0.7457 - val_accuracy: 0.4857\n",
      "Epoch 128/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5306 - accuracy: 0.7333 - val_loss: 0.7447 - val_accuracy: 0.4857\n",
      "Epoch 129/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5293 - accuracy: 0.7333 - val_loss: 0.7436 - val_accuracy: 0.4857\n",
      "Epoch 130/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5281 - accuracy: 0.7333 - val_loss: 0.7426 - val_accuracy: 0.4857\n",
      "Epoch 131/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5268 - accuracy: 0.7333 - val_loss: 0.7414 - val_accuracy: 0.4857\n",
      "Epoch 132/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5255 - accuracy: 0.7333 - val_loss: 0.7403 - val_accuracy: 0.4857\n",
      "Epoch 133/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5243 - accuracy: 0.7333 - val_loss: 0.7392 - val_accuracy: 0.5000\n",
      "Epoch 134/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5230 - accuracy: 0.7333 - val_loss: 0.7382 - val_accuracy: 0.5143\n",
      "Epoch 135/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5217 - accuracy: 0.7333 - val_loss: 0.7370 - val_accuracy: 0.5143\n",
      "Epoch 136/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5204 - accuracy: 0.7333 - val_loss: 0.7359 - val_accuracy: 0.5143\n",
      "Epoch 137/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5191 - accuracy: 0.7667 - val_loss: 0.7347 - val_accuracy: 0.5143\n",
      "Epoch 138/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5178 - accuracy: 0.7667 - val_loss: 0.7335 - val_accuracy: 0.5143\n",
      "Epoch 139/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5165 - accuracy: 0.7667 - val_loss: 0.7323 - val_accuracy: 0.5429\n",
      "Epoch 140/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5152 - accuracy: 0.7667 - val_loss: 0.7311 - val_accuracy: 0.5429\n",
      "Epoch 141/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5139 - accuracy: 0.7667 - val_loss: 0.7299 - val_accuracy: 0.5429\n",
      "Epoch 142/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5126 - accuracy: 0.7667 - val_loss: 0.7287 - val_accuracy: 0.5429\n",
      "Epoch 143/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5113 - accuracy: 0.7667 - val_loss: 0.7274 - val_accuracy: 0.5429\n",
      "Epoch 144/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5099 - accuracy: 0.7667 - val_loss: 0.7261 - val_accuracy: 0.5429\n",
      "Epoch 145/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5086 - accuracy: 0.7667 - val_loss: 0.7248 - val_accuracy: 0.5429\n",
      "Epoch 146/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5072 - accuracy: 0.7667 - val_loss: 0.7235 - val_accuracy: 0.5429\n",
      "Epoch 147/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5059 - accuracy: 0.7667 - val_loss: 0.7223 - val_accuracy: 0.5429\n",
      "Epoch 148/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5045 - accuracy: 0.7667 - val_loss: 0.7212 - val_accuracy: 0.5429\n",
      "Epoch 149/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5031 - accuracy: 0.7667 - val_loss: 0.7201 - val_accuracy: 0.5429\n",
      "Epoch 150/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5018 - accuracy: 0.7667 - val_loss: 0.7189 - val_accuracy: 0.5429\n",
      "Epoch 151/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5004 - accuracy: 0.7667 - val_loss: 0.7177 - val_accuracy: 0.5571\n",
      "Epoch 152/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4991 - accuracy: 0.7667 - val_loss: 0.7165 - val_accuracy: 0.5714\n",
      "Epoch 153/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4977 - accuracy: 0.7667 - val_loss: 0.7153 - val_accuracy: 0.5857\n",
      "Epoch 154/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4964 - accuracy: 0.7667 - val_loss: 0.7140 - val_accuracy: 0.5857\n",
      "Epoch 155/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4950 - accuracy: 0.7667 - val_loss: 0.7126 - val_accuracy: 0.5857\n",
      "Epoch 156/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4936 - accuracy: 0.7667 - val_loss: 0.7112 - val_accuracy: 0.5857\n",
      "Epoch 157/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4922 - accuracy: 0.7667 - val_loss: 0.7098 - val_accuracy: 0.5857\n",
      "Epoch 158/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4908 - accuracy: 0.7667 - val_loss: 0.7084 - val_accuracy: 0.5857\n",
      "Epoch 159/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4895 - accuracy: 0.7667 - val_loss: 0.7071 - val_accuracy: 0.5857\n",
      "Epoch 160/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4881 - accuracy: 0.7667 - val_loss: 0.7057 - val_accuracy: 0.5857\n",
      "Epoch 161/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4867 - accuracy: 0.7667 - val_loss: 0.7043 - val_accuracy: 0.5857\n",
      "Epoch 162/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4854 - accuracy: 0.7667 - val_loss: 0.7029 - val_accuracy: 0.5857\n",
      "Epoch 163/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4840 - accuracy: 0.7667 - val_loss: 0.7015 - val_accuracy: 0.5857\n",
      "Epoch 164/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4827 - accuracy: 0.8000 - val_loss: 0.7000 - val_accuracy: 0.5857\n",
      "Epoch 165/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4814 - accuracy: 0.8000 - val_loss: 0.6985 - val_accuracy: 0.5857\n",
      "Epoch 166/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4800 - accuracy: 0.8000 - val_loss: 0.6970 - val_accuracy: 0.5857\n",
      "Epoch 167/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4786 - accuracy: 0.8000 - val_loss: 0.6956 - val_accuracy: 0.5857\n",
      "Epoch 168/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4772 - accuracy: 0.8000 - val_loss: 0.6942 - val_accuracy: 0.5857\n",
      "Epoch 169/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4758 - accuracy: 0.8000 - val_loss: 0.6928 - val_accuracy: 0.5857\n",
      "Epoch 170/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4745 - accuracy: 0.8000 - val_loss: 0.6914 - val_accuracy: 0.5857\n",
      "Epoch 171/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4731 - accuracy: 0.8333 - val_loss: 0.6900 - val_accuracy: 0.5857\n",
      "Epoch 172/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4717 - accuracy: 0.8333 - val_loss: 0.6886 - val_accuracy: 0.5857\n",
      "Epoch 173/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4703 - accuracy: 0.8333 - val_loss: 0.6872 - val_accuracy: 0.5857\n",
      "Epoch 174/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4689 - accuracy: 0.8333 - val_loss: 0.6858 - val_accuracy: 0.5857\n",
      "Epoch 175/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4675 - accuracy: 0.8333 - val_loss: 0.6845 - val_accuracy: 0.5857\n",
      "Epoch 176/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4662 - accuracy: 0.8333 - val_loss: 0.6831 - val_accuracy: 0.5857\n",
      "Epoch 177/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4648 - accuracy: 0.8333 - val_loss: 0.6817 - val_accuracy: 0.5857\n",
      "Epoch 178/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4634 - accuracy: 0.8333 - val_loss: 0.6803 - val_accuracy: 0.5857\n",
      "Epoch 179/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4620 - accuracy: 0.8333 - val_loss: 0.6789 - val_accuracy: 0.5857\n",
      "Epoch 180/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4606 - accuracy: 0.8333 - val_loss: 0.6775 - val_accuracy: 0.6000\n",
      "Epoch 181/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4592 - accuracy: 0.8333 - val_loss: 0.6760 - val_accuracy: 0.6000\n",
      "Epoch 182/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4579 - accuracy: 0.8333 - val_loss: 0.6745 - val_accuracy: 0.6000\n",
      "Epoch 183/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4565 - accuracy: 0.8333 - val_loss: 0.6730 - val_accuracy: 0.6143\n",
      "Epoch 184/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4551 - accuracy: 0.8333 - val_loss: 0.6715 - val_accuracy: 0.6143\n",
      "Epoch 185/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4538 - accuracy: 0.8333 - val_loss: 0.6701 - val_accuracy: 0.6143\n",
      "Epoch 186/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4524 - accuracy: 0.8333 - val_loss: 0.6687 - val_accuracy: 0.6286\n",
      "Epoch 187/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4511 - accuracy: 0.8333 - val_loss: 0.6674 - val_accuracy: 0.6286\n",
      "Epoch 188/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4498 - accuracy: 0.8333 - val_loss: 0.6661 - val_accuracy: 0.6286\n",
      "Epoch 189/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4485 - accuracy: 0.8333 - val_loss: 0.6647 - val_accuracy: 0.6286\n",
      "Epoch 190/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4471 - accuracy: 0.8333 - val_loss: 0.6633 - val_accuracy: 0.6286\n",
      "Epoch 191/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4458 - accuracy: 0.8333 - val_loss: 0.6619 - val_accuracy: 0.6286\n",
      "Epoch 192/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4445 - accuracy: 0.8333 - val_loss: 0.6605 - val_accuracy: 0.6286\n",
      "Epoch 193/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4432 - accuracy: 0.8333 - val_loss: 0.6592 - val_accuracy: 0.6286\n",
      "Epoch 194/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4419 - accuracy: 0.8333 - val_loss: 0.6578 - val_accuracy: 0.6286\n",
      "Epoch 195/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4406 - accuracy: 0.8333 - val_loss: 0.6565 - val_accuracy: 0.6286\n",
      "Epoch 196/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4393 - accuracy: 0.8333 - val_loss: 0.6551 - val_accuracy: 0.6286\n",
      "Epoch 197/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4380 - accuracy: 0.8333 - val_loss: 0.6537 - val_accuracy: 0.6429\n",
      "Epoch 198/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4367 - accuracy: 0.8333 - val_loss: 0.6523 - val_accuracy: 0.6429\n",
      "Epoch 199/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4354 - accuracy: 0.8333 - val_loss: 0.6508 - val_accuracy: 0.6571\n",
      "Epoch 200/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4341 - accuracy: 0.8333 - val_loss: 0.6493 - val_accuracy: 0.6571\n",
      "Epoch 201/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4328 - accuracy: 0.8333 - val_loss: 0.6478 - val_accuracy: 0.6571\n",
      "Epoch 202/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4315 - accuracy: 0.8333 - val_loss: 0.6463 - val_accuracy: 0.6571\n",
      "Epoch 203/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4302 - accuracy: 0.8333 - val_loss: 0.6449 - val_accuracy: 0.6571\n",
      "Epoch 204/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4289 - accuracy: 0.8333 - val_loss: 0.6435 - val_accuracy: 0.6571\n",
      "Epoch 205/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4276 - accuracy: 0.8333 - val_loss: 0.6421 - val_accuracy: 0.6571\n",
      "Epoch 206/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4263 - accuracy: 0.8333 - val_loss: 0.6407 - val_accuracy: 0.6571\n",
      "Epoch 207/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4251 - accuracy: 0.8333 - val_loss: 0.6392 - val_accuracy: 0.6571\n",
      "Epoch 208/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4238 - accuracy: 0.8333 - val_loss: 0.6377 - val_accuracy: 0.6571\n",
      "Epoch 209/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4225 - accuracy: 0.8333 - val_loss: 0.6362 - val_accuracy: 0.6571\n",
      "Epoch 210/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4212 - accuracy: 0.8333 - val_loss: 0.6347 - val_accuracy: 0.6571\n",
      "Epoch 211/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4199 - accuracy: 0.8333 - val_loss: 0.6332 - val_accuracy: 0.6714\n",
      "Epoch 212/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4186 - accuracy: 0.8333 - val_loss: 0.6318 - val_accuracy: 0.6714\n",
      "Epoch 213/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4173 - accuracy: 0.8333 - val_loss: 0.6303 - val_accuracy: 0.6714\n",
      "Epoch 214/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4161 - accuracy: 0.8333 - val_loss: 0.6288 - val_accuracy: 0.6714\n",
      "Epoch 215/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4148 - accuracy: 0.8333 - val_loss: 0.6274 - val_accuracy: 0.6714\n",
      "Epoch 216/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4135 - accuracy: 0.8333 - val_loss: 0.6260 - val_accuracy: 0.6714\n",
      "Epoch 217/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4122 - accuracy: 0.8333 - val_loss: 0.6245 - val_accuracy: 0.6714\n",
      "Epoch 218/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4110 - accuracy: 0.8333 - val_loss: 0.6230 - val_accuracy: 0.6714\n",
      "Epoch 219/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4097 - accuracy: 0.8333 - val_loss: 0.6215 - val_accuracy: 0.6571\n",
      "Epoch 220/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4084 - accuracy: 0.8333 - val_loss: 0.6200 - val_accuracy: 0.6571\n",
      "Epoch 221/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4072 - accuracy: 0.8333 - val_loss: 0.6186 - val_accuracy: 0.6571\n",
      "Epoch 222/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4059 - accuracy: 0.8333 - val_loss: 0.6172 - val_accuracy: 0.6571\n",
      "Epoch 223/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4046 - accuracy: 0.8333 - val_loss: 0.6158 - val_accuracy: 0.6714\n",
      "Epoch 224/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4034 - accuracy: 0.8333 - val_loss: 0.6143 - val_accuracy: 0.6714\n",
      "Epoch 225/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4021 - accuracy: 0.8333 - val_loss: 0.6128 - val_accuracy: 0.6714\n",
      "Epoch 226/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4008 - accuracy: 0.8333 - val_loss: 0.6113 - val_accuracy: 0.6714\n",
      "Epoch 227/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.6098 - val_accuracy: 0.6714\n",
      "Epoch 228/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3983 - accuracy: 0.8333 - val_loss: 0.6083 - val_accuracy: 0.6714\n",
      "Epoch 229/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3971 - accuracy: 0.8333 - val_loss: 0.6068 - val_accuracy: 0.6714\n",
      "Epoch 230/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3958 - accuracy: 0.8333 - val_loss: 0.6053 - val_accuracy: 0.6714\n",
      "Epoch 231/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3946 - accuracy: 0.8333 - val_loss: 0.6038 - val_accuracy: 0.6714\n",
      "Epoch 232/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3933 - accuracy: 0.8333 - val_loss: 0.6023 - val_accuracy: 0.6714\n",
      "Epoch 233/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3921 - accuracy: 0.8333 - val_loss: 0.6007 - val_accuracy: 0.6714\n",
      "Epoch 234/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3908 - accuracy: 0.8333 - val_loss: 0.5993 - val_accuracy: 0.6714\n",
      "Epoch 235/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3896 - accuracy: 0.8333 - val_loss: 0.5978 - val_accuracy: 0.6714\n",
      "Epoch 236/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3883 - accuracy: 0.8333 - val_loss: 0.5964 - val_accuracy: 0.6714\n",
      "Epoch 237/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.5950 - val_accuracy: 0.6714\n",
      "Epoch 238/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5935 - val_accuracy: 0.6714\n",
      "Epoch 239/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5921 - val_accuracy: 0.6714\n",
      "Epoch 240/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3833 - accuracy: 0.8333 - val_loss: 0.5905 - val_accuracy: 0.6714\n",
      "Epoch 241/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3821 - accuracy: 0.8333 - val_loss: 0.5890 - val_accuracy: 0.6714\n",
      "Epoch 242/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3808 - accuracy: 0.8333 - val_loss: 0.5876 - val_accuracy: 0.6714\n",
      "Epoch 243/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3796 - accuracy: 0.8333 - val_loss: 0.5861 - val_accuracy: 0.6714\n",
      "Epoch 244/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3783 - accuracy: 0.8333 - val_loss: 0.5848 - val_accuracy: 0.6714\n",
      "Epoch 245/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3771 - accuracy: 0.8333 - val_loss: 0.5834 - val_accuracy: 0.6714\n",
      "Epoch 246/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3758 - accuracy: 0.8333 - val_loss: 0.5820 - val_accuracy: 0.6714\n",
      "Epoch 247/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3746 - accuracy: 0.8333 - val_loss: 0.5806 - val_accuracy: 0.6714\n",
      "Epoch 248/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3733 - accuracy: 0.8333 - val_loss: 0.5791 - val_accuracy: 0.6714\n",
      "Epoch 249/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3720 - accuracy: 0.8333 - val_loss: 0.5777 - val_accuracy: 0.6714\n",
      "Epoch 250/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3708 - accuracy: 0.8333 - val_loss: 0.5763 - val_accuracy: 0.6714\n",
      "Epoch 251/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3695 - accuracy: 0.8333 - val_loss: 0.5749 - val_accuracy: 0.6857\n",
      "Epoch 252/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3683 - accuracy: 0.8333 - val_loss: 0.5734 - val_accuracy: 0.6857\n",
      "Epoch 253/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3670 - accuracy: 0.8333 - val_loss: 0.5719 - val_accuracy: 0.6857\n",
      "Epoch 254/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3658 - accuracy: 0.8333 - val_loss: 0.5704 - val_accuracy: 0.6857\n",
      "Epoch 255/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3645 - accuracy: 0.8333 - val_loss: 0.5691 - val_accuracy: 0.6857\n",
      "Epoch 256/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3633 - accuracy: 0.8667 - val_loss: 0.5678 - val_accuracy: 0.6857\n",
      "Epoch 257/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3622 - accuracy: 0.8667 - val_loss: 0.5666 - val_accuracy: 0.6857\n",
      "Epoch 258/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3610 - accuracy: 0.8667 - val_loss: 0.5653 - val_accuracy: 0.6857\n",
      "Epoch 259/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3598 - accuracy: 0.8667 - val_loss: 0.5640 - val_accuracy: 0.6857\n",
      "Epoch 260/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3586 - accuracy: 0.8667 - val_loss: 0.5627 - val_accuracy: 0.6857\n",
      "Epoch 261/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3574 - accuracy: 0.8667 - val_loss: 0.5615 - val_accuracy: 0.6857\n",
      "Epoch 262/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3562 - accuracy: 0.8667 - val_loss: 0.5604 - val_accuracy: 0.6857\n",
      "Epoch 263/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3551 - accuracy: 0.8667 - val_loss: 0.5593 - val_accuracy: 0.6857\n",
      "Epoch 264/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3539 - accuracy: 0.8667 - val_loss: 0.5581 - val_accuracy: 0.6857\n",
      "Epoch 265/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3528 - accuracy: 0.8667 - val_loss: 0.5568 - val_accuracy: 0.7000\n",
      "Epoch 266/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3516 - accuracy: 0.8667 - val_loss: 0.5556 - val_accuracy: 0.7000\n",
      "Epoch 267/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3504 - accuracy: 0.8667 - val_loss: 0.5544 - val_accuracy: 0.7000\n",
      "Epoch 268/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3493 - accuracy: 0.8667 - val_loss: 0.5532 - val_accuracy: 0.7000\n",
      "Epoch 269/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3481 - accuracy: 0.8667 - val_loss: 0.5520 - val_accuracy: 0.7000\n",
      "Epoch 270/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3470 - accuracy: 0.8667 - val_loss: 0.5508 - val_accuracy: 0.7000\n",
      "Epoch 271/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3458 - accuracy: 0.8667 - val_loss: 0.5497 - val_accuracy: 0.7000\n",
      "Epoch 272/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3447 - accuracy: 0.8667 - val_loss: 0.5486 - val_accuracy: 0.7000\n",
      "Epoch 273/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3436 - accuracy: 0.8667 - val_loss: 0.5474 - val_accuracy: 0.7000\n",
      "Epoch 274/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3424 - accuracy: 0.8667 - val_loss: 0.5462 - val_accuracy: 0.7143\n",
      "Epoch 275/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3413 - accuracy: 0.8667 - val_loss: 0.5450 - val_accuracy: 0.7143\n",
      "Epoch 276/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3402 - accuracy: 0.8667 - val_loss: 0.5439 - val_accuracy: 0.7143\n",
      "Epoch 277/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3391 - accuracy: 0.8667 - val_loss: 0.5428 - val_accuracy: 0.7143\n",
      "Epoch 278/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3380 - accuracy: 0.8667 - val_loss: 0.5417 - val_accuracy: 0.7143\n",
      "Epoch 279/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3369 - accuracy: 0.8667 - val_loss: 0.5406 - val_accuracy: 0.7143\n",
      "Epoch 280/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3358 - accuracy: 0.8667 - val_loss: 0.5395 - val_accuracy: 0.7143\n",
      "Epoch 281/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3346 - accuracy: 0.8667 - val_loss: 0.5383 - val_accuracy: 0.7143\n",
      "Epoch 282/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3335 - accuracy: 0.8667 - val_loss: 0.5371 - val_accuracy: 0.7143\n",
      "Epoch 283/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3324 - accuracy: 0.8667 - val_loss: 0.5359 - val_accuracy: 0.7000\n",
      "Epoch 284/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3314 - accuracy: 0.8667 - val_loss: 0.5347 - val_accuracy: 0.7000\n",
      "Epoch 285/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3303 - accuracy: 0.8667 - val_loss: 0.5336 - val_accuracy: 0.7000\n",
      "Epoch 286/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3292 - accuracy: 0.8667 - val_loss: 0.5324 - val_accuracy: 0.7143\n",
      "Epoch 287/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3281 - accuracy: 0.8667 - val_loss: 0.5314 - val_accuracy: 0.7143\n",
      "Epoch 288/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3271 - accuracy: 0.8667 - val_loss: 0.5303 - val_accuracy: 0.7143\n",
      "Epoch 289/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3260 - accuracy: 0.8667 - val_loss: 0.5293 - val_accuracy: 0.7286\n",
      "Epoch 290/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3249 - accuracy: 0.8667 - val_loss: 0.5284 - val_accuracy: 0.7286\n",
      "Epoch 291/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3239 - accuracy: 0.8667 - val_loss: 0.5274 - val_accuracy: 0.7286\n",
      "Epoch 292/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3228 - accuracy: 0.8667 - val_loss: 0.5263 - val_accuracy: 0.7286\n",
      "Epoch 293/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3217 - accuracy: 0.8667 - val_loss: 0.5251 - val_accuracy: 0.7286\n",
      "Epoch 294/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3207 - accuracy: 0.8667 - val_loss: 0.5240 - val_accuracy: 0.7286\n",
      "Epoch 295/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3196 - accuracy: 0.8667 - val_loss: 0.5230 - val_accuracy: 0.7286\n",
      "Epoch 296/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3186 - accuracy: 0.8667 - val_loss: 0.5221 - val_accuracy: 0.7286\n",
      "Epoch 297/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3175 - accuracy: 0.8667 - val_loss: 0.5211 - val_accuracy: 0.7286\n",
      "Epoch 298/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3165 - accuracy: 0.8667 - val_loss: 0.5201 - val_accuracy: 0.7286\n",
      "Epoch 299/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3155 - accuracy: 0.8667 - val_loss: 0.5191 - val_accuracy: 0.7286\n",
      "Epoch 300/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3144 - accuracy: 0.8667 - val_loss: 0.5181 - val_accuracy: 0.7286\n",
      "Epoch 301/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3134 - accuracy: 0.8667 - val_loss: 0.5171 - val_accuracy: 0.7286\n",
      "Epoch 302/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3124 - accuracy: 0.8667 - val_loss: 0.5160 - val_accuracy: 0.7286\n",
      "Epoch 303/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3114 - accuracy: 0.8667 - val_loss: 0.5150 - val_accuracy: 0.7286\n",
      "Epoch 304/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3104 - accuracy: 0.8667 - val_loss: 0.5141 - val_accuracy: 0.7286\n",
      "Epoch 305/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3094 - accuracy: 0.8667 - val_loss: 0.5132 - val_accuracy: 0.7286\n",
      "Epoch 306/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3083 - accuracy: 0.8667 - val_loss: 0.5122 - val_accuracy: 0.7286\n",
      "Epoch 307/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3073 - accuracy: 0.8667 - val_loss: 0.5113 - val_accuracy: 0.7286\n",
      "Epoch 308/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3063 - accuracy: 0.8667 - val_loss: 0.5103 - val_accuracy: 0.7286\n",
      "Epoch 309/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3053 - accuracy: 0.8667 - val_loss: 0.5094 - val_accuracy: 0.7286\n",
      "Epoch 310/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3044 - accuracy: 0.8667 - val_loss: 0.5084 - val_accuracy: 0.7286\n",
      "Epoch 311/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3034 - accuracy: 0.8667 - val_loss: 0.5074 - val_accuracy: 0.7429\n",
      "Epoch 312/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3024 - accuracy: 0.8667 - val_loss: 0.5064 - val_accuracy: 0.7429\n",
      "Epoch 313/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3014 - accuracy: 0.8667 - val_loss: 0.5054 - val_accuracy: 0.7429\n",
      "Epoch 314/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3004 - accuracy: 0.9000 - val_loss: 0.5046 - val_accuracy: 0.7429\n",
      "Epoch 315/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2995 - accuracy: 0.9000 - val_loss: 0.5039 - val_accuracy: 0.7429\n",
      "Epoch 316/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2985 - accuracy: 0.9333 - val_loss: 0.5033 - val_accuracy: 0.7429\n",
      "Epoch 317/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2975 - accuracy: 0.9333 - val_loss: 0.5025 - val_accuracy: 0.7429\n",
      "Epoch 318/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2965 - accuracy: 0.9333 - val_loss: 0.5015 - val_accuracy: 0.7429\n",
      "Epoch 319/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2956 - accuracy: 0.9333 - val_loss: 0.5006 - val_accuracy: 0.7429\n",
      "Epoch 320/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2946 - accuracy: 0.9333 - val_loss: 0.4997 - val_accuracy: 0.7429\n",
      "Epoch 321/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2936 - accuracy: 0.9333 - val_loss: 0.4988 - val_accuracy: 0.7429\n",
      "Epoch 322/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2927 - accuracy: 0.9333 - val_loss: 0.4979 - val_accuracy: 0.7429\n",
      "Epoch 323/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2917 - accuracy: 0.9333 - val_loss: 0.4971 - val_accuracy: 0.7571\n",
      "Epoch 324/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2908 - accuracy: 0.9333 - val_loss: 0.4963 - val_accuracy: 0.7571\n",
      "Epoch 325/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2898 - accuracy: 0.9333 - val_loss: 0.4955 - val_accuracy: 0.7571\n",
      "Epoch 326/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2889 - accuracy: 0.9333 - val_loss: 0.4946 - val_accuracy: 0.7571\n",
      "Epoch 327/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2879 - accuracy: 0.9333 - val_loss: 0.4936 - val_accuracy: 0.7571\n",
      "Epoch 328/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2870 - accuracy: 0.9333 - val_loss: 0.4927 - val_accuracy: 0.7571\n",
      "Epoch 329/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2861 - accuracy: 0.9333 - val_loss: 0.4919 - val_accuracy: 0.7571\n",
      "Epoch 330/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2851 - accuracy: 0.9333 - val_loss: 0.4911 - val_accuracy: 0.7571\n",
      "Epoch 331/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2842 - accuracy: 0.9333 - val_loss: 0.4904 - val_accuracy: 0.7571\n",
      "Epoch 332/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2833 - accuracy: 0.9333 - val_loss: 0.4897 - val_accuracy: 0.7571\n",
      "Epoch 333/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2824 - accuracy: 0.9333 - val_loss: 0.4890 - val_accuracy: 0.7571\n",
      "Epoch 334/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2815 - accuracy: 0.9667 - val_loss: 0.4883 - val_accuracy: 0.7571\n",
      "Epoch 335/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2806 - accuracy: 0.9667 - val_loss: 0.4875 - val_accuracy: 0.7571\n",
      "Epoch 336/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2797 - accuracy: 0.9667 - val_loss: 0.4868 - val_accuracy: 0.7571\n",
      "Epoch 337/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2788 - accuracy: 0.9667 - val_loss: 0.4861 - val_accuracy: 0.7571\n",
      "Epoch 338/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2779 - accuracy: 0.9667 - val_loss: 0.4853 - val_accuracy: 0.7571\n",
      "Epoch 339/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2770 - accuracy: 0.9667 - val_loss: 0.4844 - val_accuracy: 0.7571\n",
      "Epoch 340/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2761 - accuracy: 0.9667 - val_loss: 0.4835 - val_accuracy: 0.7571\n",
      "Epoch 341/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2753 - accuracy: 0.9667 - val_loss: 0.4828 - val_accuracy: 0.7571\n",
      "Epoch 342/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2744 - accuracy: 0.9667 - val_loss: 0.4822 - val_accuracy: 0.7571\n",
      "Epoch 343/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2735 - accuracy: 0.9667 - val_loss: 0.4816 - val_accuracy: 0.7571\n",
      "Epoch 344/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2726 - accuracy: 0.9667 - val_loss: 0.4810 - val_accuracy: 0.7571\n",
      "Epoch 345/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2718 - accuracy: 0.9667 - val_loss: 0.4803 - val_accuracy: 0.7571\n",
      "Epoch 346/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2709 - accuracy: 0.9667 - val_loss: 0.4796 - val_accuracy: 0.7571\n",
      "Epoch 347/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2701 - accuracy: 0.9667 - val_loss: 0.4789 - val_accuracy: 0.7571\n",
      "Epoch 348/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2692 - accuracy: 0.9667 - val_loss: 0.4782 - val_accuracy: 0.7571\n",
      "Epoch 349/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2683 - accuracy: 0.9667 - val_loss: 0.4776 - val_accuracy: 0.7571\n",
      "Epoch 350/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2675 - accuracy: 0.9667 - val_loss: 0.4770 - val_accuracy: 0.7571\n",
      "Epoch 351/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2667 - accuracy: 0.9667 - val_loss: 0.4764 - val_accuracy: 0.7571\n",
      "Epoch 352/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2658 - accuracy: 0.9667 - val_loss: 0.4758 - val_accuracy: 0.7571\n",
      "Epoch 353/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2650 - accuracy: 0.9667 - val_loss: 0.4752 - val_accuracy: 0.7571\n",
      "Epoch 354/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2641 - accuracy: 0.9667 - val_loss: 0.4745 - val_accuracy: 0.7571\n",
      "Epoch 355/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2633 - accuracy: 0.9667 - val_loss: 0.4739 - val_accuracy: 0.7714\n",
      "Epoch 356/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2625 - accuracy: 0.9667 - val_loss: 0.4731 - val_accuracy: 0.7857\n",
      "Epoch 357/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2617 - accuracy: 0.9667 - val_loss: 0.4725 - val_accuracy: 0.7857\n",
      "Epoch 358/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2608 - accuracy: 0.9667 - val_loss: 0.4720 - val_accuracy: 0.7857\n",
      "Epoch 359/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2600 - accuracy: 0.9667 - val_loss: 0.4714 - val_accuracy: 0.7857\n",
      "Epoch 360/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2592 - accuracy: 0.9667 - val_loss: 0.4707 - val_accuracy: 0.7857\n",
      "Epoch 361/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2584 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.7857\n",
      "Epoch 362/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2576 - accuracy: 0.9667 - val_loss: 0.4695 - val_accuracy: 0.7857\n",
      "Epoch 363/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2568 - accuracy: 0.9667 - val_loss: 0.4690 - val_accuracy: 0.7857\n",
      "Epoch 364/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2560 - accuracy: 0.9667 - val_loss: 0.4685 - val_accuracy: 0.7857\n",
      "Epoch 365/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2552 - accuracy: 0.9667 - val_loss: 0.4680 - val_accuracy: 0.7857\n",
      "Epoch 366/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2544 - accuracy: 0.9667 - val_loss: 0.4674 - val_accuracy: 0.7857\n",
      "Epoch 367/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2536 - accuracy: 0.9667 - val_loss: 0.4667 - val_accuracy: 0.7857\n",
      "Epoch 368/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2528 - accuracy: 0.9667 - val_loss: 0.4660 - val_accuracy: 0.7857\n",
      "Epoch 369/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2520 - accuracy: 0.9667 - val_loss: 0.4653 - val_accuracy: 0.7857\n",
      "Epoch 370/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2512 - accuracy: 0.9667 - val_loss: 0.4646 - val_accuracy: 0.7857\n",
      "Epoch 371/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2505 - accuracy: 0.9667 - val_loss: 0.4641 - val_accuracy: 0.7857\n",
      "Epoch 372/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2497 - accuracy: 0.9667 - val_loss: 0.4636 - val_accuracy: 0.7857\n",
      "Epoch 373/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2489 - accuracy: 0.9667 - val_loss: 0.4632 - val_accuracy: 0.7857\n",
      "Epoch 374/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2481 - accuracy: 0.9667 - val_loss: 0.4627 - val_accuracy: 0.7857\n",
      "Epoch 375/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2474 - accuracy: 0.9667 - val_loss: 0.4621 - val_accuracy: 0.7857\n",
      "Epoch 376/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2466 - accuracy: 0.9667 - val_loss: 0.4615 - val_accuracy: 0.7857\n",
      "Epoch 377/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2458 - accuracy: 0.9667 - val_loss: 0.4609 - val_accuracy: 0.7857\n",
      "Epoch 378/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2451 - accuracy: 0.9667 - val_loss: 0.4603 - val_accuracy: 0.7714\n",
      "Epoch 379/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2443 - accuracy: 0.9667 - val_loss: 0.4598 - val_accuracy: 0.7714\n",
      "Epoch 380/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2436 - accuracy: 0.9667 - val_loss: 0.4594 - val_accuracy: 0.7714\n",
      "Epoch 381/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2428 - accuracy: 0.9667 - val_loss: 0.4591 - val_accuracy: 0.7714\n",
      "Epoch 382/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2421 - accuracy: 0.9667 - val_loss: 0.4587 - val_accuracy: 0.7714\n",
      "Epoch 383/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2413 - accuracy: 0.9667 - val_loss: 0.4582 - val_accuracy: 0.7714\n",
      "Epoch 384/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2406 - accuracy: 0.9667 - val_loss: 0.4577 - val_accuracy: 0.7714\n",
      "Epoch 385/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2399 - accuracy: 0.9667 - val_loss: 0.4571 - val_accuracy: 0.7714\n",
      "Epoch 386/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2391 - accuracy: 0.9667 - val_loss: 0.4565 - val_accuracy: 0.7857\n",
      "Epoch 387/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2384 - accuracy: 0.9667 - val_loss: 0.4560 - val_accuracy: 0.7857\n",
      "Epoch 388/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2377 - accuracy: 0.9667 - val_loss: 0.4556 - val_accuracy: 0.7857\n",
      "Epoch 389/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2370 - accuracy: 0.9667 - val_loss: 0.4553 - val_accuracy: 0.7857\n",
      "Epoch 390/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2363 - accuracy: 0.9667 - val_loss: 0.4550 - val_accuracy: 0.7857\n",
      "Epoch 391/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2355 - accuracy: 0.9667 - val_loss: 0.4547 - val_accuracy: 0.7857\n",
      "Epoch 392/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2348 - accuracy: 0.9667 - val_loss: 0.4545 - val_accuracy: 0.7857\n",
      "Epoch 393/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2341 - accuracy: 0.9667 - val_loss: 0.4542 - val_accuracy: 0.8000\n",
      "Epoch 394/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2334 - accuracy: 0.9667 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 395/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2327 - accuracy: 0.9667 - val_loss: 0.4534 - val_accuracy: 0.8000\n",
      "Epoch 396/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2320 - accuracy: 0.9667 - val_loss: 0.4530 - val_accuracy: 0.8000\n",
      "Epoch 397/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2313 - accuracy: 0.9667 - val_loss: 0.4526 - val_accuracy: 0.8000\n",
      "Epoch 398/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2306 - accuracy: 0.9667 - val_loss: 0.4522 - val_accuracy: 0.8000\n",
      "Epoch 399/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2300 - accuracy: 0.9667 - val_loss: 0.4517 - val_accuracy: 0.8000\n",
      "Epoch 400/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2293 - accuracy: 0.9667 - val_loss: 0.4514 - val_accuracy: 0.8000\n",
      "Epoch 401/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2286 - accuracy: 0.9667 - val_loss: 0.4511 - val_accuracy: 0.8000\n",
      "Epoch 402/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2279 - accuracy: 0.9667 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 403/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2272 - accuracy: 0.9667 - val_loss: 0.4507 - val_accuracy: 0.8000\n",
      "Epoch 404/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2266 - accuracy: 0.9667 - val_loss: 0.4504 - val_accuracy: 0.8000\n",
      "Epoch 405/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2259 - accuracy: 0.9667 - val_loss: 0.4501 - val_accuracy: 0.8000\n",
      "Epoch 406/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2253 - accuracy: 0.9667 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 407/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2246 - accuracy: 0.9667 - val_loss: 0.4495 - val_accuracy: 0.8000\n",
      "Epoch 408/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2240 - accuracy: 0.9667 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 409/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2233 - accuracy: 0.9667 - val_loss: 0.4490 - val_accuracy: 0.8000\n",
      "Epoch 410/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2227 - accuracy: 0.9667 - val_loss: 0.4488 - val_accuracy: 0.8000\n",
      "Epoch 411/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2220 - accuracy: 0.9667 - val_loss: 0.4485 - val_accuracy: 0.8000\n",
      "Epoch 412/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2214 - accuracy: 0.9667 - val_loss: 0.4483 - val_accuracy: 0.8000\n",
      "Epoch 413/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2207 - accuracy: 0.9667 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
      "Epoch 414/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2201 - accuracy: 0.9667 - val_loss: 0.4479 - val_accuracy: 0.8000\n",
      "Epoch 415/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2195 - accuracy: 0.9667 - val_loss: 0.4476 - val_accuracy: 0.8000\n",
      "Epoch 416/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2188 - accuracy: 0.9667 - val_loss: 0.4474 - val_accuracy: 0.8000\n",
      "Epoch 417/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2182 - accuracy: 0.9667 - val_loss: 0.4472 - val_accuracy: 0.8000\n",
      "Epoch 418/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2176 - accuracy: 0.9667 - val_loss: 0.4471 - val_accuracy: 0.8000\n",
      "Epoch 419/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2170 - accuracy: 0.9667 - val_loss: 0.4469 - val_accuracy: 0.8000\n",
      "Epoch 420/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2164 - accuracy: 0.9667 - val_loss: 0.4468 - val_accuracy: 0.8000\n",
      "Epoch 421/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2157 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 422/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2151 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 423/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2145 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.7857\n",
      "Epoch 424/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2139 - accuracy: 0.9667 - val_loss: 0.4466 - val_accuracy: 0.7857\n",
      "Epoch 425/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2133 - accuracy: 0.9667 - val_loss: 0.4464 - val_accuracy: 0.7857\n",
      "Epoch 426/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2127 - accuracy: 0.9667 - val_loss: 0.4462 - val_accuracy: 0.7857\n",
      "Epoch 427/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2121 - accuracy: 0.9667 - val_loss: 0.4460 - val_accuracy: 0.7857\n",
      "Epoch 428/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2116 - accuracy: 0.9667 - val_loss: 0.4458 - val_accuracy: 0.7857\n",
      "Epoch 429/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2110 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.7857\n",
      "Epoch 430/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2104 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.7857\n",
      "Epoch 431/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2098 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.7857\n",
      "Epoch 432/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2092 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.7857\n",
      "Epoch 433/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2087 - accuracy: 0.9667 - val_loss: 0.4455 - val_accuracy: 0.7857\n",
      "Epoch 434/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2081 - accuracy: 0.9667 - val_loss: 0.4454 - val_accuracy: 0.7857\n",
      "Epoch 435/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2075 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 436/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2069 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 437/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2064 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 438/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2058 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 439/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2053 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 440/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2047 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 441/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2042 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 442/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2036 - accuracy: 0.9667 - val_loss: 0.4451 - val_accuracy: 0.7857\n",
      "Epoch 443/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2031 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 444/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2025 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 445/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2020 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 446/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2015 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 447/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2009 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 448/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2004 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 449/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1999 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 450/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1993 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 451/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1988 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 452/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1983 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 453/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1978 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 454/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1973 - accuracy: 0.9667 - val_loss: 0.4449 - val_accuracy: 0.7857\n",
      "Epoch 455/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1967 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 456/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1962 - accuracy: 0.9667 - val_loss: 0.4451 - val_accuracy: 0.7857\n",
      "Epoch 457/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1957 - accuracy: 0.9667 - val_loss: 0.4451 - val_accuracy: 0.7857\n",
      "Epoch 458/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1952 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 459/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1947 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 460/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1942 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 461/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1937 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 462/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1932 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 463/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1927 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.7857\n",
      "Epoch 464/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1922 - accuracy: 0.9667 - val_loss: 0.4451 - val_accuracy: 0.7857\n",
      "Epoch 465/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1917 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 466/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1913 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 467/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1908 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 468/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1903 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 469/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1898 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 470/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1893 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 471/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1888 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 472/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1884 - accuracy: 0.9667 - val_loss: 0.4452 - val_accuracy: 0.7857\n",
      "Epoch 473/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1879 - accuracy: 0.9667 - val_loss: 0.4453 - val_accuracy: 0.7857\n",
      "Epoch 474/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1874 - accuracy: 0.9667 - val_loss: 0.4454 - val_accuracy: 0.7857\n",
      "Epoch 475/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1870 - accuracy: 0.9667 - val_loss: 0.4455 - val_accuracy: 0.7857\n",
      "Epoch 476/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1865 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 477/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1860 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 478/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1856 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 479/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1851 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 480/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1847 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 481/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1842 - accuracy: 0.9667 - val_loss: 0.4456 - val_accuracy: 0.7857\n",
      "Epoch 482/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1838 - accuracy: 0.9667 - val_loss: 0.4457 - val_accuracy: 0.7857\n",
      "Epoch 483/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1833 - accuracy: 0.9667 - val_loss: 0.4458 - val_accuracy: 0.8000\n",
      "Epoch 484/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1829 - accuracy: 0.9667 - val_loss: 0.4459 - val_accuracy: 0.8000\n",
      "Epoch 485/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1824 - accuracy: 0.9667 - val_loss: 0.4460 - val_accuracy: 0.8000\n",
      "Epoch 486/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1820 - accuracy: 0.9667 - val_loss: 0.4461 - val_accuracy: 0.8000\n",
      "Epoch 487/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1815 - accuracy: 0.9667 - val_loss: 0.4462 - val_accuracy: 0.8000\n",
      "Epoch 488/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1811 - accuracy: 0.9667 - val_loss: 0.4463 - val_accuracy: 0.8000\n",
      "Epoch 489/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1807 - accuracy: 0.9667 - val_loss: 0.4464 - val_accuracy: 0.8000\n",
      "Epoch 490/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1802 - accuracy: 0.9667 - val_loss: 0.4465 - val_accuracy: 0.8000\n",
      "Epoch 491/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1798 - accuracy: 0.9667 - val_loss: 0.4466 - val_accuracy: 0.8000\n",
      "Epoch 492/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1794 - accuracy: 0.9667 - val_loss: 0.4466 - val_accuracy: 0.8000\n",
      "Epoch 493/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1790 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 494/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1785 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 495/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1781 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 496/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1777 - accuracy: 0.9667 - val_loss: 0.4467 - val_accuracy: 0.8000\n",
      "Epoch 497/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1773 - accuracy: 0.9667 - val_loss: 0.4468 - val_accuracy: 0.8000\n",
      "Epoch 498/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1768 - accuracy: 0.9667 - val_loss: 0.4470 - val_accuracy: 0.8000\n",
      "Epoch 499/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1764 - accuracy: 0.9667 - val_loss: 0.4471 - val_accuracy: 0.8000\n",
      "Epoch 500/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1760 - accuracy: 0.9667 - val_loss: 0.4473 - val_accuracy: 0.8000\n",
      "Epoch 501/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1756 - accuracy: 0.9667 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 502/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1752 - accuracy: 0.9667 - val_loss: 0.4476 - val_accuracy: 0.8000\n",
      "Epoch 503/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1748 - accuracy: 0.9667 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
      "Epoch 504/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1744 - accuracy: 0.9667 - val_loss: 0.4479 - val_accuracy: 0.8000\n",
      "Epoch 505/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1740 - accuracy: 0.9667 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
      "Epoch 506/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1736 - accuracy: 0.9667 - val_loss: 0.4482 - val_accuracy: 0.8000\n",
      "Epoch 507/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1732 - accuracy: 0.9667 - val_loss: 0.4481 - val_accuracy: 0.8000\n",
      "Epoch 508/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1728 - accuracy: 0.9667 - val_loss: 0.4480 - val_accuracy: 0.8000\n",
      "Epoch 509/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1724 - accuracy: 0.9667 - val_loss: 0.4480 - val_accuracy: 0.8000\n",
      "Epoch 510/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1720 - accuracy: 0.9667 - val_loss: 0.4480 - val_accuracy: 0.8000\n",
      "Epoch 511/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1716 - accuracy: 0.9667 - val_loss: 0.4482 - val_accuracy: 0.8000\n",
      "Epoch 512/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1712 - accuracy: 0.9667 - val_loss: 0.4485 - val_accuracy: 0.8000\n",
      "Epoch 513/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1708 - accuracy: 0.9667 - val_loss: 0.4487 - val_accuracy: 0.8000\n",
      "Epoch 514/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1704 - accuracy: 0.9667 - val_loss: 0.4490 - val_accuracy: 0.8000\n",
      "Epoch 515/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1700 - accuracy: 0.9667 - val_loss: 0.4491 - val_accuracy: 0.8000\n",
      "Epoch 516/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1696 - accuracy: 0.9667 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 517/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1693 - accuracy: 0.9667 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 518/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1689 - accuracy: 0.9667 - val_loss: 0.4494 - val_accuracy: 0.8000\n",
      "Epoch 519/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1685 - accuracy: 0.9667 - val_loss: 0.4495 - val_accuracy: 0.8000\n",
      "Epoch 520/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1681 - accuracy: 0.9667 - val_loss: 0.4496 - val_accuracy: 0.8000\n",
      "Epoch 521/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1677 - accuracy: 0.9667 - val_loss: 0.4497 - val_accuracy: 0.8000\n",
      "Epoch 522/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1674 - accuracy: 0.9667 - val_loss: 0.4497 - val_accuracy: 0.8000\n",
      "Epoch 523/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1670 - accuracy: 0.9667 - val_loss: 0.4497 - val_accuracy: 0.8000\n",
      "Epoch 524/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1666 - accuracy: 0.9667 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 525/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1663 - accuracy: 0.9667 - val_loss: 0.4500 - val_accuracy: 0.8000\n",
      "Epoch 526/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1659 - accuracy: 0.9667 - val_loss: 0.4502 - val_accuracy: 0.8000\n",
      "Epoch 527/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1655 - accuracy: 0.9667 - val_loss: 0.4506 - val_accuracy: 0.8000\n",
      "Epoch 528/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1652 - accuracy: 0.9667 - val_loss: 0.4508 - val_accuracy: 0.8000\n",
      "Epoch 529/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1648 - accuracy: 0.9667 - val_loss: 0.4510 - val_accuracy: 0.8143\n",
      "Epoch 530/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1644 - accuracy: 0.9667 - val_loss: 0.4511 - val_accuracy: 0.8143\n",
      "Epoch 531/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1641 - accuracy: 0.9667 - val_loss: 0.4511 - val_accuracy: 0.8143\n",
      "Epoch 532/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1637 - accuracy: 0.9667 - val_loss: 0.4512 - val_accuracy: 0.8000\n",
      "Epoch 533/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1634 - accuracy: 0.9667 - val_loss: 0.4512 - val_accuracy: 0.8000\n",
      "Epoch 534/4000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1630 - accuracy: 0.9667 - val_loss: 0.4514 - val_accuracy: 0.8000\n",
      "Epoch 535/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1626 - accuracy: 0.9667 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
      "Epoch 536/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1623 - accuracy: 0.9667 - val_loss: 0.4518 - val_accuracy: 0.8143\n",
      "Epoch 537/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1620 - accuracy: 0.9667 - val_loss: 0.4521 - val_accuracy: 0.8143\n",
      "Epoch 538/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1616 - accuracy: 0.9667 - val_loss: 0.4523 - val_accuracy: 0.8143\n",
      "Epoch 539/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1613 - accuracy: 0.9667 - val_loss: 0.4524 - val_accuracy: 0.8143\n",
      "Epoch 540/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1609 - accuracy: 0.9667 - val_loss: 0.4525 - val_accuracy: 0.8143\n",
      "Epoch 541/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1606 - accuracy: 0.9667 - val_loss: 0.4526 - val_accuracy: 0.8143\n",
      "Epoch 542/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1602 - accuracy: 0.9667 - val_loss: 0.4527 - val_accuracy: 0.8143\n",
      "Epoch 543/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1599 - accuracy: 0.9667 - val_loss: 0.4529 - val_accuracy: 0.8143\n",
      "Epoch 544/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1595 - accuracy: 0.9667 - val_loss: 0.4530 - val_accuracy: 0.8143\n",
      "Epoch 545/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1592 - accuracy: 0.9667 - val_loss: 0.4531 - val_accuracy: 0.8143\n",
      "Epoch 546/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1589 - accuracy: 0.9667 - val_loss: 0.4533 - val_accuracy: 0.8143\n",
      "Epoch 547/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1585 - accuracy: 0.9667 - val_loss: 0.4535 - val_accuracy: 0.8143\n",
      "Epoch 548/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1582 - accuracy: 0.9667 - val_loss: 0.4537 - val_accuracy: 0.8143\n",
      "Epoch 549/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1579 - accuracy: 0.9667 - val_loss: 0.4539 - val_accuracy: 0.8143\n",
      "Epoch 550/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1575 - accuracy: 0.9667 - val_loss: 0.4540 - val_accuracy: 0.8143\n",
      "Epoch 551/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1572 - accuracy: 0.9667 - val_loss: 0.4542 - val_accuracy: 0.8143\n",
      "Epoch 552/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1569 - accuracy: 0.9667 - val_loss: 0.4543 - val_accuracy: 0.8143\n",
      "Epoch 553/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1565 - accuracy: 0.9667 - val_loss: 0.4544 - val_accuracy: 0.8143\n",
      "Epoch 554/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1562 - accuracy: 0.9667 - val_loss: 0.4545 - val_accuracy: 0.8000\n",
      "Epoch 555/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1559 - accuracy: 0.9667 - val_loss: 0.4546 - val_accuracy: 0.8000\n",
      "Epoch 556/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1556 - accuracy: 0.9667 - val_loss: 0.4548 - val_accuracy: 0.8000\n",
      "Epoch 557/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1553 - accuracy: 0.9667 - val_loss: 0.4549 - val_accuracy: 0.8000\n",
      "Epoch 558/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1549 - accuracy: 0.9667 - val_loss: 0.4550 - val_accuracy: 0.8000\n",
      "Epoch 559/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1546 - accuracy: 0.9667 - val_loss: 0.4552 - val_accuracy: 0.8000\n",
      "Epoch 560/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1543 - accuracy: 0.9667 - val_loss: 0.4554 - val_accuracy: 0.8000\n",
      "Epoch 561/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1540 - accuracy: 0.9667 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
      "Epoch 562/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1537 - accuracy: 0.9667 - val_loss: 0.4559 - val_accuracy: 0.8000\n",
      "Epoch 563/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1534 - accuracy: 0.9667 - val_loss: 0.4561 - val_accuracy: 0.8000\n",
      "Epoch 564/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1530 - accuracy: 0.9667 - val_loss: 0.4563 - val_accuracy: 0.8000\n",
      "Epoch 565/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1527 - accuracy: 0.9667 - val_loss: 0.4565 - val_accuracy: 0.8000\n",
      "Epoch 566/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1524 - accuracy: 0.9667 - val_loss: 0.4566 - val_accuracy: 0.8000\n",
      "Epoch 567/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1521 - accuracy: 0.9667 - val_loss: 0.4567 - val_accuracy: 0.8000\n",
      "Epoch 568/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1518 - accuracy: 0.9667 - val_loss: 0.4567 - val_accuracy: 0.8000\n",
      "Epoch 569/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1515 - accuracy: 0.9667 - val_loss: 0.4568 - val_accuracy: 0.8000\n",
      "Epoch 570/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1512 - accuracy: 0.9667 - val_loss: 0.4570 - val_accuracy: 0.8000\n",
      "Epoch 571/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1509 - accuracy: 0.9667 - val_loss: 0.4571 - val_accuracy: 0.8000\n",
      "Epoch 572/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1506 - accuracy: 0.9667 - val_loss: 0.4573 - val_accuracy: 0.8000\n",
      "Epoch 573/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1503 - accuracy: 0.9667 - val_loss: 0.4575 - val_accuracy: 0.8000\n",
      "Epoch 574/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1500 - accuracy: 0.9667 - val_loss: 0.4578 - val_accuracy: 0.8000\n",
      "Epoch 575/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1497 - accuracy: 0.9667 - val_loss: 0.4580 - val_accuracy: 0.8000\n",
      "Epoch 576/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1494 - accuracy: 0.9667 - val_loss: 0.4582 - val_accuracy: 0.8000\n",
      "Epoch 577/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1491 - accuracy: 0.9667 - val_loss: 0.4585 - val_accuracy: 0.8143\n",
      "Epoch 578/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1488 - accuracy: 0.9667 - val_loss: 0.4587 - val_accuracy: 0.8143\n",
      "Epoch 579/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1485 - accuracy: 0.9667 - val_loss: 0.4588 - val_accuracy: 0.8143\n",
      "Epoch 580/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1482 - accuracy: 0.9667 - val_loss: 0.4589 - val_accuracy: 0.8143\n",
      "Epoch 581/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1479 - accuracy: 0.9667 - val_loss: 0.4590 - val_accuracy: 0.8143\n",
      "Epoch 582/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1477 - accuracy: 0.9667 - val_loss: 0.4591 - val_accuracy: 0.8143\n",
      "Epoch 583/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1474 - accuracy: 0.9667 - val_loss: 0.4592 - val_accuracy: 0.8143\n",
      "Epoch 584/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1471 - accuracy: 0.9667 - val_loss: 0.4593 - val_accuracy: 0.8143\n",
      "Epoch 585/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1468 - accuracy: 0.9667 - val_loss: 0.4595 - val_accuracy: 0.8143\n",
      "Epoch 586/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1465 - accuracy: 0.9667 - val_loss: 0.4597 - val_accuracy: 0.8143\n",
      "Epoch 587/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1462 - accuracy: 0.9667 - val_loss: 0.4600 - val_accuracy: 0.8143\n",
      "Epoch 588/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1459 - accuracy: 0.9667 - val_loss: 0.4603 - val_accuracy: 0.8143\n",
      "Epoch 589/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1457 - accuracy: 0.9667 - val_loss: 0.4606 - val_accuracy: 0.8143\n",
      "Epoch 590/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1454 - accuracy: 0.9667 - val_loss: 0.4608 - val_accuracy: 0.8143\n",
      "Epoch 591/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1451 - accuracy: 0.9667 - val_loss: 0.4609 - val_accuracy: 0.8143\n",
      "Epoch 592/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1448 - accuracy: 0.9667 - val_loss: 0.4610 - val_accuracy: 0.8143\n",
      "Epoch 593/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1445 - accuracy: 0.9667 - val_loss: 0.4611 - val_accuracy: 0.8143\n",
      "Epoch 594/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1443 - accuracy: 0.9667 - val_loss: 0.4612 - val_accuracy: 0.8143\n",
      "Epoch 595/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1440 - accuracy: 0.9667 - val_loss: 0.4612 - val_accuracy: 0.8143\n",
      "Epoch 596/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1437 - accuracy: 0.9667 - val_loss: 0.4614 - val_accuracy: 0.8143\n",
      "Epoch 597/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1435 - accuracy: 0.9667 - val_loss: 0.4616 - val_accuracy: 0.8143\n",
      "Epoch 598/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1432 - accuracy: 0.9667 - val_loss: 0.4617 - val_accuracy: 0.8143\n",
      "Epoch 599/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1429 - accuracy: 0.9667 - val_loss: 0.4620 - val_accuracy: 0.8143\n",
      "Epoch 600/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1426 - accuracy: 0.9667 - val_loss: 0.4622 - val_accuracy: 0.8143\n",
      "Epoch 601/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1424 - accuracy: 0.9667 - val_loss: 0.4624 - val_accuracy: 0.8143\n",
      "Epoch 602/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1421 - accuracy: 0.9667 - val_loss: 0.4627 - val_accuracy: 0.8143\n",
      "Epoch 603/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1419 - accuracy: 0.9667 - val_loss: 0.4629 - val_accuracy: 0.8143\n",
      "Epoch 604/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1416 - accuracy: 0.9667 - val_loss: 0.4631 - val_accuracy: 0.8143\n",
      "Epoch 605/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1413 - accuracy: 0.9667 - val_loss: 0.4632 - val_accuracy: 0.8143\n",
      "Epoch 606/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1411 - accuracy: 0.9667 - val_loss: 0.4633 - val_accuracy: 0.8143\n",
      "Epoch 607/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1408 - accuracy: 0.9667 - val_loss: 0.4633 - val_accuracy: 0.8143\n",
      "Epoch 608/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1405 - accuracy: 0.9667 - val_loss: 0.4634 - val_accuracy: 0.8143\n",
      "Epoch 609/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1403 - accuracy: 0.9667 - val_loss: 0.4635 - val_accuracy: 0.8143\n",
      "Epoch 610/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1400 - accuracy: 0.9667 - val_loss: 0.4638 - val_accuracy: 0.8143\n",
      "Epoch 611/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1398 - accuracy: 0.9667 - val_loss: 0.4642 - val_accuracy: 0.8143\n",
      "Epoch 612/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1395 - accuracy: 0.9667 - val_loss: 0.4644 - val_accuracy: 0.8143\n",
      "Epoch 613/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1393 - accuracy: 0.9667 - val_loss: 0.4646 - val_accuracy: 0.8143\n",
      "Epoch 614/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1390 - accuracy: 0.9667 - val_loss: 0.4646 - val_accuracy: 0.8143\n",
      "Epoch 615/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1387 - accuracy: 0.9667 - val_loss: 0.4646 - val_accuracy: 0.8143\n",
      "Epoch 616/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1385 - accuracy: 0.9667 - val_loss: 0.4647 - val_accuracy: 0.8143\n",
      "Epoch 617/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1382 - accuracy: 0.9667 - val_loss: 0.4649 - val_accuracy: 0.8143\n",
      "Epoch 618/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1380 - accuracy: 0.9667 - val_loss: 0.4652 - val_accuracy: 0.8143\n",
      "Epoch 619/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1377 - accuracy: 0.9667 - val_loss: 0.4654 - val_accuracy: 0.8143\n",
      "Epoch 620/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1375 - accuracy: 0.9667 - val_loss: 0.4657 - val_accuracy: 0.8143\n",
      "Epoch 621/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1372 - accuracy: 0.9667 - val_loss: 0.4660 - val_accuracy: 0.8143\n",
      "Epoch 622/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1370 - accuracy: 0.9667 - val_loss: 0.4662 - val_accuracy: 0.8143\n",
      "Epoch 623/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1367 - accuracy: 0.9667 - val_loss: 0.4663 - val_accuracy: 0.8143\n",
      "Epoch 624/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1365 - accuracy: 0.9667 - val_loss: 0.4664 - val_accuracy: 0.8143\n",
      "Epoch 625/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1362 - accuracy: 0.9667 - val_loss: 0.4664 - val_accuracy: 0.8143\n",
      "Epoch 626/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1360 - accuracy: 0.9667 - val_loss: 0.4665 - val_accuracy: 0.8143\n",
      "Epoch 627/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1358 - accuracy: 0.9667 - val_loss: 0.4666 - val_accuracy: 0.8143\n",
      "Epoch 628/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1355 - accuracy: 0.9667 - val_loss: 0.4668 - val_accuracy: 0.8143\n",
      "Epoch 629/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.4670 - val_accuracy: 0.8143\n",
      "Epoch 630/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1351 - accuracy: 0.9667 - val_loss: 0.4673 - val_accuracy: 0.8143\n",
      "Epoch 631/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1348 - accuracy: 0.9667 - val_loss: 0.4675 - val_accuracy: 0.8286\n",
      "Epoch 632/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1346 - accuracy: 0.9667 - val_loss: 0.4678 - val_accuracy: 0.8286\n",
      "Epoch 633/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1343 - accuracy: 0.9667 - val_loss: 0.4680 - val_accuracy: 0.8286\n",
      "Epoch 634/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1341 - accuracy: 0.9667 - val_loss: 0.4682 - val_accuracy: 0.8286\n",
      "Epoch 635/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1339 - accuracy: 0.9667 - val_loss: 0.4683 - val_accuracy: 0.8286\n",
      "Epoch 636/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1336 - accuracy: 0.9667 - val_loss: 0.4683 - val_accuracy: 0.8286\n",
      "Epoch 637/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1334 - accuracy: 0.9667 - val_loss: 0.4684 - val_accuracy: 0.8286\n",
      "Epoch 638/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1332 - accuracy: 0.9667 - val_loss: 0.4684 - val_accuracy: 0.8286\n",
      "Epoch 639/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1329 - accuracy: 0.9667 - val_loss: 0.4686 - val_accuracy: 0.8286\n",
      "Epoch 640/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1327 - accuracy: 0.9667 - val_loss: 0.4687 - val_accuracy: 0.8286\n",
      "Epoch 641/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1325 - accuracy: 0.9667 - val_loss: 0.4689 - val_accuracy: 0.8286\n",
      "Epoch 642/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1322 - accuracy: 0.9667 - val_loss: 0.4692 - val_accuracy: 0.8286\n",
      "Epoch 643/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1320 - accuracy: 0.9667 - val_loss: 0.4694 - val_accuracy: 0.8286\n",
      "Epoch 644/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1318 - accuracy: 0.9667 - val_loss: 0.4696 - val_accuracy: 0.8286\n",
      "Epoch 645/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1316 - accuracy: 0.9667 - val_loss: 0.4698 - val_accuracy: 0.8286\n",
      "Epoch 646/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1313 - accuracy: 0.9667 - val_loss: 0.4699 - val_accuracy: 0.8286\n",
      "Epoch 647/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1311 - accuracy: 0.9667 - val_loss: 0.4700 - val_accuracy: 0.8286\n",
      "Epoch 648/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1309 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.8286\n",
      "Epoch 649/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1307 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.8286\n",
      "Epoch 650/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1304 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.8286\n",
      "Epoch 651/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1302 - accuracy: 0.9667 - val_loss: 0.4701 - val_accuracy: 0.8286\n",
      "Epoch 652/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1300 - accuracy: 0.9667 - val_loss: 0.4703 - val_accuracy: 0.8286\n",
      "Epoch 653/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1298 - accuracy: 0.9667 - val_loss: 0.4705 - val_accuracy: 0.8286\n",
      "Epoch 654/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1296 - accuracy: 0.9667 - val_loss: 0.4707 - val_accuracy: 0.8286\n",
      "Epoch 655/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1293 - accuracy: 0.9667 - val_loss: 0.4710 - val_accuracy: 0.8286\n",
      "Epoch 656/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1291 - accuracy: 0.9667 - val_loss: 0.4712 - val_accuracy: 0.8286\n",
      "Epoch 657/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1289 - accuracy: 0.9667 - val_loss: 0.4714 - val_accuracy: 0.8286\n",
      "Epoch 658/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1287 - accuracy: 0.9667 - val_loss: 0.4715 - val_accuracy: 0.8286\n",
      "Epoch 659/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1285 - accuracy: 0.9667 - val_loss: 0.4715 - val_accuracy: 0.8286\n",
      "Epoch 660/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.4715 - val_accuracy: 0.8286\n",
      "Epoch 661/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1280 - accuracy: 0.9667 - val_loss: 0.4715 - val_accuracy: 0.8286\n",
      "Epoch 662/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1278 - accuracy: 0.9667 - val_loss: 0.4715 - val_accuracy: 0.8286\n",
      "Epoch 663/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1276 - accuracy: 0.9667 - val_loss: 0.4717 - val_accuracy: 0.8143\n",
      "Epoch 664/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1274 - accuracy: 0.9667 - val_loss: 0.4719 - val_accuracy: 0.8143\n",
      "Epoch 665/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1272 - accuracy: 0.9667 - val_loss: 0.4721 - val_accuracy: 0.8143\n",
      "Epoch 666/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1270 - accuracy: 0.9667 - val_loss: 0.4724 - val_accuracy: 0.8143\n",
      "Epoch 667/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1268 - accuracy: 0.9667 - val_loss: 0.4726 - val_accuracy: 0.8143\n",
      "Epoch 668/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1266 - accuracy: 0.9667 - val_loss: 0.4727 - val_accuracy: 0.8143\n",
      "Epoch 669/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1264 - accuracy: 0.9667 - val_loss: 0.4727 - val_accuracy: 0.8143\n",
      "Epoch 670/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1261 - accuracy: 0.9667 - val_loss: 0.4728 - val_accuracy: 0.8143\n",
      "Epoch 671/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1259 - accuracy: 0.9667 - val_loss: 0.4729 - val_accuracy: 0.8143\n",
      "Epoch 672/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1257 - accuracy: 0.9667 - val_loss: 0.4731 - val_accuracy: 0.8143\n",
      "Epoch 673/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1255 - accuracy: 0.9667 - val_loss: 0.4732 - val_accuracy: 0.8143\n",
      "Epoch 674/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1253 - accuracy: 0.9667 - val_loss: 0.4732 - val_accuracy: 0.8143\n",
      "Epoch 675/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.4732 - val_accuracy: 0.8143\n",
      "Epoch 676/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1249 - accuracy: 0.9667 - val_loss: 0.4733 - val_accuracy: 0.8143\n",
      "Epoch 677/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1247 - accuracy: 0.9667 - val_loss: 0.4733 - val_accuracy: 0.8143\n",
      "Epoch 678/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1245 - accuracy: 0.9667 - val_loss: 0.4736 - val_accuracy: 0.8143\n",
      "Epoch 679/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1243 - accuracy: 0.9667 - val_loss: 0.4738 - val_accuracy: 0.8143\n",
      "Epoch 680/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1241 - accuracy: 0.9667 - val_loss: 0.4741 - val_accuracy: 0.8143\n",
      "Epoch 681/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.4742 - val_accuracy: 0.8143\n",
      "Epoch 682/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1237 - accuracy: 0.9667 - val_loss: 0.4743 - val_accuracy: 0.8143\n",
      "Epoch 683/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1235 - accuracy: 0.9667 - val_loss: 0.4743 - val_accuracy: 0.8143\n",
      "Epoch 684/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1233 - accuracy: 0.9667 - val_loss: 0.4743 - val_accuracy: 0.8143\n",
      "Epoch 685/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1231 - accuracy: 0.9667 - val_loss: 0.4744 - val_accuracy: 0.8143\n",
      "Epoch 686/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1229 - accuracy: 0.9667 - val_loss: 0.4746 - val_accuracy: 0.8143\n",
      "Epoch 687/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1227 - accuracy: 0.9667 - val_loss: 0.4748 - val_accuracy: 0.8143\n",
      "Epoch 688/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1225 - accuracy: 0.9667 - val_loss: 0.4751 - val_accuracy: 0.8143\n",
      "Epoch 689/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1223 - accuracy: 0.9667 - val_loss: 0.4753 - val_accuracy: 0.8143\n",
      "Epoch 690/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1221 - accuracy: 0.9667 - val_loss: 0.4755 - val_accuracy: 0.8143\n",
      "Epoch 691/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.4756 - val_accuracy: 0.8143\n",
      "Epoch 692/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1217 - accuracy: 0.9667 - val_loss: 0.4757 - val_accuracy: 0.8143\n",
      "Epoch 693/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1216 - accuracy: 0.9667 - val_loss: 0.4757 - val_accuracy: 0.8143\n",
      "Epoch 694/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1214 - accuracy: 0.9667 - val_loss: 0.4757 - val_accuracy: 0.8143\n",
      "Epoch 695/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1212 - accuracy: 0.9667 - val_loss: 0.4757 - val_accuracy: 0.8143\n",
      "Epoch 696/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1210 - accuracy: 0.9667 - val_loss: 0.4759 - val_accuracy: 0.8143\n",
      "Epoch 697/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1208 - accuracy: 0.9667 - val_loss: 0.4762 - val_accuracy: 0.8143\n",
      "Epoch 698/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1206 - accuracy: 0.9667 - val_loss: 0.4765 - val_accuracy: 0.8143\n",
      "Epoch 699/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1204 - accuracy: 0.9667 - val_loss: 0.4767 - val_accuracy: 0.8143\n",
      "Epoch 700/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1202 - accuracy: 0.9667 - val_loss: 0.4769 - val_accuracy: 0.8143\n",
      "Epoch 701/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1200 - accuracy: 0.9667 - val_loss: 0.4771 - val_accuracy: 0.8143\n",
      "Epoch 702/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.4772 - val_accuracy: 0.8143\n",
      "Epoch 703/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1197 - accuracy: 0.9667 - val_loss: 0.4773 - val_accuracy: 0.8143\n",
      "Epoch 704/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.4775 - val_accuracy: 0.8143\n",
      "Epoch 705/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1193 - accuracy: 0.9667 - val_loss: 0.4777 - val_accuracy: 0.8143\n",
      "Epoch 706/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.4778 - val_accuracy: 0.8143\n",
      "Epoch 707/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.4780 - val_accuracy: 0.8143\n",
      "Epoch 708/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1187 - accuracy: 0.9667 - val_loss: 0.4781 - val_accuracy: 0.8143\n",
      "Epoch 709/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1186 - accuracy: 0.9667 - val_loss: 0.4782 - val_accuracy: 0.8143\n",
      "Epoch 710/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1184 - accuracy: 0.9667 - val_loss: 0.4784 - val_accuracy: 0.8143\n",
      "Epoch 711/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1182 - accuracy: 0.9667 - val_loss: 0.4787 - val_accuracy: 0.8143\n",
      "Epoch 712/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1180 - accuracy: 0.9667 - val_loss: 0.4790 - val_accuracy: 0.8143\n",
      "Epoch 713/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1179 - accuracy: 0.9667 - val_loss: 0.4793 - val_accuracy: 0.8143\n",
      "Epoch 714/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1177 - accuracy: 0.9667 - val_loss: 0.4795 - val_accuracy: 0.8143\n",
      "Epoch 715/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.4798 - val_accuracy: 0.8143\n",
      "Epoch 716/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1173 - accuracy: 0.9667 - val_loss: 0.4800 - val_accuracy: 0.8143\n",
      "Epoch 717/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1171 - accuracy: 0.9667 - val_loss: 0.4802 - val_accuracy: 0.8143\n",
      "Epoch 718/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1170 - accuracy: 0.9667 - val_loss: 0.4803 - val_accuracy: 0.8143\n",
      "Epoch 719/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1168 - accuracy: 0.9667 - val_loss: 0.4805 - val_accuracy: 0.8143\n",
      "Epoch 720/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1166 - accuracy: 0.9667 - val_loss: 0.4807 - val_accuracy: 0.8143\n",
      "Epoch 721/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1164 - accuracy: 0.9667 - val_loss: 0.4808 - val_accuracy: 0.8143\n",
      "Epoch 722/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.4810 - val_accuracy: 0.8143\n",
      "Epoch 723/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1161 - accuracy: 0.9667 - val_loss: 0.4812 - val_accuracy: 0.8143\n",
      "Epoch 724/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1159 - accuracy: 0.9667 - val_loss: 0.4815 - val_accuracy: 0.8143\n",
      "Epoch 725/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.4818 - val_accuracy: 0.8143\n",
      "Epoch 726/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1156 - accuracy: 0.9667 - val_loss: 0.4820 - val_accuracy: 0.8143\n",
      "Epoch 727/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1154 - accuracy: 0.9667 - val_loss: 0.4821 - val_accuracy: 0.8143\n",
      "Epoch 728/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1152 - accuracy: 0.9667 - val_loss: 0.4823 - val_accuracy: 0.8143\n",
      "Epoch 729/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.4825 - val_accuracy: 0.8143\n",
      "Epoch 730/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1149 - accuracy: 0.9667 - val_loss: 0.4828 - val_accuracy: 0.8143\n",
      "Epoch 731/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.4831 - val_accuracy: 0.8143\n",
      "Epoch 732/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1145 - accuracy: 0.9667 - val_loss: 0.4834 - val_accuracy: 0.8143\n",
      "Epoch 733/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.4836 - val_accuracy: 0.8143\n",
      "Epoch 734/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1142 - accuracy: 0.9667 - val_loss: 0.4839 - val_accuracy: 0.8143\n",
      "Epoch 735/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1140 - accuracy: 0.9667 - val_loss: 0.4841 - val_accuracy: 0.8143\n",
      "Epoch 736/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1139 - accuracy: 0.9667 - val_loss: 0.4843 - val_accuracy: 0.8143\n",
      "Epoch 737/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1137 - accuracy: 0.9667 - val_loss: 0.4845 - val_accuracy: 0.8143\n",
      "Epoch 738/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1135 - accuracy: 0.9667 - val_loss: 0.4847 - val_accuracy: 0.8143\n",
      "Epoch 739/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.4850 - val_accuracy: 0.8143\n",
      "Epoch 740/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.4852 - val_accuracy: 0.8143\n",
      "Epoch 741/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.4854 - val_accuracy: 0.8143\n",
      "Epoch 742/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1129 - accuracy: 0.9667 - val_loss: 0.4856 - val_accuracy: 0.8143\n",
      "Epoch 743/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1127 - accuracy: 0.9667 - val_loss: 0.4857 - val_accuracy: 0.8143\n",
      "Epoch 744/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.4859 - val_accuracy: 0.8143\n",
      "Epoch 745/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.4861 - val_accuracy: 0.8143\n",
      "Epoch 746/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.4863 - val_accuracy: 0.8143\n",
      "Epoch 747/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.4866 - val_accuracy: 0.8143\n",
      "Epoch 748/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.4869 - val_accuracy: 0.8143\n",
      "Epoch 749/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.4873 - val_accuracy: 0.8143\n",
      "Epoch 750/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.4876 - val_accuracy: 0.8143\n",
      "Epoch 751/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1114 - accuracy: 0.9667 - val_loss: 0.4879 - val_accuracy: 0.8143\n",
      "Epoch 752/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.4881 - val_accuracy: 0.8143\n",
      "Epoch 753/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.4882 - val_accuracy: 0.8143\n",
      "Epoch 754/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1109 - accuracy: 0.9667 - val_loss: 0.4883 - val_accuracy: 0.8143\n",
      "Epoch 755/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.4884 - val_accuracy: 0.8286\n",
      "Epoch 756/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1106 - accuracy: 0.9667 - val_loss: 0.4886 - val_accuracy: 0.8286\n",
      "Epoch 757/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1105 - accuracy: 0.9667 - val_loss: 0.4889 - val_accuracy: 0.8286\n",
      "Epoch 758/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1103 - accuracy: 0.9667 - val_loss: 0.4894 - val_accuracy: 0.8286\n",
      "Epoch 759/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1102 - accuracy: 0.9667 - val_loss: 0.4897 - val_accuracy: 0.8286\n",
      "Epoch 760/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1100 - accuracy: 0.9667 - val_loss: 0.4900 - val_accuracy: 0.8286\n",
      "Epoch 761/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1099 - accuracy: 0.9667 - val_loss: 0.4903 - val_accuracy: 0.8286\n",
      "Epoch 762/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1097 - accuracy: 0.9667 - val_loss: 0.4907 - val_accuracy: 0.8286\n",
      "Epoch 763/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.4910 - val_accuracy: 0.8286\n",
      "Epoch 764/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1094 - accuracy: 0.9667 - val_loss: 0.4913 - val_accuracy: 0.8286\n",
      "Epoch 765/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1092 - accuracy: 0.9667 - val_loss: 0.4914 - val_accuracy: 0.8286\n",
      "Epoch 766/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1091 - accuracy: 0.9667 - val_loss: 0.4916 - val_accuracy: 0.8286\n",
      "Epoch 767/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1089 - accuracy: 0.9667 - val_loss: 0.4918 - val_accuracy: 0.8286\n",
      "Epoch 768/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.4921 - val_accuracy: 0.8286\n",
      "Epoch 769/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1086 - accuracy: 0.9667 - val_loss: 0.4924 - val_accuracy: 0.8286\n",
      "Epoch 770/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1085 - accuracy: 0.9667 - val_loss: 0.4928 - val_accuracy: 0.8286\n",
      "Epoch 771/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1083 - accuracy: 0.9667 - val_loss: 0.4933 - val_accuracy: 0.8286\n",
      "Epoch 772/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 0.4937 - val_accuracy: 0.8286\n",
      "Epoch 773/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.4940 - val_accuracy: 0.8286\n",
      "Epoch 774/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1079 - accuracy: 0.9667 - val_loss: 0.4942 - val_accuracy: 0.8286\n",
      "Epoch 775/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1078 - accuracy: 0.9667 - val_loss: 0.4944 - val_accuracy: 0.8286\n",
      "Epoch 776/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.4946 - val_accuracy: 0.8286\n",
      "Epoch 777/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1075 - accuracy: 0.9667 - val_loss: 0.4949 - val_accuracy: 0.8286\n",
      "Epoch 778/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1073 - accuracy: 0.9667 - val_loss: 0.4952 - val_accuracy: 0.8286\n",
      "Epoch 779/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.4955 - val_accuracy: 0.8286\n",
      "Epoch 780/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.4959 - val_accuracy: 0.8286\n",
      "Epoch 781/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1069 - accuracy: 0.9667 - val_loss: 0.4962 - val_accuracy: 0.8286\n",
      "Epoch 782/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1067 - accuracy: 0.9667 - val_loss: 0.4966 - val_accuracy: 0.8286\n",
      "Epoch 783/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1066 - accuracy: 0.9667 - val_loss: 0.4970 - val_accuracy: 0.8286\n",
      "Epoch 784/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1064 - accuracy: 0.9667 - val_loss: 0.4973 - val_accuracy: 0.8286\n",
      "Epoch 785/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1063 - accuracy: 0.9667 - val_loss: 0.4976 - val_accuracy: 0.8286\n",
      "Epoch 786/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.4979 - val_accuracy: 0.8286\n",
      "Epoch 787/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1060 - accuracy: 0.9667 - val_loss: 0.4983 - val_accuracy: 0.8286\n",
      "Epoch 788/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 0.4985 - val_accuracy: 0.8286\n",
      "Epoch 789/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1057 - accuracy: 0.9667 - val_loss: 0.4987 - val_accuracy: 0.8286\n",
      "Epoch 790/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1056 - accuracy: 0.9667 - val_loss: 0.4990 - val_accuracy: 0.8286\n",
      "Epoch 791/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1054 - accuracy: 0.9667 - val_loss: 0.4993 - val_accuracy: 0.8286\n",
      "Epoch 792/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1053 - accuracy: 0.9667 - val_loss: 0.4996 - val_accuracy: 0.8286\n",
      "Epoch 793/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1052 - accuracy: 0.9667 - val_loss: 0.4999 - val_accuracy: 0.8286\n",
      "Epoch 794/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 0.5003 - val_accuracy: 0.8286\n",
      "Epoch 795/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1049 - accuracy: 0.9667 - val_loss: 0.5008 - val_accuracy: 0.8286\n",
      "Epoch 796/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1048 - accuracy: 0.9667 - val_loss: 0.5011 - val_accuracy: 0.8286\n",
      "Epoch 797/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1046 - accuracy: 0.9667 - val_loss: 0.5014 - val_accuracy: 0.8286\n",
      "Epoch 798/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1045 - accuracy: 0.9667 - val_loss: 0.5016 - val_accuracy: 0.8286\n",
      "Epoch 799/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.5019 - val_accuracy: 0.8286\n",
      "Epoch 800/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1042 - accuracy: 0.9667 - val_loss: 0.5021 - val_accuracy: 0.8286\n",
      "Epoch 801/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1041 - accuracy: 0.9667 - val_loss: 0.5024 - val_accuracy: 0.8286\n",
      "Epoch 802/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1039 - accuracy: 0.9667 - val_loss: 0.5027 - val_accuracy: 0.8286\n",
      "Epoch 803/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1038 - accuracy: 0.9667 - val_loss: 0.5031 - val_accuracy: 0.8286\n",
      "Epoch 804/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1036 - accuracy: 0.9667 - val_loss: 0.5036 - val_accuracy: 0.8286\n",
      "Epoch 805/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.5041 - val_accuracy: 0.8286\n",
      "Epoch 806/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1034 - accuracy: 0.9667 - val_loss: 0.5045 - val_accuracy: 0.8286\n",
      "Epoch 807/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.5048 - val_accuracy: 0.8286\n",
      "Epoch 808/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1031 - accuracy: 0.9667 - val_loss: 0.5050 - val_accuracy: 0.8286\n",
      "Epoch 809/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.5052 - val_accuracy: 0.8286\n",
      "Epoch 810/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1028 - accuracy: 0.9667 - val_loss: 0.5054 - val_accuracy: 0.8286\n",
      "Epoch 811/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1027 - accuracy: 0.9667 - val_loss: 0.5057 - val_accuracy: 0.8286\n",
      "Epoch 812/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1025 - accuracy: 0.9667 - val_loss: 0.5061 - val_accuracy: 0.8286\n",
      "Epoch 813/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1024 - accuracy: 0.9667 - val_loss: 0.5064 - val_accuracy: 0.8286\n",
      "Epoch 814/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1023 - accuracy: 0.9667 - val_loss: 0.5067 - val_accuracy: 0.8286\n",
      "Epoch 815/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1021 - accuracy: 0.9667 - val_loss: 0.5070 - val_accuracy: 0.8286\n",
      "Epoch 816/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1020 - accuracy: 0.9667 - val_loss: 0.5074 - val_accuracy: 0.8286\n",
      "Epoch 817/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.5078 - val_accuracy: 0.8286\n",
      "Epoch 818/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 0.5082 - val_accuracy: 0.8286\n",
      "Epoch 819/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.5085 - val_accuracy: 0.8286\n",
      "Epoch 820/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1015 - accuracy: 0.9667 - val_loss: 0.5088 - val_accuracy: 0.8286\n",
      "Epoch 821/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1014 - accuracy: 0.9667 - val_loss: 0.5092 - val_accuracy: 0.8286\n",
      "Epoch 822/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.5096 - val_accuracy: 0.8286\n",
      "Epoch 823/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 0.5099 - val_accuracy: 0.8286\n",
      "Epoch 824/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1010 - accuracy: 0.9667 - val_loss: 0.5102 - val_accuracy: 0.8286\n",
      "Epoch 825/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1008 - accuracy: 0.9667 - val_loss: 0.5105 - val_accuracy: 0.8286\n",
      "Epoch 826/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1007 - accuracy: 0.9667 - val_loss: 0.5108 - val_accuracy: 0.8286\n",
      "Epoch 827/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1006 - accuracy: 0.9667 - val_loss: 0.5111 - val_accuracy: 0.8286\n",
      "Epoch 828/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1004 - accuracy: 0.9667 - val_loss: 0.5116 - val_accuracy: 0.8286\n",
      "Epoch 829/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1003 - accuracy: 0.9667 - val_loss: 0.5120 - val_accuracy: 0.8286\n",
      "Epoch 830/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1002 - accuracy: 0.9667 - val_loss: 0.5122 - val_accuracy: 0.8286\n",
      "Epoch 831/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1000 - accuracy: 0.9667 - val_loss: 0.5125 - val_accuracy: 0.8286\n",
      "Epoch 832/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0999 - accuracy: 0.9667 - val_loss: 0.5129 - val_accuracy: 0.8286\n",
      "Epoch 833/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0998 - accuracy: 0.9667 - val_loss: 0.5132 - val_accuracy: 0.8286\n",
      "Epoch 834/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0997 - accuracy: 0.9667 - val_loss: 0.5135 - val_accuracy: 0.8286\n",
      "Epoch 835/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0995 - accuracy: 0.9667 - val_loss: 0.5139 - val_accuracy: 0.8286\n",
      "Epoch 836/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 0.5143 - val_accuracy: 0.8286\n",
      "Epoch 837/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0993 - accuracy: 0.9667 - val_loss: 0.5146 - val_accuracy: 0.8286\n",
      "Epoch 838/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.5150 - val_accuracy: 0.8286\n",
      "Epoch 839/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0990 - accuracy: 0.9667 - val_loss: 0.5153 - val_accuracy: 0.8286\n",
      "Epoch 840/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0989 - accuracy: 0.9667 - val_loss: 0.5156 - val_accuracy: 0.8286\n",
      "Epoch 841/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0988 - accuracy: 0.9667 - val_loss: 0.5158 - val_accuracy: 0.8286\n",
      "Epoch 842/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0986 - accuracy: 0.9667 - val_loss: 0.5160 - val_accuracy: 0.8286\n",
      "Epoch 843/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0985 - accuracy: 0.9667 - val_loss: 0.5163 - val_accuracy: 0.8286\n",
      "Epoch 844/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0984 - accuracy: 0.9667 - val_loss: 0.5166 - val_accuracy: 0.8286\n",
      "Epoch 845/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0983 - accuracy: 0.9667 - val_loss: 0.5170 - val_accuracy: 0.8286\n",
      "Epoch 846/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0982 - accuracy: 0.9667 - val_loss: 0.5175 - val_accuracy: 0.8286\n",
      "Epoch 847/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0980 - accuracy: 0.9667 - val_loss: 0.5180 - val_accuracy: 0.8286\n",
      "Epoch 848/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0979 - accuracy: 0.9667 - val_loss: 0.5184 - val_accuracy: 0.8286\n",
      "Epoch 849/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0978 - accuracy: 0.9667 - val_loss: 0.5188 - val_accuracy: 0.8286\n",
      "Epoch 850/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0977 - accuracy: 0.9667 - val_loss: 0.5191 - val_accuracy: 0.8286\n",
      "Epoch 851/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0975 - accuracy: 0.9667 - val_loss: 0.5193 - val_accuracy: 0.8286\n",
      "Epoch 852/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0974 - accuracy: 0.9667 - val_loss: 0.5196 - val_accuracy: 0.8286\n",
      "Epoch 853/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0973 - accuracy: 0.9667 - val_loss: 0.5199 - val_accuracy: 0.8286\n",
      "Epoch 854/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.5202 - val_accuracy: 0.8286\n",
      "Epoch 855/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0970 - accuracy: 0.9667 - val_loss: 0.5205 - val_accuracy: 0.8286\n",
      "Epoch 856/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0969 - accuracy: 0.9667 - val_loss: 0.5209 - val_accuracy: 0.8286\n",
      "Epoch 857/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0968 - accuracy: 0.9667 - val_loss: 0.5214 - val_accuracy: 0.8286\n",
      "Epoch 858/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 0.5218 - val_accuracy: 0.8286\n",
      "Epoch 859/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0965 - accuracy: 0.9667 - val_loss: 0.5221 - val_accuracy: 0.8286\n",
      "Epoch 860/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0964 - accuracy: 0.9667 - val_loss: 0.5223 - val_accuracy: 0.8286\n",
      "Epoch 861/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0963 - accuracy: 0.9667 - val_loss: 0.5225 - val_accuracy: 0.8286\n",
      "Epoch 862/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.5228 - val_accuracy: 0.8286\n",
      "Epoch 863/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.5231 - val_accuracy: 0.8286\n",
      "Epoch 864/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0960 - accuracy: 0.9667 - val_loss: 0.5236 - val_accuracy: 0.8286\n",
      "Epoch 865/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.5240 - val_accuracy: 0.8286\n",
      "Epoch 866/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0957 - accuracy: 0.9667 - val_loss: 0.5245 - val_accuracy: 0.8286\n",
      "Epoch 867/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0956 - accuracy: 0.9667 - val_loss: 0.5249 - val_accuracy: 0.8286\n",
      "Epoch 868/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0955 - accuracy: 0.9667 - val_loss: 0.5253 - val_accuracy: 0.8286\n",
      "Epoch 869/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0954 - accuracy: 0.9667 - val_loss: 0.5254 - val_accuracy: 0.8286\n",
      "Epoch 870/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.5256 - val_accuracy: 0.8286\n",
      "Epoch 871/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.5258 - val_accuracy: 0.8286\n",
      "Epoch 872/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.5261 - val_accuracy: 0.8286\n",
      "Epoch 873/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0949 - accuracy: 0.9667 - val_loss: 0.5264 - val_accuracy: 0.8286\n",
      "Epoch 874/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0948 - accuracy: 0.9667 - val_loss: 0.5269 - val_accuracy: 0.8286\n",
      "Epoch 875/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.5273 - val_accuracy: 0.8286\n",
      "Epoch 876/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.5277 - val_accuracy: 0.8286\n",
      "Epoch 877/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0944 - accuracy: 0.9667 - val_loss: 0.5281 - val_accuracy: 0.8286\n",
      "Epoch 878/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0943 - accuracy: 0.9667 - val_loss: 0.5285 - val_accuracy: 0.8286\n",
      "Epoch 879/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0942 - accuracy: 0.9667 - val_loss: 0.5288 - val_accuracy: 0.8286\n",
      "Epoch 880/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.5291 - val_accuracy: 0.8286\n",
      "Epoch 881/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0940 - accuracy: 0.9667 - val_loss: 0.5294 - val_accuracy: 0.8286\n",
      "Epoch 882/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.5297 - val_accuracy: 0.8286\n",
      "Epoch 883/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0937 - accuracy: 0.9667 - val_loss: 0.5300 - val_accuracy: 0.8286\n",
      "Epoch 884/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0936 - accuracy: 0.9667 - val_loss: 0.5303 - val_accuracy: 0.8286\n",
      "Epoch 885/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0935 - accuracy: 0.9667 - val_loss: 0.5306 - val_accuracy: 0.8286\n",
      "Epoch 886/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.5308 - val_accuracy: 0.8286\n",
      "Epoch 887/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0932 - accuracy: 0.9667 - val_loss: 0.5309 - val_accuracy: 0.8286\n",
      "Epoch 888/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.5312 - val_accuracy: 0.8286\n",
      "Epoch 889/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0930 - accuracy: 0.9667 - val_loss: 0.5316 - val_accuracy: 0.8286\n",
      "Epoch 890/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.5321 - val_accuracy: 0.8286\n",
      "Epoch 891/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.5326 - val_accuracy: 0.8286\n",
      "Epoch 892/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 0.5331 - val_accuracy: 0.8286\n",
      "Epoch 893/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.5335 - val_accuracy: 0.8286\n",
      "Epoch 894/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.5339 - val_accuracy: 0.8286\n",
      "Epoch 895/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0923 - accuracy: 0.9667 - val_loss: 0.5341 - val_accuracy: 0.8286\n",
      "Epoch 896/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0922 - accuracy: 0.9667 - val_loss: 0.5342 - val_accuracy: 0.8286\n",
      "Epoch 897/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.5343 - val_accuracy: 0.8286\n",
      "Epoch 898/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0920 - accuracy: 0.9667 - val_loss: 0.5345 - val_accuracy: 0.8286\n",
      "Epoch 899/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.5348 - val_accuracy: 0.8286\n",
      "Epoch 900/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.5353 - val_accuracy: 0.8286\n",
      "Epoch 901/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.5358 - val_accuracy: 0.8286\n",
      "Epoch 902/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.5363 - val_accuracy: 0.8286\n",
      "Epoch 903/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0914 - accuracy: 0.9667 - val_loss: 0.5368 - val_accuracy: 0.8286\n",
      "Epoch 904/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0913 - accuracy: 0.9667 - val_loss: 0.5371 - val_accuracy: 0.8286\n",
      "Epoch 905/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0912 - accuracy: 0.9667 - val_loss: 0.5373 - val_accuracy: 0.8286\n",
      "Epoch 906/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0911 - accuracy: 0.9667 - val_loss: 0.5374 - val_accuracy: 0.8286\n",
      "Epoch 907/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.5376 - val_accuracy: 0.8286\n",
      "Epoch 908/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0909 - accuracy: 0.9667 - val_loss: 0.5378 - val_accuracy: 0.8286\n",
      "Epoch 909/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.5382 - val_accuracy: 0.8286\n",
      "Epoch 910/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0906 - accuracy: 0.9667 - val_loss: 0.5386 - val_accuracy: 0.8286\n",
      "Epoch 911/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.5391 - val_accuracy: 0.8286\n",
      "Epoch 912/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0904 - accuracy: 0.9667 - val_loss: 0.5396 - val_accuracy: 0.8286\n",
      "Epoch 913/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0903 - accuracy: 0.9667 - val_loss: 0.5399 - val_accuracy: 0.8286\n",
      "Epoch 914/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.5403 - val_accuracy: 0.8286\n",
      "Epoch 915/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0901 - accuracy: 0.9667 - val_loss: 0.5405 - val_accuracy: 0.8286\n",
      "Epoch 916/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0899 - accuracy: 0.9667 - val_loss: 0.5407 - val_accuracy: 0.8286\n",
      "Epoch 917/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0898 - accuracy: 0.9667 - val_loss: 0.5409 - val_accuracy: 0.8286\n",
      "Epoch 918/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0897 - accuracy: 0.9667 - val_loss: 0.5412 - val_accuracy: 0.8286\n",
      "Epoch 919/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0896 - accuracy: 0.9667 - val_loss: 0.5416 - val_accuracy: 0.8286\n",
      "Epoch 920/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0895 - accuracy: 0.9667 - val_loss: 0.5419 - val_accuracy: 0.8286\n",
      "Epoch 921/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0894 - accuracy: 0.9667 - val_loss: 0.5424 - val_accuracy: 0.8286\n",
      "Epoch 922/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0893 - accuracy: 0.9667 - val_loss: 0.5428 - val_accuracy: 0.8286\n",
      "Epoch 923/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.5432 - val_accuracy: 0.8286\n",
      "Epoch 924/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0891 - accuracy: 0.9667 - val_loss: 0.5434 - val_accuracy: 0.8286\n",
      "Epoch 925/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0890 - accuracy: 0.9667 - val_loss: 0.5436 - val_accuracy: 0.8286\n",
      "Epoch 926/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0888 - accuracy: 0.9667 - val_loss: 0.5438 - val_accuracy: 0.8286\n",
      "Epoch 927/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0887 - accuracy: 0.9667 - val_loss: 0.5441 - val_accuracy: 0.8286\n",
      "Epoch 928/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0886 - accuracy: 0.9667 - val_loss: 0.5445 - val_accuracy: 0.8286\n",
      "Epoch 929/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0885 - accuracy: 0.9667 - val_loss: 0.5450 - val_accuracy: 0.8286\n",
      "Epoch 930/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.5454 - val_accuracy: 0.8286\n",
      "Epoch 931/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0883 - accuracy: 0.9667 - val_loss: 0.5457 - val_accuracy: 0.8286\n",
      "Epoch 932/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0882 - accuracy: 0.9667 - val_loss: 0.5461 - val_accuracy: 0.8286\n",
      "Epoch 933/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0881 - accuracy: 0.9667 - val_loss: 0.5464 - val_accuracy: 0.8286\n",
      "Epoch 934/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.5466 - val_accuracy: 0.8286\n",
      "Epoch 935/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.5467 - val_accuracy: 0.8286\n",
      "Epoch 936/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.5469 - val_accuracy: 0.8286\n",
      "Epoch 937/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.5473 - val_accuracy: 0.8143\n",
      "Epoch 938/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0876 - accuracy: 0.9667 - val_loss: 0.5478 - val_accuracy: 0.8143\n",
      "Epoch 939/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.5483 - val_accuracy: 0.8143\n",
      "Epoch 940/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.5487 - val_accuracy: 0.8143\n",
      "Epoch 941/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.5490 - val_accuracy: 0.8143\n",
      "Epoch 942/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0871 - accuracy: 0.9667 - val_loss: 0.5493 - val_accuracy: 0.8143\n",
      "Epoch 943/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0870 - accuracy: 0.9667 - val_loss: 0.5496 - val_accuracy: 0.8143\n",
      "Epoch 944/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.5498 - val_accuracy: 0.8143\n",
      "Epoch 945/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0868 - accuracy: 0.9667 - val_loss: 0.5499 - val_accuracy: 0.8143\n",
      "Epoch 946/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0867 - accuracy: 0.9667 - val_loss: 0.5502 - val_accuracy: 0.8143\n",
      "Epoch 947/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0866 - accuracy: 0.9667 - val_loss: 0.5506 - val_accuracy: 0.8143\n",
      "Epoch 948/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0865 - accuracy: 0.9667 - val_loss: 0.5511 - val_accuracy: 0.8143\n",
      "Epoch 949/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.5516 - val_accuracy: 0.8143\n",
      "Epoch 950/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0863 - accuracy: 0.9667 - val_loss: 0.5520 - val_accuracy: 0.8143\n",
      "Epoch 951/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.5523 - val_accuracy: 0.8143\n",
      "Epoch 952/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0861 - accuracy: 0.9667 - val_loss: 0.5525 - val_accuracy: 0.8143\n",
      "Epoch 953/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0860 - accuracy: 0.9667 - val_loss: 0.5527 - val_accuracy: 0.8143\n",
      "Epoch 954/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0858 - accuracy: 0.9667 - val_loss: 0.5528 - val_accuracy: 0.8143\n",
      "Epoch 955/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0857 - accuracy: 0.9667 - val_loss: 0.5531 - val_accuracy: 0.8143\n",
      "Epoch 956/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0856 - accuracy: 0.9667 - val_loss: 0.5535 - val_accuracy: 0.8143\n",
      "Epoch 957/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0855 - accuracy: 0.9667 - val_loss: 0.5539 - val_accuracy: 0.8143\n",
      "Epoch 958/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.5543 - val_accuracy: 0.8143\n",
      "Epoch 959/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 0.5547 - val_accuracy: 0.8143\n",
      "Epoch 960/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0852 - accuracy: 0.9667 - val_loss: 0.5551 - val_accuracy: 0.8143\n",
      "Epoch 961/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0851 - accuracy: 0.9667 - val_loss: 0.5554 - val_accuracy: 0.8143\n",
      "Epoch 962/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0850 - accuracy: 0.9667 - val_loss: 0.5556 - val_accuracy: 0.8143\n",
      "Epoch 963/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0849 - accuracy: 0.9667 - val_loss: 0.5559 - val_accuracy: 0.8143\n",
      "Epoch 964/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0848 - accuracy: 0.9667 - val_loss: 0.5562 - val_accuracy: 0.8143\n",
      "Epoch 965/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0847 - accuracy: 0.9667 - val_loss: 0.5565 - val_accuracy: 0.8143\n",
      "Epoch 966/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0846 - accuracy: 0.9667 - val_loss: 0.5568 - val_accuracy: 0.8143\n",
      "Epoch 967/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0845 - accuracy: 0.9667 - val_loss: 0.5572 - val_accuracy: 0.8143\n",
      "Epoch 968/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0844 - accuracy: 0.9667 - val_loss: 0.5577 - val_accuracy: 0.8143\n",
      "Epoch 969/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0843 - accuracy: 0.9667 - val_loss: 0.5581 - val_accuracy: 0.8143\n",
      "Epoch 970/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0842 - accuracy: 0.9667 - val_loss: 0.5586 - val_accuracy: 0.8143\n",
      "Epoch 971/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0841 - accuracy: 0.9667 - val_loss: 0.5588 - val_accuracy: 0.8143\n",
      "Epoch 972/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0840 - accuracy: 0.9667 - val_loss: 0.5590 - val_accuracy: 0.8143\n",
      "Epoch 973/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0839 - accuracy: 0.9667 - val_loss: 0.5591 - val_accuracy: 0.8143\n",
      "Epoch 974/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.5594 - val_accuracy: 0.8143\n",
      "Epoch 975/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.5597 - val_accuracy: 0.8143\n",
      "Epoch 976/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0835 - accuracy: 0.9667 - val_loss: 0.5601 - val_accuracy: 0.8143\n",
      "Epoch 977/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0834 - accuracy: 0.9667 - val_loss: 0.5606 - val_accuracy: 0.8143\n",
      "Epoch 978/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0833 - accuracy: 0.9667 - val_loss: 0.5611 - val_accuracy: 0.8143\n",
      "Epoch 979/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0832 - accuracy: 0.9667 - val_loss: 0.5615 - val_accuracy: 0.8143\n",
      "Epoch 980/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0831 - accuracy: 0.9667 - val_loss: 0.5618 - val_accuracy: 0.8143\n",
      "Epoch 981/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0830 - accuracy: 0.9667 - val_loss: 0.5621 - val_accuracy: 0.8143\n",
      "Epoch 982/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0829 - accuracy: 0.9667 - val_loss: 0.5623 - val_accuracy: 0.8143\n",
      "Epoch 983/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.5625 - val_accuracy: 0.8143\n",
      "Epoch 984/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0827 - accuracy: 0.9667 - val_loss: 0.5628 - val_accuracy: 0.8143\n",
      "Epoch 985/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0826 - accuracy: 0.9667 - val_loss: 0.5632 - val_accuracy: 0.8143\n",
      "Epoch 986/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0825 - accuracy: 0.9667 - val_loss: 0.5635 - val_accuracy: 0.8143\n",
      "Epoch 987/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0824 - accuracy: 0.9667 - val_loss: 0.5639 - val_accuracy: 0.8143\n",
      "Epoch 988/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0822 - accuracy: 0.9667 - val_loss: 0.5644 - val_accuracy: 0.8143\n",
      "Epoch 989/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0821 - accuracy: 0.9667 - val_loss: 0.5647 - val_accuracy: 0.8143\n",
      "Epoch 990/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.5650 - val_accuracy: 0.8143\n",
      "Epoch 991/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0819 - accuracy: 0.9667 - val_loss: 0.5652 - val_accuracy: 0.8143\n",
      "Epoch 992/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0818 - accuracy: 0.9667 - val_loss: 0.5655 - val_accuracy: 0.8143\n",
      "Epoch 993/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0817 - accuracy: 0.9667 - val_loss: 0.5659 - val_accuracy: 0.8143\n",
      "Epoch 994/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 0.5662 - val_accuracy: 0.8143\n",
      "Epoch 995/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0815 - accuracy: 0.9667 - val_loss: 0.5665 - val_accuracy: 0.8143\n",
      "Epoch 996/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.5668 - val_accuracy: 0.8143\n",
      "Epoch 997/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0813 - accuracy: 0.9667 - val_loss: 0.5674 - val_accuracy: 0.8143\n",
      "Epoch 998/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0812 - accuracy: 0.9667 - val_loss: 0.5679 - val_accuracy: 0.8143\n",
      "Epoch 999/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0811 - accuracy: 0.9667 - val_loss: 0.5683 - val_accuracy: 0.8143\n",
      "Epoch 1000/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0810 - accuracy: 0.9667 - val_loss: 0.5685 - val_accuracy: 0.8143\n",
      "Epoch 1001/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0809 - accuracy: 0.9667 - val_loss: 0.5687 - val_accuracy: 0.8143\n",
      "Epoch 1002/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0807 - accuracy: 0.9667 - val_loss: 0.5691 - val_accuracy: 0.8143\n",
      "Epoch 1003/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.5695 - val_accuracy: 0.8143\n",
      "Epoch 1004/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0805 - accuracy: 0.9667 - val_loss: 0.5698 - val_accuracy: 0.8143\n",
      "Epoch 1005/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0804 - accuracy: 0.9667 - val_loss: 0.5701 - val_accuracy: 0.8143\n",
      "Epoch 1006/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0803 - accuracy: 0.9667 - val_loss: 0.5705 - val_accuracy: 0.8143\n",
      "Epoch 1007/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0802 - accuracy: 0.9667 - val_loss: 0.5711 - val_accuracy: 0.8143\n",
      "Epoch 1008/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0801 - accuracy: 0.9667 - val_loss: 0.5716 - val_accuracy: 0.8143\n",
      "Epoch 1009/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0800 - accuracy: 0.9667 - val_loss: 0.5718 - val_accuracy: 0.8143\n",
      "Epoch 1010/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0799 - accuracy: 0.9667 - val_loss: 0.5720 - val_accuracy: 0.8143\n",
      "Epoch 1011/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.5723 - val_accuracy: 0.8143\n",
      "Epoch 1012/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0797 - accuracy: 0.9667 - val_loss: 0.5726 - val_accuracy: 0.8143\n",
      "Epoch 1013/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0796 - accuracy: 0.9667 - val_loss: 0.5729 - val_accuracy: 0.8143\n",
      "Epoch 1014/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0794 - accuracy: 0.9667 - val_loss: 0.5731 - val_accuracy: 0.8143\n",
      "Epoch 1015/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.5735 - val_accuracy: 0.8143\n",
      "Epoch 1016/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0792 - accuracy: 0.9667 - val_loss: 0.5741 - val_accuracy: 0.8143\n",
      "Epoch 1017/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0791 - accuracy: 0.9667 - val_loss: 0.5749 - val_accuracy: 0.8143\n",
      "Epoch 1018/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0790 - accuracy: 0.9667 - val_loss: 0.5754 - val_accuracy: 0.8143\n",
      "Epoch 1019/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0789 - accuracy: 0.9667 - val_loss: 0.5757 - val_accuracy: 0.8143\n",
      "Epoch 1020/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0788 - accuracy: 0.9667 - val_loss: 0.5760 - val_accuracy: 0.8143\n",
      "Epoch 1021/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0786 - accuracy: 0.9667 - val_loss: 0.5762 - val_accuracy: 0.8143\n",
      "Epoch 1022/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0785 - accuracy: 0.9667 - val_loss: 0.5766 - val_accuracy: 0.8143\n",
      "Epoch 1023/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0784 - accuracy: 0.9667 - val_loss: 0.5768 - val_accuracy: 0.8143\n",
      "Epoch 1024/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0783 - accuracy: 0.9667 - val_loss: 0.5771 - val_accuracy: 0.8143\n",
      "Epoch 1025/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.8143\n",
      "Epoch 1026/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.5780 - val_accuracy: 0.8143\n",
      "Epoch 1027/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0779 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.8143\n",
      "Epoch 1028/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8143\n",
      "Epoch 1029/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.5795 - val_accuracy: 0.8143\n",
      "Epoch 1030/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.8143\n",
      "Epoch 1031/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.8143\n",
      "Epoch 1032/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.8143\n",
      "Epoch 1033/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8143\n",
      "Epoch 1034/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.8143\n",
      "Epoch 1035/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8143\n",
      "Epoch 1036/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.8143\n",
      "Epoch 1037/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8143\n",
      "Epoch 1038/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.8143\n",
      "Epoch 1039/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.8143\n",
      "Epoch 1040/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.8143\n",
      "Epoch 1041/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.8143\n",
      "Epoch 1042/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.5849 - val_accuracy: 0.8143\n",
      "Epoch 1043/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.8143\n",
      "Epoch 1044/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.8143\n",
      "Epoch 1045/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.8143\n",
      "Epoch 1046/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.8143\n",
      "Epoch 1047/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.5875 - val_accuracy: 0.8143\n",
      "Epoch 1048/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.8143\n",
      "Epoch 1049/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0753 - accuracy: 1.0000 - val_loss: 0.5888 - val_accuracy: 0.8143\n",
      "Epoch 1050/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8143\n",
      "Epoch 1051/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.8143\n",
      "Epoch 1052/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.5900 - val_accuracy: 0.8143\n",
      "Epoch 1053/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.5903 - val_accuracy: 0.8143\n",
      "Epoch 1054/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.5906 - val_accuracy: 0.8143\n",
      "Epoch 1055/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8143\n",
      "Epoch 1056/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.8143\n",
      "Epoch 1057/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8143\n",
      "Epoch 1058/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.5932 - val_accuracy: 0.8143\n",
      "Epoch 1059/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.8143\n",
      "Epoch 1060/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.8143\n",
      "Epoch 1061/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.8143\n",
      "Epoch 1062/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.8143\n",
      "Epoch 1063/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.8143\n",
      "Epoch 1064/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.8143\n",
      "Epoch 1065/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.8143\n",
      "Epoch 1066/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.8143\n",
      "Epoch 1067/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.8143\n",
      "Epoch 1068/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.8143\n",
      "Epoch 1069/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0730 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8143\n",
      "Epoch 1070/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.8143\n",
      "Epoch 1071/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.6003 - val_accuracy: 0.8143\n",
      "Epoch 1072/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8143\n",
      "Epoch 1073/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.8143\n",
      "Epoch 1074/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8143\n",
      "Epoch 1075/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.8143\n",
      "Epoch 1076/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.8143\n",
      "Epoch 1077/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.8143\n",
      "Epoch 1078/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8143\n",
      "Epoch 1079/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.8143\n",
      "Epoch 1080/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.8143\n",
      "Epoch 1081/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8143\n",
      "Epoch 1082/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.8143\n",
      "Epoch 1083/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.8143\n",
      "Epoch 1084/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8143\n",
      "Epoch 1085/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8143\n",
      "Epoch 1086/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.8143\n",
      "Epoch 1087/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 0.8143\n",
      "Epoch 1088/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8143\n",
      "Epoch 1089/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8143\n",
      "Epoch 1090/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8143\n",
      "Epoch 1091/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.8143\n",
      "Epoch 1092/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.6127 - val_accuracy: 0.8143\n",
      "Epoch 1093/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8143\n",
      "Epoch 1094/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.6136 - val_accuracy: 0.8143\n",
      "Epoch 1095/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 0.8143\n",
      "Epoch 1096/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.8143\n",
      "Epoch 1097/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8143\n",
      "Epoch 1098/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.6164 - val_accuracy: 0.8143\n",
      "Epoch 1099/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.8143\n",
      "Epoch 1100/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.8143\n",
      "Epoch 1101/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.8143\n",
      "Epoch 1102/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8143\n",
      "Epoch 1103/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 0.6192 - val_accuracy: 0.8143\n",
      "Epoch 1104/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.6198 - val_accuracy: 0.8143\n",
      "Epoch 1105/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.8143\n",
      "Epoch 1106/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8143\n",
      "Epoch 1107/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.6217 - val_accuracy: 0.8143\n",
      "Epoch 1108/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.6225 - val_accuracy: 0.8143\n",
      "Epoch 1109/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.8143\n",
      "Epoch 1110/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.8143\n",
      "Epoch 1111/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.8143\n",
      "Epoch 1112/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.8143\n",
      "Epoch 1113/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.8143\n",
      "Epoch 1114/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.8143\n",
      "Epoch 1115/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.6267 - val_accuracy: 0.8143\n",
      "Epoch 1116/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.8143\n",
      "Epoch 1117/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.6281 - val_accuracy: 0.8143\n",
      "Epoch 1118/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8143\n",
      "Epoch 1119/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.8143\n",
      "Epoch 1120/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8143\n",
      "Epoch 1121/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8143\n",
      "Epoch 1122/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.8143\n",
      "Epoch 1123/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.8143\n",
      "Epoch 1124/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.8143\n",
      "Epoch 1125/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.8143\n",
      "Epoch 1126/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.8143\n",
      "Epoch 1127/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.8143\n",
      "Epoch 1128/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.8143\n",
      "Epoch 1129/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.8143\n",
      "Epoch 1130/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.8143\n",
      "Epoch 1131/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.8143\n",
      "Epoch 1132/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.8143\n",
      "Epoch 1133/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.8143\n",
      "Epoch 1134/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8143\n",
      "Epoch 1135/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8143\n",
      "Epoch 1136/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.8143\n",
      "Epoch 1137/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 0.8143\n",
      "Epoch 1138/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8143\n",
      "Epoch 1139/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.8143\n",
      "Epoch 1140/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8000\n",
      "Epoch 1141/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.6436 - val_accuracy: 0.8000\n",
      "Epoch 1142/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.6441 - val_accuracy: 0.8000\n",
      "Epoch 1143/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.8000\n",
      "Epoch 1144/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 0.8000\n",
      "Epoch 1145/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.8000\n",
      "Epoch 1146/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.8000\n",
      "Epoch 1147/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.8000\n",
      "Epoch 1148/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.8000\n",
      "Epoch 1149/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
      "Epoch 1150/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8000\n",
      "Epoch 1151/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.6501 - val_accuracy: 0.8000\n",
      "Epoch 1152/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.6506 - val_accuracy: 0.8000\n",
      "Epoch 1153/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.6512 - val_accuracy: 0.8000\n",
      "Epoch 1154/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.6518 - val_accuracy: 0.8000\n",
      "Epoch 1155/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
      "Epoch 1156/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8000\n",
      "Epoch 1157/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.6541 - val_accuracy: 0.8000\n",
      "Epoch 1158/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.8000\n",
      "Epoch 1159/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8000\n",
      "Epoch 1160/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8000\n",
      "Epoch 1161/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8000\n",
      "Epoch 1162/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.6573 - val_accuracy: 0.8000\n",
      "Epoch 1163/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8000\n",
      "Epoch 1164/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8000\n",
      "Epoch 1165/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8000\n",
      "Epoch 1166/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 1167/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.6608 - val_accuracy: 0.8000\n",
      "Epoch 1168/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8000\n",
      "Epoch 1169/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.8000\n",
      "Epoch 1170/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.6628 - val_accuracy: 0.8000\n",
      "Epoch 1171/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8000\n",
      "Epoch 1172/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.8000\n",
      "Epoch 1173/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.6646 - val_accuracy: 0.8000\n",
      "Epoch 1174/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8000\n",
      "Epoch 1175/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.8000\n",
      "Epoch 1176/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.8000\n",
      "Epoch 1177/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.8000\n",
      "Epoch 1178/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.8000\n",
      "Epoch 1179/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.6686 - val_accuracy: 0.8000\n",
      "Epoch 1180/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.6694 - val_accuracy: 0.8000\n",
      "Epoch 1181/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8000\n",
      "Epoch 1182/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.6708 - val_accuracy: 0.8000\n",
      "Epoch 1183/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8000\n",
      "Epoch 1184/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.6721 - val_accuracy: 0.8000\n",
      "Epoch 1185/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 1186/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8000\n",
      "Epoch 1187/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.8000\n",
      "Epoch 1188/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 0.8000\n",
      "Epoch 1189/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.8000\n",
      "Epoch 1190/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.8000\n",
      "Epoch 1191/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8000\n",
      "Epoch 1192/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8000\n",
      "Epoch 1193/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.6784 - val_accuracy: 0.8000\n",
      "Epoch 1194/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8000\n",
      "Epoch 1195/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.6801 - val_accuracy: 0.8000\n",
      "Epoch 1196/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8000\n",
      "Epoch 1197/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 0.8000\n",
      "Epoch 1198/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.8000\n",
      "Epoch 1199/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.8000\n",
      "Epoch 1200/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.6835 - val_accuracy: 0.8000\n",
      "Epoch 1201/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.8000\n",
      "Epoch 1202/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.8000\n",
      "Epoch 1203/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.6855 - val_accuracy: 0.8000\n",
      "Epoch 1204/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.8000\n",
      "Epoch 1205/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8000\n",
      "Epoch 1206/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.6876 - val_accuracy: 0.8000\n",
      "Epoch 1207/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8000\n",
      "Epoch 1208/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8000\n",
      "Epoch 1209/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.6900 - val_accuracy: 0.8000\n",
      "Epoch 1210/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.8000\n",
      "Epoch 1211/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8000\n",
      "Epoch 1212/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8000\n",
      "Epoch 1213/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8000\n",
      "Epoch 1214/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.6935 - val_accuracy: 0.8000\n",
      "Epoch 1215/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.8000\n",
      "Epoch 1216/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.8000\n",
      "Epoch 1217/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.8000\n",
      "Epoch 1218/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8000\n",
      "Epoch 1219/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8000\n",
      "Epoch 1220/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.6981 - val_accuracy: 0.8000\n",
      "Epoch 1221/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.8000\n",
      "Epoch 1222/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.6994 - val_accuracy: 0.8000\n",
      "Epoch 1223/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.8000\n",
      "Epoch 1224/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.8000\n",
      "Epoch 1225/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8000\n",
      "Epoch 1226/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8000\n",
      "Epoch 1227/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.8000\n",
      "Epoch 1228/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8000\n",
      "Epoch 1229/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8000\n",
      "Epoch 1230/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8000\n",
      "Epoch 1231/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.8000\n",
      "Epoch 1232/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.7857\n",
      "Epoch 1233/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.7857\n",
      "Epoch 1234/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.7082 - val_accuracy: 0.7857\n",
      "Epoch 1235/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.7857\n",
      "Epoch 1236/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.7097 - val_accuracy: 0.7857\n",
      "Epoch 1237/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.7857\n",
      "Epoch 1238/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.7857\n",
      "Epoch 1239/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.7857\n",
      "Epoch 1240/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.7857\n",
      "Epoch 1241/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.7135 - val_accuracy: 0.7857\n",
      "Epoch 1242/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.7144 - val_accuracy: 0.7857\n",
      "Epoch 1243/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.7857\n",
      "Epoch 1244/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.7857\n",
      "Epoch 1245/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.7857\n",
      "Epoch 1246/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.7857\n",
      "Epoch 1247/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.7857\n",
      "Epoch 1248/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.7857\n",
      "Epoch 1249/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.7192 - val_accuracy: 0.7857\n",
      "Epoch 1250/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.7857\n",
      "Epoch 1251/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.7208 - val_accuracy: 0.7857\n",
      "Epoch 1252/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.7857\n",
      "Epoch 1253/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.7857\n",
      "Epoch 1254/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.7857\n",
      "Epoch 1255/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.7857\n",
      "Epoch 1256/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.7857\n",
      "Epoch 1257/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.7857\n",
      "Epoch 1258/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.7857\n",
      "Epoch 1259/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.7857\n",
      "Epoch 1260/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.7857\n",
      "Epoch 1261/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.7857\n",
      "Epoch 1262/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.7857\n",
      "Epoch 1263/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.7300 - val_accuracy: 0.7857\n",
      "Epoch 1264/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.7857\n",
      "Epoch 1265/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 0.7857\n",
      "Epoch 1266/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.7857\n",
      "Epoch 1267/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.7857\n",
      "Epoch 1268/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.7341 - val_accuracy: 0.7857\n",
      "Epoch 1269/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.7349 - val_accuracy: 0.7857\n",
      "Epoch 1270/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.7857\n",
      "Epoch 1271/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.7362 - val_accuracy: 0.7857\n",
      "Epoch 1272/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.7857\n",
      "Epoch 1273/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.7857\n",
      "Epoch 1274/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.7857\n",
      "Epoch 1275/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.7397 - val_accuracy: 0.7857\n",
      "Epoch 1276/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.7857\n",
      "Epoch 1277/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.7857\n",
      "Epoch 1278/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.7857\n",
      "Epoch 1279/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.7857\n",
      "Epoch 1280/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.7434 - val_accuracy: 0.7857\n",
      "Epoch 1281/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.7857\n",
      "Epoch 1282/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.7857\n",
      "Epoch 1283/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.7857\n",
      "Epoch 1284/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.7857\n",
      "Epoch 1285/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.7857\n",
      "Epoch 1286/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.7481 - val_accuracy: 0.7857\n",
      "Epoch 1287/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.7489 - val_accuracy: 0.7857\n",
      "Epoch 1288/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.7857\n",
      "Epoch 1289/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.7857\n",
      "Epoch 1290/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.7857\n",
      "Epoch 1291/4000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.7520 - val_accuracy: 0.7857\n",
      "Epoch 1292/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.7527 - val_accuracy: 0.7857\n",
      "Epoch 1293/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.7857\n",
      "Epoch 1294/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.7543 - val_accuracy: 0.7857\n",
      "Epoch 1295/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.7857\n",
      "Epoch 1296/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.7561 - val_accuracy: 0.7857\n",
      "Epoch 1297/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.7857\n",
      "Epoch 1298/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.7857\n",
      "Epoch 1299/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.7857\n",
      "Epoch 1300/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.7857\n",
      "Epoch 1301/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.7597 - val_accuracy: 0.7857\n",
      "Epoch 1302/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.7857\n",
      "Epoch 1303/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.7611 - val_accuracy: 0.7857\n",
      "Epoch 1304/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.7857\n",
      "Epoch 1305/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.7857\n",
      "Epoch 1306/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.7637 - val_accuracy: 0.7857\n",
      "Epoch 1307/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.7645 - val_accuracy: 0.7857\n",
      "Epoch 1308/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.7857\n",
      "Epoch 1309/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.7660 - val_accuracy: 0.7857\n",
      "Epoch 1310/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.7857\n",
      "Epoch 1311/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.7675 - val_accuracy: 0.7857\n",
      "Epoch 1312/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.7857\n",
      "Epoch 1313/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.7690 - val_accuracy: 0.7857\n",
      "Epoch 1314/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.7857\n",
      "Epoch 1315/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.7704 - val_accuracy: 0.7857\n",
      "Epoch 1316/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.7857\n",
      "Epoch 1317/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.7857\n",
      "Epoch 1318/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.7857\n",
      "Epoch 1319/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7857\n",
      "Epoch 1320/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.7745 - val_accuracy: 0.7857\n",
      "Epoch 1321/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.7752 - val_accuracy: 0.7857\n",
      "Epoch 1322/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.7760 - val_accuracy: 0.7857\n",
      "Epoch 1323/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.7768 - val_accuracy: 0.7857\n",
      "Epoch 1324/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.7775 - val_accuracy: 0.7857\n",
      "Epoch 1325/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.7782 - val_accuracy: 0.7857\n",
      "Epoch 1326/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.7857\n",
      "Epoch 1327/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.7799 - val_accuracy: 0.7857\n",
      "Epoch 1328/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.7857\n",
      "Epoch 1329/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.7857\n",
      "Epoch 1330/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.7824 - val_accuracy: 0.7857\n",
      "Epoch 1331/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.7857\n",
      "Epoch 1332/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.7857\n",
      "Epoch 1333/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.7857\n",
      "Epoch 1334/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.7853 - val_accuracy: 0.7857\n",
      "Epoch 1335/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.7857\n",
      "Epoch 1336/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7857\n",
      "Epoch 1337/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.7878 - val_accuracy: 0.7857\n",
      "Epoch 1338/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.7887 - val_accuracy: 0.7857\n",
      "Epoch 1339/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7857\n",
      "Epoch 1340/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.7902 - val_accuracy: 0.7857\n",
      "Epoch 1341/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.7909 - val_accuracy: 0.7857\n",
      "Epoch 1342/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.7916 - val_accuracy: 0.7857\n",
      "Epoch 1343/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.7857\n",
      "Epoch 1344/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.7857\n",
      "Epoch 1345/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.7857\n",
      "Epoch 1346/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.7857\n",
      "Epoch 1347/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7857\n",
      "Epoch 1348/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.7857\n",
      "Epoch 1349/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7857\n",
      "Epoch 1350/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.7857\n",
      "Epoch 1351/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.7857\n",
      "Epoch 1352/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.7857\n",
      "Epoch 1353/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.8001 - val_accuracy: 0.7857\n",
      "Epoch 1354/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.7857\n",
      "Epoch 1355/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.8015 - val_accuracy: 0.7857\n",
      "Epoch 1356/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7857\n",
      "Epoch 1357/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.8032 - val_accuracy: 0.7857\n",
      "Epoch 1358/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.8040 - val_accuracy: 0.7857\n",
      "Epoch 1359/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.7857\n",
      "Epoch 1360/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.7857\n",
      "Epoch 1361/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7857\n",
      "Epoch 1362/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.7857\n",
      "Epoch 1363/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.7857\n",
      "Epoch 1364/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.7857\n",
      "Epoch 1365/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.7857\n",
      "Epoch 1366/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.7857\n",
      "Epoch 1367/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.8105 - val_accuracy: 0.7857\n",
      "Epoch 1368/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7857\n",
      "Epoch 1369/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7857\n",
      "Epoch 1370/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.7857\n",
      "Epoch 1371/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.7857\n",
      "Epoch 1372/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.8147 - val_accuracy: 0.7857\n",
      "Epoch 1373/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.8155 - val_accuracy: 0.7857\n",
      "Epoch 1374/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.7857\n",
      "Epoch 1375/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.7857\n",
      "Epoch 1376/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.8177 - val_accuracy: 0.7857\n",
      "Epoch 1377/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.7857\n",
      "Epoch 1378/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.7857\n",
      "Epoch 1379/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.8198 - val_accuracy: 0.7857\n",
      "Epoch 1380/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.7857\n",
      "Epoch 1381/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.7857\n",
      "Epoch 1382/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.8224 - val_accuracy: 0.7857\n",
      "Epoch 1383/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.7857\n",
      "Epoch 1384/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7857\n",
      "Epoch 1385/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.7857\n",
      "Epoch 1386/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.8254 - val_accuracy: 0.7857\n",
      "Epoch 1387/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.8262 - val_accuracy: 0.7857\n",
      "Epoch 1388/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.7857\n",
      "Epoch 1389/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.7857\n",
      "Epoch 1390/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.8284 - val_accuracy: 0.7857\n",
      "Epoch 1391/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.7857\n",
      "Epoch 1392/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7857\n",
      "Epoch 1393/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.8304 - val_accuracy: 0.7857\n",
      "Epoch 1394/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.7857\n",
      "Epoch 1395/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.7857\n",
      "Epoch 1396/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.8328 - val_accuracy: 0.7857\n",
      "Epoch 1397/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.8335 - val_accuracy: 0.7857\n",
      "Epoch 1398/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.7857\n",
      "Epoch 1399/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.7857\n",
      "Epoch 1400/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.8359 - val_accuracy: 0.7857\n",
      "Epoch 1401/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.8367 - val_accuracy: 0.7857\n",
      "Epoch 1402/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.8375 - val_accuracy: 0.7857\n",
      "Epoch 1403/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.8383 - val_accuracy: 0.7857\n",
      "Epoch 1404/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.8392 - val_accuracy: 0.7857\n",
      "Epoch 1405/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.8399 - val_accuracy: 0.7857\n",
      "Epoch 1406/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7857\n",
      "Epoch 1407/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.8414 - val_accuracy: 0.7857\n",
      "Epoch 1408/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.8422 - val_accuracy: 0.7857\n",
      "Epoch 1409/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.7857\n",
      "Epoch 1410/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.8433 - val_accuracy: 0.7857\n",
      "Epoch 1411/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.8441 - val_accuracy: 0.7857\n",
      "Epoch 1412/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.8449 - val_accuracy: 0.7857\n",
      "Epoch 1413/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.7857\n",
      "Epoch 1414/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.7857\n",
      "Epoch 1415/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.7857\n",
      "Epoch 1416/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.7857\n",
      "Epoch 1417/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.7857\n",
      "Epoch 1418/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.8498 - val_accuracy: 0.7857\n",
      "Epoch 1419/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.8506 - val_accuracy: 0.7857\n",
      "Epoch 1420/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.8513 - val_accuracy: 0.7857\n",
      "Epoch 1421/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.8521 - val_accuracy: 0.7857\n",
      "Epoch 1422/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.8528 - val_accuracy: 0.7857\n",
      "Epoch 1423/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.7857\n",
      "Epoch 1424/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.7857\n",
      "Epoch 1425/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.7857\n",
      "Epoch 1426/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.7857\n",
      "Epoch 1427/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.7857\n",
      "Epoch 1428/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.8569 - val_accuracy: 0.7857\n",
      "Epoch 1429/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.7857\n",
      "Epoch 1430/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.7857\n",
      "Epoch 1431/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.7857\n",
      "Epoch 1432/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.7857\n",
      "Epoch 1433/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.8609 - val_accuracy: 0.7857\n",
      "Epoch 1434/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.7857\n",
      "Epoch 1435/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.7857\n",
      "Epoch 1436/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.7857\n",
      "Epoch 1437/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.7857\n",
      "Epoch 1438/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.7857\n",
      "Epoch 1439/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.7857\n",
      "Epoch 1440/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.7857\n",
      "Epoch 1441/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.7857\n",
      "Epoch 1442/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.7857\n",
      "Epoch 1443/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.7857\n",
      "Epoch 1444/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 0.7857\n",
      "Epoch 1445/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.8696 - val_accuracy: 0.7857\n",
      "Epoch 1446/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.8704 - val_accuracy: 0.7857\n",
      "Epoch 1447/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.7857\n",
      "Epoch 1448/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.7857\n",
      "Epoch 1449/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.7857\n",
      "Epoch 1450/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.7857\n",
      "Epoch 1451/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.7857\n",
      "Epoch 1452/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.7857\n",
      "Epoch 1453/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.7857\n",
      "Epoch 1454/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.7857\n",
      "Epoch 1455/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.8770 - val_accuracy: 0.7857\n",
      "Epoch 1456/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.7857\n",
      "Epoch 1457/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.8786 - val_accuracy: 0.7857\n",
      "Epoch 1458/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.8795 - val_accuracy: 0.7857\n",
      "Epoch 1459/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.8803 - val_accuracy: 0.7857\n",
      "Epoch 1460/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7857\n",
      "Epoch 1461/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.8816 - val_accuracy: 0.7857\n",
      "Epoch 1462/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.8824 - val_accuracy: 0.7857\n",
      "Epoch 1463/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7857\n",
      "Epoch 1464/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.7857\n",
      "Epoch 1465/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.7857\n",
      "Epoch 1466/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.8852 - val_accuracy: 0.7857\n",
      "Epoch 1467/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.8859 - val_accuracy: 0.7857\n",
      "Epoch 1468/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.7857\n",
      "Epoch 1469/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.8873 - val_accuracy: 0.7857\n",
      "Epoch 1470/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.7857\n",
      "Epoch 1471/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.8888 - val_accuracy: 0.7857\n",
      "Epoch 1472/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.8896 - val_accuracy: 0.7857\n",
      "Epoch 1473/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.8903 - val_accuracy: 0.7857\n",
      "Epoch 1474/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.7857\n",
      "Epoch 1475/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.8918 - val_accuracy: 0.7857\n",
      "Epoch 1476/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.7857\n",
      "Epoch 1477/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.8935 - val_accuracy: 0.7857\n",
      "Epoch 1478/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.7857\n",
      "Epoch 1479/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.8949 - val_accuracy: 0.7857\n",
      "Epoch 1480/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.7857\n",
      "Epoch 1481/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.7857\n",
      "Epoch 1482/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.7857\n",
      "Epoch 1483/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.7857\n",
      "Epoch 1484/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.7857\n",
      "Epoch 1485/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.8993 - val_accuracy: 0.7857\n",
      "Epoch 1486/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.7857\n",
      "Epoch 1487/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.7857\n",
      "Epoch 1488/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.7857\n",
      "Epoch 1489/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.7857\n",
      "Epoch 1490/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.7857\n",
      "Epoch 1491/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.9042 - val_accuracy: 0.7857\n",
      "Epoch 1492/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.7857\n",
      "Epoch 1493/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.7857\n",
      "Epoch 1494/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7857\n",
      "Epoch 1495/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.9076 - val_accuracy: 0.7857\n",
      "Epoch 1496/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.9084 - val_accuracy: 0.7857\n",
      "Epoch 1497/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7857\n",
      "Epoch 1498/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.7857\n",
      "Epoch 1499/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.7857\n",
      "Epoch 1500/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.9111 - val_accuracy: 0.7857\n",
      "Epoch 1501/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.7857\n",
      "Epoch 1502/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.7857\n",
      "Epoch 1503/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.7857\n",
      "Epoch 1504/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.9143 - val_accuracy: 0.7857\n",
      "Epoch 1505/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.7857\n",
      "Epoch 1506/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.7857\n",
      "Epoch 1507/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.7857\n",
      "Epoch 1508/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.9170 - val_accuracy: 0.7857\n",
      "Epoch 1509/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.7857\n",
      "Epoch 1510/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.7857\n",
      "Epoch 1511/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.7857\n",
      "Epoch 1512/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.9198 - val_accuracy: 0.7857\n",
      "Epoch 1513/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.7857\n",
      "Epoch 1514/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.9216 - val_accuracy: 0.7857\n",
      "Epoch 1515/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.7857\n",
      "Epoch 1516/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.9232 - val_accuracy: 0.7857\n",
      "Epoch 1517/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.7857\n",
      "Epoch 1518/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.9244 - val_accuracy: 0.7857\n",
      "Epoch 1519/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 0.7857\n",
      "Epoch 1520/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.7857\n",
      "Epoch 1521/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.7857\n",
      "Epoch 1522/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.9273 - val_accuracy: 0.7857\n",
      "Epoch 1523/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.9282 - val_accuracy: 0.7857\n",
      "Epoch 1524/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.9291 - val_accuracy: 0.7857\n",
      "Epoch 1525/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.7857\n",
      "Epoch 1526/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.7857\n",
      "Epoch 1527/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.7857\n",
      "Epoch 1528/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.7857\n",
      "Epoch 1529/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.7857\n",
      "Epoch 1530/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.9332 - val_accuracy: 0.7857\n",
      "Epoch 1531/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.7857\n",
      "Epoch 1532/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.7857\n",
      "Epoch 1533/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.7857\n",
      "Epoch 1534/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.9361 - val_accuracy: 0.7857\n",
      "Epoch 1535/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.7857\n",
      "Epoch 1536/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.7857\n",
      "Epoch 1537/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.7857\n",
      "Epoch 1538/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.7857\n",
      "Epoch 1539/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.7857\n",
      "Epoch 1540/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.9406 - val_accuracy: 0.7857\n",
      "Epoch 1541/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.9413 - val_accuracy: 0.7857\n",
      "Epoch 1542/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.7857\n",
      "Epoch 1543/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.7857\n",
      "Epoch 1544/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7857\n",
      "Epoch 1545/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.7857\n",
      "Epoch 1546/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.9451 - val_accuracy: 0.7857\n",
      "Epoch 1547/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.7857\n",
      "Epoch 1548/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.7857\n",
      "Epoch 1549/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.7857\n",
      "Epoch 1550/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.7857\n",
      "Epoch 1551/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.7857\n",
      "Epoch 1552/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.7857\n",
      "Epoch 1553/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.7857\n",
      "Epoch 1554/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.9507 - val_accuracy: 0.7857\n",
      "Epoch 1555/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.7857\n",
      "Epoch 1556/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.7857\n",
      "Epoch 1557/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.7857\n",
      "Epoch 1558/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.7857\n",
      "Epoch 1559/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.7857\n",
      "Epoch 1560/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.9553 - val_accuracy: 0.7857\n",
      "Epoch 1561/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.7857\n",
      "Epoch 1562/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.7857\n",
      "Epoch 1563/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.7857\n",
      "Epoch 1564/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7857\n",
      "Epoch 1565/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.7857\n",
      "Epoch 1566/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.9594 - val_accuracy: 0.7857\n",
      "Epoch 1567/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.7857\n",
      "Epoch 1568/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.7857\n",
      "Epoch 1569/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.7857\n",
      "Epoch 1570/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.7857\n",
      "Epoch 1571/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.7857\n",
      "Epoch 1572/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.7857\n",
      "Epoch 1573/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.7857\n",
      "Epoch 1574/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.7857\n",
      "Epoch 1575/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.7857\n",
      "Epoch 1576/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.7857\n",
      "Epoch 1577/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.7857\n",
      "Epoch 1578/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.7857\n",
      "Epoch 1579/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.7857\n",
      "Epoch 1580/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.7857\n",
      "Epoch 1581/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.9703 - val_accuracy: 0.7857\n",
      "Epoch 1582/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.7857\n",
      "Epoch 1583/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.7857\n",
      "Epoch 1584/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.7857\n",
      "Epoch 1585/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.7857\n",
      "Epoch 1586/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.7857\n",
      "Epoch 1587/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.7857\n",
      "Epoch 1588/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.7857\n",
      "Epoch 1589/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.7857\n",
      "Epoch 1590/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.7857\n",
      "Epoch 1591/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.9776 - val_accuracy: 0.7857\n",
      "Epoch 1592/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.7857\n",
      "Epoch 1593/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.7857\n",
      "Epoch 1594/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.9795 - val_accuracy: 0.7857\n",
      "Epoch 1595/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.7857\n",
      "Epoch 1596/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.9812 - val_accuracy: 0.7857\n",
      "Epoch 1597/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.7857\n",
      "Epoch 1598/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.7857\n",
      "Epoch 1599/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.7857\n",
      "Epoch 1600/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.9841 - val_accuracy: 0.7857\n",
      "Epoch 1601/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.7857\n",
      "Epoch 1602/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.7857\n",
      "Epoch 1603/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.9863 - val_accuracy: 0.7857\n",
      "Epoch 1604/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.7857\n",
      "Epoch 1605/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.9876 - val_accuracy: 0.7857\n",
      "Epoch 1606/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.7857\n",
      "Epoch 1607/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.7857\n",
      "Epoch 1608/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.7857\n",
      "Epoch 1609/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.7857\n",
      "Epoch 1610/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.7857\n",
      "Epoch 1611/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.9916 - val_accuracy: 0.7857\n",
      "Epoch 1612/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.9923 - val_accuracy: 0.7857\n",
      "Epoch 1613/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.9932 - val_accuracy: 0.7857\n",
      "Epoch 1614/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.9939 - val_accuracy: 0.7857\n",
      "Epoch 1615/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.9946 - val_accuracy: 0.7857\n",
      "Epoch 1616/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.7857\n",
      "Epoch 1617/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.7857\n",
      "Epoch 1618/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.7857\n",
      "Epoch 1619/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.7857\n",
      "Epoch 1620/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.9980 - val_accuracy: 0.7857\n",
      "Epoch 1621/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.7857\n",
      "Epoch 1622/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7857\n",
      "Epoch 1623/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0004 - val_accuracy: 0.7857\n",
      "Epoch 1624/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.7857\n",
      "Epoch 1625/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.0015 - val_accuracy: 0.7857\n",
      "Epoch 1626/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.7857\n",
      "Epoch 1627/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.7857\n",
      "Epoch 1628/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.0038 - val_accuracy: 0.7857\n",
      "Epoch 1629/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.7857\n",
      "Epoch 1630/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.0052 - val_accuracy: 0.7857\n",
      "Epoch 1631/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.7857\n",
      "Epoch 1632/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.0068 - val_accuracy: 0.7857\n",
      "Epoch 1633/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.7857\n",
      "Epoch 1634/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.7857\n",
      "Epoch 1635/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.7857\n",
      "Epoch 1636/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0094 - val_accuracy: 0.7857\n",
      "Epoch 1637/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.7857\n",
      "Epoch 1638/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.7857\n",
      "Epoch 1639/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.7857\n",
      "Epoch 1640/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.7857\n",
      "Epoch 1641/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.7857\n",
      "Epoch 1642/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.7857\n",
      "Epoch 1643/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.7857\n",
      "Epoch 1644/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.7857\n",
      "Epoch 1645/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.7857\n",
      "Epoch 1646/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.7857\n",
      "Epoch 1647/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.7857\n",
      "Epoch 1648/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.7857\n",
      "Epoch 1649/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.7857\n",
      "Epoch 1650/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.0193 - val_accuracy: 0.7857\n",
      "Epoch 1651/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.7857\n",
      "Epoch 1652/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.0209 - val_accuracy: 0.7857\n",
      "Epoch 1653/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.0216 - val_accuracy: 0.7857\n",
      "Epoch 1654/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.7857\n",
      "Epoch 1655/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.7857\n",
      "Epoch 1656/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.0238 - val_accuracy: 0.7857\n",
      "Epoch 1657/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.7857\n",
      "Epoch 1658/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.0249 - val_accuracy: 0.7857\n",
      "Epoch 1659/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.7857\n",
      "Epoch 1660/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.0261 - val_accuracy: 0.7857\n",
      "Epoch 1661/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.0268 - val_accuracy: 0.7857\n",
      "Epoch 1662/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.7857\n",
      "Epoch 1663/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.7857\n",
      "Epoch 1664/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7857\n",
      "Epoch 1665/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.7857\n",
      "Epoch 1666/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.7857\n",
      "Epoch 1667/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.7857\n",
      "Epoch 1668/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.0318 - val_accuracy: 0.7857\n",
      "Epoch 1669/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.7857\n",
      "Epoch 1670/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.0329 - val_accuracy: 0.7857\n",
      "Epoch 1671/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.0336 - val_accuracy: 0.7857\n",
      "Epoch 1672/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.0344 - val_accuracy: 0.7857\n",
      "Epoch 1673/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.7857\n",
      "Epoch 1674/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.7857\n",
      "Epoch 1675/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.0370 - val_accuracy: 0.7857\n",
      "Epoch 1676/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.7857\n",
      "Epoch 1677/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.0385 - val_accuracy: 0.7857\n",
      "Epoch 1678/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.7857\n",
      "Epoch 1679/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.0396 - val_accuracy: 0.7857\n",
      "Epoch 1680/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.7857\n",
      "Epoch 1681/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.7857\n",
      "Epoch 1682/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.7857\n",
      "Epoch 1683/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.7857\n",
      "Epoch 1684/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.0429 - val_accuracy: 0.7857\n",
      "Epoch 1685/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 0.7857\n",
      "Epoch 1686/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.7857\n",
      "Epoch 1687/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.7857\n",
      "Epoch 1688/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.0459 - val_accuracy: 0.7857\n",
      "Epoch 1689/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.7857\n",
      "Epoch 1690/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.0471 - val_accuracy: 0.7857\n",
      "Epoch 1691/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.0478 - val_accuracy: 0.7857\n",
      "Epoch 1692/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.0483 - val_accuracy: 0.7857\n",
      "Epoch 1693/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.7857\n",
      "Epoch 1694/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.7857\n",
      "Epoch 1695/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.7857\n",
      "Epoch 1696/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.7857\n",
      "Epoch 1697/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.7857\n",
      "Epoch 1698/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.7857\n",
      "Epoch 1699/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.7857\n",
      "Epoch 1700/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.0541 - val_accuracy: 0.7857\n",
      "Epoch 1701/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.0545 - val_accuracy: 0.7857\n",
      "Epoch 1702/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.7857\n",
      "Epoch 1703/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.0560 - val_accuracy: 0.7857\n",
      "Epoch 1704/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.7857\n",
      "Epoch 1705/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.7857\n",
      "Epoch 1706/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.7857\n",
      "Epoch 1707/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.7857\n",
      "Epoch 1708/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.7857\n",
      "Epoch 1709/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.7857\n",
      "Epoch 1710/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.7857\n",
      "Epoch 1711/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.0615 - val_accuracy: 0.7857\n",
      "Epoch 1712/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.7857\n",
      "Epoch 1713/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.7857\n",
      "Epoch 1714/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.7857\n",
      "Epoch 1715/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.7857\n",
      "Epoch 1716/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.0650 - val_accuracy: 0.7857\n",
      "Epoch 1717/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.7857\n",
      "Epoch 1718/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.7857\n",
      "Epoch 1719/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.7857\n",
      "Epoch 1720/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7857\n",
      "Epoch 1721/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.7857\n",
      "Epoch 1722/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.7857\n",
      "Epoch 1723/4000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.7857\n",
      "Epoch 1724/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.7857\n",
      "Epoch 1725/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.7857\n",
      "Epoch 1726/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.0717 - val_accuracy: 0.7857\n",
      "Epoch 1727/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.7857\n",
      "Epoch 1728/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.7857\n",
      "Epoch 1729/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.7857\n",
      "Epoch 1730/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.0743 - val_accuracy: 0.7857\n",
      "Epoch 1731/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.7857\n",
      "Epoch 1732/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 0.7857\n",
      "Epoch 1733/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.7857\n",
      "Epoch 1734/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.0772 - val_accuracy: 0.7857\n",
      "Epoch 1735/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.0779 - val_accuracy: 0.7857\n",
      "Epoch 1736/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.7857\n",
      "Epoch 1737/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 0.7857\n",
      "Epoch 1738/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.7857\n",
      "Epoch 1739/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.0806 - val_accuracy: 0.7857\n",
      "Epoch 1740/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.7857\n",
      "Epoch 1741/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.7857\n",
      "Epoch 1742/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.0826 - val_accuracy: 0.7857\n",
      "Epoch 1743/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.7857\n",
      "Epoch 1744/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.7857\n",
      "Epoch 1745/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.7857\n",
      "Epoch 1746/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.0854 - val_accuracy: 0.7857\n",
      "Epoch 1747/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0859 - val_accuracy: 0.7857\n",
      "Epoch 1748/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.7857\n",
      "Epoch 1749/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0872 - val_accuracy: 0.7857\n",
      "Epoch 1750/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.7857\n",
      "Epoch 1751/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.7857\n",
      "Epoch 1752/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.7857\n",
      "Epoch 1753/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.0899 - val_accuracy: 0.7857\n",
      "Epoch 1754/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.0906 - val_accuracy: 0.7857\n",
      "Epoch 1755/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.0912 - val_accuracy: 0.7857\n",
      "Epoch 1756/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7857\n",
      "Epoch 1757/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.7857\n",
      "Epoch 1758/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.7857\n",
      "Epoch 1759/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.7857\n",
      "Epoch 1760/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.0945 - val_accuracy: 0.7857\n",
      "Epoch 1761/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.7857\n",
      "Epoch 1762/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.7857\n",
      "Epoch 1763/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.0966 - val_accuracy: 0.7857\n",
      "Epoch 1764/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.7857\n",
      "Epoch 1765/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.0978 - val_accuracy: 0.7857\n",
      "Epoch 1766/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.7857\n",
      "Epoch 1767/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.7857\n",
      "Epoch 1768/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.0998 - val_accuracy: 0.7857\n",
      "Epoch 1769/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.1004 - val_accuracy: 0.7857\n",
      "Epoch 1770/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.1010 - val_accuracy: 0.7857\n",
      "Epoch 1771/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.1018 - val_accuracy: 0.7857\n",
      "Epoch 1772/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.7857\n",
      "Epoch 1773/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.7857\n",
      "Epoch 1774/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.7857\n",
      "Epoch 1775/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.7857\n",
      "Epoch 1776/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.7857\n",
      "Epoch 1777/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.7857\n",
      "Epoch 1778/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1065 - val_accuracy: 0.7857\n",
      "Epoch 1779/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.7857\n",
      "Epoch 1780/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.7857\n",
      "Epoch 1781/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.7857\n",
      "Epoch 1782/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.7857\n",
      "Epoch 1783/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.1099 - val_accuracy: 0.7857\n",
      "Epoch 1784/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.1104 - val_accuracy: 0.7857\n",
      "Epoch 1785/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.7857\n",
      "Epoch 1786/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.1117 - val_accuracy: 0.7857\n",
      "Epoch 1787/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.1123 - val_accuracy: 0.7857\n",
      "Epoch 1788/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.1129 - val_accuracy: 0.7857\n",
      "Epoch 1789/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.1136 - val_accuracy: 0.7857\n",
      "Epoch 1790/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.7857\n",
      "Epoch 1791/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.1150 - val_accuracy: 0.7857\n",
      "Epoch 1792/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.7857\n",
      "Epoch 1793/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.1164 - val_accuracy: 0.7857\n",
      "Epoch 1794/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.7857\n",
      "Epoch 1795/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.1178 - val_accuracy: 0.7857\n",
      "Epoch 1796/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.1184 - val_accuracy: 0.7857\n",
      "Epoch 1797/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.7857\n",
      "Epoch 1798/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.7857\n",
      "Epoch 1799/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.1200 - val_accuracy: 0.7857\n",
      "Epoch 1800/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.1205 - val_accuracy: 0.7857\n",
      "Epoch 1801/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.1212 - val_accuracy: 0.7857\n",
      "Epoch 1802/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.7857\n",
      "Epoch 1803/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.1228 - val_accuracy: 0.7857\n",
      "Epoch 1804/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.7857\n",
      "Epoch 1805/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.7857\n",
      "Epoch 1806/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.1249 - val_accuracy: 0.7857\n",
      "Epoch 1807/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.1256 - val_accuracy: 0.7857\n",
      "Epoch 1808/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.1261 - val_accuracy: 0.7857\n",
      "Epoch 1809/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.1267 - val_accuracy: 0.7857\n",
      "Epoch 1810/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.7857\n",
      "Epoch 1811/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.7857\n",
      "Epoch 1812/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.7857\n",
      "Epoch 1813/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7857\n",
      "Epoch 1814/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1297 - val_accuracy: 0.7857\n",
      "Epoch 1815/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.7857\n",
      "Epoch 1816/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.1310 - val_accuracy: 0.7857\n",
      "Epoch 1817/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.1317 - val_accuracy: 0.7857\n",
      "Epoch 1818/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.1324 - val_accuracy: 0.7857\n",
      "Epoch 1819/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.7857\n",
      "Epoch 1820/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.7857\n",
      "Epoch 1821/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1343 - val_accuracy: 0.7857\n",
      "Epoch 1822/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.1350 - val_accuracy: 0.7857\n",
      "Epoch 1823/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.7857\n",
      "Epoch 1824/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.1363 - val_accuracy: 0.7857\n",
      "Epoch 1825/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.1370 - val_accuracy: 0.7857\n",
      "Epoch 1826/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.7857\n",
      "Epoch 1827/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.1382 - val_accuracy: 0.7857\n",
      "Epoch 1828/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.7857\n",
      "Epoch 1829/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1393 - val_accuracy: 0.7857\n",
      "Epoch 1830/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.7857\n",
      "Epoch 1831/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.1407 - val_accuracy: 0.7857\n",
      "Epoch 1832/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.1414 - val_accuracy: 0.7857\n",
      "Epoch 1833/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.7857\n",
      "Epoch 1834/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.1427 - val_accuracy: 0.7857\n",
      "Epoch 1835/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.1435 - val_accuracy: 0.7857\n",
      "Epoch 1836/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.7857\n",
      "Epoch 1837/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1448 - val_accuracy: 0.7857\n",
      "Epoch 1838/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1454 - val_accuracy: 0.7857\n",
      "Epoch 1839/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.7857\n",
      "Epoch 1840/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.7857\n",
      "Epoch 1841/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.1471 - val_accuracy: 0.7857\n",
      "Epoch 1842/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.1476 - val_accuracy: 0.7857\n",
      "Epoch 1843/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.7857\n",
      "Epoch 1844/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.1489 - val_accuracy: 0.7857\n",
      "Epoch 1845/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.1496 - val_accuracy: 0.7857\n",
      "Epoch 1846/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.1502 - val_accuracy: 0.7857\n",
      "Epoch 1847/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.7857\n",
      "Epoch 1848/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.1515 - val_accuracy: 0.7857\n",
      "Epoch 1849/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7857\n",
      "Epoch 1850/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.1527 - val_accuracy: 0.7857\n",
      "Epoch 1851/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.7857\n",
      "Epoch 1852/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.7857\n",
      "Epoch 1853/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.1545 - val_accuracy: 0.7857\n",
      "Epoch 1854/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.7857\n",
      "Epoch 1855/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.7857\n",
      "Epoch 1856/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.7857\n",
      "Epoch 1857/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1572 - val_accuracy: 0.7857\n",
      "Epoch 1858/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.7857\n",
      "Epoch 1859/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.1583 - val_accuracy: 0.7857\n",
      "Epoch 1860/4000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.1590 - val_accuracy: 0.7857\n",
      "Epoch 1861/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.7857\n",
      "Epoch 1862/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.1603 - val_accuracy: 0.7857\n",
      "Epoch 1863/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.1609 - val_accuracy: 0.7857\n",
      "Epoch 1864/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.1615 - val_accuracy: 0.7857\n",
      "Epoch 1865/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1623 - val_accuracy: 0.7857\n",
      "Epoch 1866/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.7857\n",
      "Epoch 1867/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.7857\n",
      "Epoch 1868/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.7857\n",
      "Epoch 1869/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.7857\n",
      "Epoch 1870/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.7857\n",
      "Epoch 1871/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1658 - val_accuracy: 0.7857\n",
      "Epoch 1872/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.7857\n",
      "Epoch 1873/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.7857\n",
      "Epoch 1874/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7857\n",
      "Epoch 1875/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.1684 - val_accuracy: 0.7857\n",
      "Epoch 1876/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.7857\n",
      "Epoch 1877/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.7857\n",
      "Epoch 1878/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.7857\n",
      "Epoch 1879/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.1707 - val_accuracy: 0.7857\n",
      "Epoch 1880/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.7857\n",
      "Epoch 1881/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1719 - val_accuracy: 0.7857\n",
      "Epoch 1882/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1727 - val_accuracy: 0.7857\n",
      "Epoch 1883/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1735 - val_accuracy: 0.7857\n",
      "Epoch 1884/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.7857\n",
      "Epoch 1885/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.1748 - val_accuracy: 0.7857\n",
      "Epoch 1886/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.7857\n",
      "Epoch 1887/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.1760 - val_accuracy: 0.7857\n",
      "Epoch 1888/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.1765 - val_accuracy: 0.7857\n",
      "Epoch 1889/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.1771 - val_accuracy: 0.7857\n",
      "Epoch 1890/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.1776 - val_accuracy: 0.7857\n",
      "Epoch 1891/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.7857\n",
      "Epoch 1892/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.7857\n",
      "Epoch 1893/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.7857\n",
      "Epoch 1894/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1801 - val_accuracy: 0.7857\n",
      "Epoch 1895/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1808 - val_accuracy: 0.7857\n",
      "Epoch 1896/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1815 - val_accuracy: 0.7857\n",
      "Epoch 1897/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.7857\n",
      "Epoch 1898/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.1826 - val_accuracy: 0.7857\n",
      "Epoch 1899/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.7857\n",
      "Epoch 1900/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.7857\n",
      "Epoch 1901/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.7857\n",
      "Epoch 1902/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.7857\n",
      "Epoch 1903/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1855 - val_accuracy: 0.7857\n",
      "Epoch 1904/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.7857\n",
      "Epoch 1905/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.1869 - val_accuracy: 0.7857\n",
      "Epoch 1906/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.7857\n",
      "Epoch 1907/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.7857\n",
      "Epoch 1908/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.1888 - val_accuracy: 0.7857\n",
      "Epoch 1909/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.1893 - val_accuracy: 0.7857\n",
      "Epoch 1910/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.1898 - val_accuracy: 0.7857\n",
      "Epoch 1911/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.1904 - val_accuracy: 0.7857\n",
      "Epoch 1912/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.1911 - val_accuracy: 0.7857\n",
      "Epoch 1913/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 0.7857\n",
      "Epoch 1914/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.7857\n",
      "Epoch 1915/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.7857\n",
      "Epoch 1916/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.7857\n",
      "Epoch 1917/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.1944 - val_accuracy: 0.7857\n",
      "Epoch 1918/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.1949 - val_accuracy: 0.7857\n",
      "Epoch 1919/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.7857\n",
      "Epoch 1920/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1960 - val_accuracy: 0.7857\n",
      "Epoch 1921/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1966 - val_accuracy: 0.7857\n",
      "Epoch 1922/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.7857\n",
      "Epoch 1923/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.7857\n",
      "Epoch 1924/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.1983 - val_accuracy: 0.7857\n",
      "Epoch 1925/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.1990 - val_accuracy: 0.7857\n",
      "Epoch 1926/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.1997 - val_accuracy: 0.7857\n",
      "Epoch 1927/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.7857\n",
      "Epoch 1928/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.7857\n",
      "Epoch 1929/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.7857\n",
      "Epoch 1930/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2021 - val_accuracy: 0.7857\n",
      "Epoch 1931/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2028 - val_accuracy: 0.7857\n",
      "Epoch 1932/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2034 - val_accuracy: 0.7857\n",
      "Epoch 1933/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.7857\n",
      "Epoch 1934/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2046 - val_accuracy: 0.7857\n",
      "Epoch 1935/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.7857\n",
      "Epoch 1936/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2059 - val_accuracy: 0.7857\n",
      "Epoch 1937/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2065 - val_accuracy: 0.7857\n",
      "Epoch 1938/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2070 - val_accuracy: 0.7857\n",
      "Epoch 1939/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.7857\n",
      "Epoch 1940/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2081 - val_accuracy: 0.7857\n",
      "Epoch 1941/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 0.7857\n",
      "Epoch 1942/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2092 - val_accuracy: 0.7857\n",
      "Epoch 1943/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7857\n",
      "Epoch 1944/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2104 - val_accuracy: 0.7857\n",
      "Epoch 1945/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2111 - val_accuracy: 0.7857\n",
      "Epoch 1946/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2117 - val_accuracy: 0.7857\n",
      "Epoch 1947/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2123 - val_accuracy: 0.7857\n",
      "Epoch 1948/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2129 - val_accuracy: 0.7857\n",
      "Epoch 1949/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2136 - val_accuracy: 0.7857\n",
      "Epoch 1950/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2143 - val_accuracy: 0.7857\n",
      "Epoch 1951/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.7857\n",
      "Epoch 1952/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2153 - val_accuracy: 0.7857\n",
      "Epoch 1953/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2159 - val_accuracy: 0.7857\n",
      "Epoch 1954/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2166 - val_accuracy: 0.7857\n",
      "Epoch 1955/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.7857\n",
      "Epoch 1956/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2178 - val_accuracy: 0.7857\n",
      "Epoch 1957/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.7857\n",
      "Epoch 1958/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.7857\n",
      "Epoch 1959/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.7857\n",
      "Epoch 1960/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2202 - val_accuracy: 0.7857\n",
      "Epoch 1961/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.7857\n",
      "Epoch 1962/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2212 - val_accuracy: 0.7857\n",
      "Epoch 1963/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.2218 - val_accuracy: 0.7857\n",
      "Epoch 1964/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.7857\n",
      "Epoch 1965/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.7857\n",
      "Epoch 1966/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.7857\n",
      "Epoch 1967/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.7857\n",
      "Epoch 1968/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.7857\n",
      "Epoch 1969/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.7857\n",
      "Epoch 1970/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2262 - val_accuracy: 0.7857\n",
      "Epoch 1971/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.7857\n",
      "Epoch 1972/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.7857\n",
      "Epoch 1973/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.7857\n",
      "Epoch 1974/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2285 - val_accuracy: 0.7857\n",
      "Epoch 1975/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2291 - val_accuracy: 0.7857\n",
      "Epoch 1976/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2297 - val_accuracy: 0.7857\n",
      "Epoch 1977/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.7857\n",
      "Epoch 1978/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2310 - val_accuracy: 0.7857\n",
      "Epoch 1979/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.7857\n",
      "Epoch 1980/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2322 - val_accuracy: 0.7857\n",
      "Epoch 1981/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2328 - val_accuracy: 0.7857\n",
      "Epoch 1982/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2333 - val_accuracy: 0.7857\n",
      "Epoch 1983/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2339 - val_accuracy: 0.7857\n",
      "Epoch 1984/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.7857\n",
      "Epoch 1985/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2350 - val_accuracy: 0.7857\n",
      "Epoch 1986/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.7857\n",
      "Epoch 1987/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2363 - val_accuracy: 0.7857\n",
      "Epoch 1988/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2368 - val_accuracy: 0.7857\n",
      "Epoch 1989/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.7857\n",
      "Epoch 1990/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.7857\n",
      "Epoch 1991/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.2384 - val_accuracy: 0.7857\n",
      "Epoch 1992/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.7857\n",
      "Epoch 1993/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.7857\n",
      "Epoch 1994/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.7857\n",
      "Epoch 1995/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7857\n",
      "Epoch 1996/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.7857\n",
      "Epoch 1997/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.7857\n",
      "Epoch 1998/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2427 - val_accuracy: 0.7857\n",
      "Epoch 1999/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2433 - val_accuracy: 0.7857\n",
      "Epoch 2000/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2439 - val_accuracy: 0.7857\n",
      "Epoch 2001/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.7857\n",
      "Epoch 2002/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.7857\n",
      "Epoch 2003/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.7857\n",
      "Epoch 2004/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.2463 - val_accuracy: 0.7857\n",
      "Epoch 2005/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.7857\n",
      "Epoch 2006/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2475 - val_accuracy: 0.7857\n",
      "Epoch 2007/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.7857\n",
      "Epoch 2008/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2485 - val_accuracy: 0.7857\n",
      "Epoch 2009/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2490 - val_accuracy: 0.7857\n",
      "Epoch 2010/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.7857\n",
      "Epoch 2011/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2503 - val_accuracy: 0.7857\n",
      "Epoch 2012/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.7857\n",
      "Epoch 2013/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.7857\n",
      "Epoch 2014/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.2523 - val_accuracy: 0.7857\n",
      "Epoch 2015/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2529 - val_accuracy: 0.7857\n",
      "Epoch 2016/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.7857\n",
      "Epoch 2017/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2541 - val_accuracy: 0.7857\n",
      "Epoch 2018/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.7857\n",
      "Epoch 2019/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.7857\n",
      "Epoch 2020/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2557 - val_accuracy: 0.7857\n",
      "Epoch 2021/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2562 - val_accuracy: 0.7857\n",
      "Epoch 2022/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.7857\n",
      "Epoch 2023/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.7857\n",
      "Epoch 2024/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2577 - val_accuracy: 0.7857\n",
      "Epoch 2025/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.7857\n",
      "Epoch 2026/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.7857\n",
      "Epoch 2027/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2597 - val_accuracy: 0.7857\n",
      "Epoch 2028/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.7857\n",
      "Epoch 2029/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2610 - val_accuracy: 0.7857\n",
      "Epoch 2030/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.7857\n",
      "Epoch 2031/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.2619 - val_accuracy: 0.7857\n",
      "Epoch 2032/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.7857\n",
      "Epoch 2033/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.7857\n",
      "Epoch 2034/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.2638 - val_accuracy: 0.7857\n",
      "Epoch 2035/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.2644 - val_accuracy: 0.7857\n",
      "Epoch 2036/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.2649 - val_accuracy: 0.7857\n",
      "Epoch 2037/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.7857\n",
      "Epoch 2038/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.2661 - val_accuracy: 0.7857\n",
      "Epoch 2039/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.2667 - val_accuracy: 0.7857\n",
      "Epoch 2040/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2672 - val_accuracy: 0.7857\n",
      "Epoch 2041/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.7857\n",
      "Epoch 2042/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2683 - val_accuracy: 0.7857\n",
      "Epoch 2043/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2689 - val_accuracy: 0.7857\n",
      "Epoch 2044/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2697 - val_accuracy: 0.7857\n",
      "Epoch 2045/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2703 - val_accuracy: 0.7857\n",
      "Epoch 2046/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7857\n",
      "Epoch 2047/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2714 - val_accuracy: 0.7857\n",
      "Epoch 2048/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.2718 - val_accuracy: 0.7857\n",
      "Epoch 2049/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2723 - val_accuracy: 0.7857\n",
      "Epoch 2050/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2729 - val_accuracy: 0.7857\n",
      "Epoch 2051/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.7857\n",
      "Epoch 2052/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2741 - val_accuracy: 0.7857\n",
      "Epoch 2053/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2747 - val_accuracy: 0.7857\n",
      "Epoch 2054/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2753 - val_accuracy: 0.7857\n",
      "Epoch 2055/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.7857\n",
      "Epoch 2056/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2763 - val_accuracy: 0.7857\n",
      "Epoch 2057/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.7857\n",
      "Epoch 2058/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.2775 - val_accuracy: 0.7857\n",
      "Epoch 2059/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.2781 - val_accuracy: 0.7857\n",
      "Epoch 2060/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.2786 - val_accuracy: 0.7857\n",
      "Epoch 2061/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.2792 - val_accuracy: 0.7857\n",
      "Epoch 2062/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2799 - val_accuracy: 0.7857\n",
      "Epoch 2063/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2806 - val_accuracy: 0.7857\n",
      "Epoch 2064/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2812 - val_accuracy: 0.7857\n",
      "Epoch 2065/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.7857\n",
      "Epoch 2066/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.2823 - val_accuracy: 0.7857\n",
      "Epoch 2067/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2828 - val_accuracy: 0.7857\n",
      "Epoch 2068/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2833 - val_accuracy: 0.7857\n",
      "Epoch 2069/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2839 - val_accuracy: 0.7857\n",
      "Epoch 2070/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2845 - val_accuracy: 0.7857\n",
      "Epoch 2071/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2851 - val_accuracy: 0.7857\n",
      "Epoch 2072/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.7857\n",
      "Epoch 2073/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2862 - val_accuracy: 0.7857\n",
      "Epoch 2074/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2868 - val_accuracy: 0.7857\n",
      "Epoch 2075/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.7857\n",
      "Epoch 2076/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.2879 - val_accuracy: 0.7857\n",
      "Epoch 2077/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.7857\n",
      "Epoch 2078/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7857\n",
      "Epoch 2079/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.2894 - val_accuracy: 0.7857\n",
      "Epoch 2080/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.2900 - val_accuracy: 0.7857\n",
      "Epoch 2081/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.7857\n",
      "Epoch 2082/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2912 - val_accuracy: 0.7857\n",
      "Epoch 2083/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.7857\n",
      "Epoch 2084/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2924 - val_accuracy: 0.7857\n",
      "Epoch 2085/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2929 - val_accuracy: 0.7857\n",
      "Epoch 2086/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2935 - val_accuracy: 0.7857\n",
      "Epoch 2087/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2941 - val_accuracy: 0.7857\n",
      "Epoch 2088/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.7857\n",
      "Epoch 2089/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.7857\n",
      "Epoch 2090/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2955 - val_accuracy: 0.7857\n",
      "Epoch 2091/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.7857\n",
      "Epoch 2092/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2968 - val_accuracy: 0.7857\n",
      "Epoch 2093/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.7857\n",
      "Epoch 2094/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.7857\n",
      "Epoch 2095/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2986 - val_accuracy: 0.7857\n",
      "Epoch 2096/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2993 - val_accuracy: 0.7714\n",
      "Epoch 2097/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2999 - val_accuracy: 0.7714\n",
      "Epoch 2098/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.7714\n",
      "Epoch 2099/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.7714\n",
      "Epoch 2100/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.7714\n",
      "Epoch 2101/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3020 - val_accuracy: 0.7714\n",
      "Epoch 2102/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.7714\n",
      "Epoch 2103/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3030 - val_accuracy: 0.7714\n",
      "Epoch 2104/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.3036 - val_accuracy: 0.7714\n",
      "Epoch 2105/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3043 - val_accuracy: 0.7714\n",
      "Epoch 2106/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.7714\n",
      "Epoch 2107/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3055 - val_accuracy: 0.7714\n",
      "Epoch 2108/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.7714\n",
      "Epoch 2109/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.7714\n",
      "Epoch 2110/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3071 - val_accuracy: 0.7714\n",
      "Epoch 2111/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3076 - val_accuracy: 0.7714\n",
      "Epoch 2112/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3080 - val_accuracy: 0.7714\n",
      "Epoch 2113/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3086 - val_accuracy: 0.7714\n",
      "Epoch 2114/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3092 - val_accuracy: 0.7714\n",
      "Epoch 2115/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3099 - val_accuracy: 0.7714\n",
      "Epoch 2116/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3105 - val_accuracy: 0.7714\n",
      "Epoch 2117/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3111 - val_accuracy: 0.7714\n",
      "Epoch 2118/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.7714\n",
      "Epoch 2119/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.7714\n",
      "Epoch 2120/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.7714\n",
      "Epoch 2121/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.7714\n",
      "Epoch 2122/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3136 - val_accuracy: 0.7714\n",
      "Epoch 2123/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3141 - val_accuracy: 0.7714\n",
      "Epoch 2124/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.7714\n",
      "Epoch 2125/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3151 - val_accuracy: 0.7714\n",
      "Epoch 2126/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3157 - val_accuracy: 0.7714\n",
      "Epoch 2127/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.7714\n",
      "Epoch 2128/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3170 - val_accuracy: 0.7714\n",
      "Epoch 2129/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.3177 - val_accuracy: 0.7714\n",
      "Epoch 2130/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3183 - val_accuracy: 0.7714\n",
      "Epoch 2131/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.7714\n",
      "Epoch 2132/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3193 - val_accuracy: 0.7714\n",
      "Epoch 2133/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.7714\n",
      "Epoch 2134/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3202 - val_accuracy: 0.7714\n",
      "Epoch 2135/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.7714\n",
      "Epoch 2136/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3215 - val_accuracy: 0.7714\n",
      "Epoch 2137/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.7714\n",
      "Epoch 2138/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3226 - val_accuracy: 0.7714\n",
      "Epoch 2139/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.3232 - val_accuracy: 0.7714\n",
      "Epoch 2140/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3238 - val_accuracy: 0.7714\n",
      "Epoch 2141/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.7714\n",
      "Epoch 2142/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.7714\n",
      "Epoch 2143/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3253 - val_accuracy: 0.7714\n",
      "Epoch 2144/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.7714\n",
      "Epoch 2145/4000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3263 - val_accuracy: 0.7714\n",
      "Epoch 2146/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3268 - val_accuracy: 0.7714\n",
      "Epoch 2147/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3274 - val_accuracy: 0.7714\n",
      "Epoch 2148/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.7714\n",
      "Epoch 2149/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.7714\n",
      "Epoch 2150/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3293 - val_accuracy: 0.7714\n",
      "Epoch 2151/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3298 - val_accuracy: 0.7714\n",
      "Epoch 2152/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7714\n",
      "Epoch 2153/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.7714\n",
      "Epoch 2154/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.7714\n",
      "Epoch 2155/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.7714\n",
      "Epoch 2156/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3325 - val_accuracy: 0.7714\n",
      "Epoch 2157/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3331 - val_accuracy: 0.7714\n",
      "Epoch 2158/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3336 - val_accuracy: 0.7714\n",
      "Epoch 2159/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3341 - val_accuracy: 0.7714\n",
      "Epoch 2160/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.7714\n",
      "Epoch 2161/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3353 - val_accuracy: 0.7714\n",
      "Epoch 2162/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.7714\n",
      "Epoch 2163/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3362 - val_accuracy: 0.7714\n",
      "Epoch 2164/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3369 - val_accuracy: 0.7714\n",
      "Epoch 2165/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3376 - val_accuracy: 0.7714\n",
      "Epoch 2166/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.3381 - val_accuracy: 0.7714\n",
      "Epoch 2167/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.7714\n",
      "Epoch 2168/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3391 - val_accuracy: 0.7714\n",
      "Epoch 2169/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.7714\n",
      "Epoch 2170/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.7714\n",
      "Epoch 2171/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.3406 - val_accuracy: 0.7714\n",
      "Epoch 2172/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.7714\n",
      "Epoch 2173/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.7714\n",
      "Epoch 2174/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.7714\n",
      "Epoch 2175/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3427 - val_accuracy: 0.7714\n",
      "Epoch 2176/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.7714\n",
      "Epoch 2177/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3440 - val_accuracy: 0.7714\n",
      "Epoch 2178/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3445 - val_accuracy: 0.7714\n",
      "Epoch 2179/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3450 - val_accuracy: 0.7714\n",
      "Epoch 2180/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.7714\n",
      "Epoch 2181/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3462 - val_accuracy: 0.7714\n",
      "Epoch 2182/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.7714\n",
      "Epoch 2183/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3471 - val_accuracy: 0.7714\n",
      "Epoch 2184/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3477 - val_accuracy: 0.7714\n",
      "Epoch 2185/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.7714\n",
      "Epoch 2186/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3488 - val_accuracy: 0.7714\n",
      "Epoch 2187/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3493 - val_accuracy: 0.7714\n",
      "Epoch 2188/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.3498 - val_accuracy: 0.7714\n",
      "Epoch 2189/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.7714\n",
      "Epoch 2190/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.7714\n",
      "Epoch 2191/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3513 - val_accuracy: 0.7714\n",
      "Epoch 2192/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3518 - val_accuracy: 0.7714\n",
      "Epoch 2193/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3524 - val_accuracy: 0.7714\n",
      "Epoch 2194/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.7714\n",
      "Epoch 2195/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.7714\n",
      "Epoch 2196/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.7714\n",
      "Epoch 2197/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.7714\n",
      "Epoch 2198/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3553 - val_accuracy: 0.7714\n",
      "Epoch 2199/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3559 - val_accuracy: 0.7714\n",
      "Epoch 2200/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3565 - val_accuracy: 0.7714\n",
      "Epoch 2201/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3569 - val_accuracy: 0.7714\n",
      "Epoch 2202/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3574 - val_accuracy: 0.7714\n",
      "Epoch 2203/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.7714\n",
      "Epoch 2204/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.7714\n",
      "Epoch 2205/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3590 - val_accuracy: 0.7714\n",
      "Epoch 2206/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3596 - val_accuracy: 0.7714\n",
      "Epoch 2207/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3601 - val_accuracy: 0.7714\n",
      "Epoch 2208/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3607 - val_accuracy: 0.7714\n",
      "Epoch 2209/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.7714\n",
      "Epoch 2210/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3616 - val_accuracy: 0.7714\n",
      "Epoch 2211/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.3621 - val_accuracy: 0.7714\n",
      "Epoch 2212/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3625 - val_accuracy: 0.7714\n",
      "Epoch 2213/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3630 - val_accuracy: 0.7714\n",
      "Epoch 2214/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3637 - val_accuracy: 0.7714\n",
      "Epoch 2215/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3644 - val_accuracy: 0.7714\n",
      "Epoch 2216/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3650 - val_accuracy: 0.7714\n",
      "Epoch 2217/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3656 - val_accuracy: 0.7714\n",
      "Epoch 2218/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3662 - val_accuracy: 0.7714\n",
      "Epoch 2219/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3668 - val_accuracy: 0.7714\n",
      "Epoch 2220/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3673 - val_accuracy: 0.7714\n",
      "Epoch 2221/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.7714\n",
      "Epoch 2222/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3679 - val_accuracy: 0.7714\n",
      "Epoch 2223/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3683 - val_accuracy: 0.7714\n",
      "Epoch 2224/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3688 - val_accuracy: 0.7714\n",
      "Epoch 2225/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.7714\n",
      "Epoch 2226/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3700 - val_accuracy: 0.7714\n",
      "Epoch 2227/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3707 - val_accuracy: 0.7714\n",
      "Epoch 2228/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3714 - val_accuracy: 0.7714\n",
      "Epoch 2229/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3720 - val_accuracy: 0.7714\n",
      "Epoch 2230/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3725 - val_accuracy: 0.7714\n",
      "Epoch 2231/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3729 - val_accuracy: 0.7714\n",
      "Epoch 2232/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3733 - val_accuracy: 0.7714\n",
      "Epoch 2233/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3738 - val_accuracy: 0.7714\n",
      "Epoch 2234/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.7714\n",
      "Epoch 2235/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3748 - val_accuracy: 0.7714\n",
      "Epoch 2236/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3752 - val_accuracy: 0.7714\n",
      "Epoch 2237/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.7714\n",
      "Epoch 2238/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3764 - val_accuracy: 0.7714\n",
      "Epoch 2239/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.7714\n",
      "Epoch 2240/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.7714\n",
      "Epoch 2241/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3781 - val_accuracy: 0.7714\n",
      "Epoch 2242/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.7714\n",
      "Epoch 2243/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.7714\n",
      "Epoch 2244/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.7714\n",
      "Epoch 2245/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.7714\n",
      "Epoch 2246/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3805 - val_accuracy: 0.7714\n",
      "Epoch 2247/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.7714\n",
      "Epoch 2248/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3816 - val_accuracy: 0.7714\n",
      "Epoch 2249/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.7714\n",
      "Epoch 2250/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3829 - val_accuracy: 0.7714\n",
      "Epoch 2251/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3834 - val_accuracy: 0.7714\n",
      "Epoch 2252/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.7714\n",
      "Epoch 2253/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3845 - val_accuracy: 0.7714\n",
      "Epoch 2254/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.7714\n",
      "Epoch 2255/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3854 - val_accuracy: 0.7714\n",
      "Epoch 2256/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3859 - val_accuracy: 0.7714\n",
      "Epoch 2257/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.7714\n",
      "Epoch 2258/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.7714\n",
      "Epoch 2259/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3878 - val_accuracy: 0.7714\n",
      "Epoch 2260/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3883 - val_accuracy: 0.7714\n",
      "Epoch 2261/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3889 - val_accuracy: 0.7714\n",
      "Epoch 2262/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3894 - val_accuracy: 0.7714\n",
      "Epoch 2263/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.7714\n",
      "Epoch 2264/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3902 - val_accuracy: 0.7714\n",
      "Epoch 2265/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3907 - val_accuracy: 0.7714\n",
      "Epoch 2266/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3912 - val_accuracy: 0.7714\n",
      "Epoch 2267/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3917 - val_accuracy: 0.7714\n",
      "Epoch 2268/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3922 - val_accuracy: 0.7714\n",
      "Epoch 2269/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.7714\n",
      "Epoch 2270/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3932 - val_accuracy: 0.7714\n",
      "Epoch 2271/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3937 - val_accuracy: 0.7714\n",
      "Epoch 2272/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.7714\n",
      "Epoch 2273/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3948 - val_accuracy: 0.7714\n",
      "Epoch 2274/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.7714\n",
      "Epoch 2275/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3958 - val_accuracy: 0.7714\n",
      "Epoch 2276/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.7714\n",
      "Epoch 2277/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3967 - val_accuracy: 0.7714\n",
      "Epoch 2278/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.7714\n",
      "Epoch 2279/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.3978 - val_accuracy: 0.7714\n",
      "Epoch 2280/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3984 - val_accuracy: 0.7714\n",
      "Epoch 2281/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3988 - val_accuracy: 0.7714\n",
      "Epoch 2282/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.7714\n",
      "Epoch 2283/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.7714\n",
      "Epoch 2284/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.7714\n",
      "Epoch 2285/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.7714\n",
      "Epoch 2286/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4014 - val_accuracy: 0.7714\n",
      "Epoch 2287/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.7714\n",
      "Epoch 2288/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.7714\n",
      "Epoch 2289/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4031 - val_accuracy: 0.7714\n",
      "Epoch 2290/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4037 - val_accuracy: 0.7714\n",
      "Epoch 2291/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4042 - val_accuracy: 0.7714\n",
      "Epoch 2292/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.7714\n",
      "Epoch 2293/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4052 - val_accuracy: 0.7714\n",
      "Epoch 2294/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4057 - val_accuracy: 0.7714\n",
      "Epoch 2295/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4063 - val_accuracy: 0.7714\n",
      "Epoch 2296/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4067 - val_accuracy: 0.7714\n",
      "Epoch 2297/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4071 - val_accuracy: 0.7714\n",
      "Epoch 2298/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.7714\n",
      "Epoch 2299/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4083 - val_accuracy: 0.7714\n",
      "Epoch 2300/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.7714\n",
      "Epoch 2301/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.7714\n",
      "Epoch 2302/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4098 - val_accuracy: 0.7714\n",
      "Epoch 2303/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4102 - val_accuracy: 0.7714\n",
      "Epoch 2304/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.7714\n",
      "Epoch 2305/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4113 - val_accuracy: 0.7714\n",
      "Epoch 2306/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.7714\n",
      "Epoch 2307/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.7714\n",
      "Epoch 2308/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4129 - val_accuracy: 0.7714\n",
      "Epoch 2309/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7714\n",
      "Epoch 2310/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4138 - val_accuracy: 0.7714\n",
      "Epoch 2311/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.7714\n",
      "Epoch 2312/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.7714\n",
      "Epoch 2313/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4154 - val_accuracy: 0.7714\n",
      "Epoch 2314/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4159 - val_accuracy: 0.7714\n",
      "Epoch 2315/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4165 - val_accuracy: 0.7714\n",
      "Epoch 2316/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.7714\n",
      "Epoch 2317/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.7714\n",
      "Epoch 2318/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.7714\n",
      "Epoch 2319/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.4185 - val_accuracy: 0.7714\n",
      "Epoch 2320/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.7714\n",
      "Epoch 2321/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.7714\n",
      "Epoch 2322/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.7714\n",
      "Epoch 2323/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.7714\n",
      "Epoch 2324/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.7714\n",
      "Epoch 2325/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4215 - val_accuracy: 0.7714\n",
      "Epoch 2326/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4220 - val_accuracy: 0.7714\n",
      "Epoch 2327/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4225 - val_accuracy: 0.7714\n",
      "Epoch 2328/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.7714\n",
      "Epoch 2329/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4236 - val_accuracy: 0.7714\n",
      "Epoch 2330/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4240 - val_accuracy: 0.7714\n",
      "Epoch 2331/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.7714\n",
      "Epoch 2332/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4249 - val_accuracy: 0.7714\n",
      "Epoch 2333/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4253 - val_accuracy: 0.7714\n",
      "Epoch 2334/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4259 - val_accuracy: 0.7714\n",
      "Epoch 2335/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.7714\n",
      "Epoch 2336/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4269 - val_accuracy: 0.7714\n",
      "Epoch 2337/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.7714\n",
      "Epoch 2338/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4281 - val_accuracy: 0.7714\n",
      "Epoch 2339/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.7714\n",
      "Epoch 2340/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4291 - val_accuracy: 0.7714\n",
      "Epoch 2341/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.4295 - val_accuracy: 0.7714\n",
      "Epoch 2342/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.7714\n",
      "Epoch 2343/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4305 - val_accuracy: 0.7714\n",
      "Epoch 2344/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4310 - val_accuracy: 0.7714\n",
      "Epoch 2345/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4314 - val_accuracy: 0.7714\n",
      "Epoch 2346/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4320 - val_accuracy: 0.7714\n",
      "Epoch 2347/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.7714\n",
      "Epoch 2348/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4330 - val_accuracy: 0.7714\n",
      "Epoch 2349/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.7714\n",
      "Epoch 2350/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4340 - val_accuracy: 0.7714\n",
      "Epoch 2351/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4344 - val_accuracy: 0.7714\n",
      "Epoch 2352/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4349 - val_accuracy: 0.7714\n",
      "Epoch 2353/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4355 - val_accuracy: 0.7714\n",
      "Epoch 2354/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.7714\n",
      "Epoch 2355/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.4365 - val_accuracy: 0.7714\n",
      "Epoch 2356/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4370 - val_accuracy: 0.7714\n",
      "Epoch 2357/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4375 - val_accuracy: 0.7714\n",
      "Epoch 2358/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.7714\n",
      "Epoch 2359/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4386 - val_accuracy: 0.7714\n",
      "Epoch 2360/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4391 - val_accuracy: 0.7714\n",
      "Epoch 2361/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4396 - val_accuracy: 0.7714\n",
      "Epoch 2362/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.7714\n",
      "Epoch 2363/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4404 - val_accuracy: 0.7714\n",
      "Epoch 2364/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.7714\n",
      "Epoch 2365/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.7714\n",
      "Epoch 2366/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4420 - val_accuracy: 0.7714\n",
      "Epoch 2367/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.7714\n",
      "Epoch 2368/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4430 - val_accuracy: 0.7714\n",
      "Epoch 2369/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.7714\n",
      "Epoch 2370/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.4441 - val_accuracy: 0.7714\n",
      "Epoch 2371/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4446 - val_accuracy: 0.7714\n",
      "Epoch 2372/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4451 - val_accuracy: 0.7714\n",
      "Epoch 2373/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4456 - val_accuracy: 0.7714\n",
      "Epoch 2374/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4461 - val_accuracy: 0.7714\n",
      "Epoch 2375/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4466 - val_accuracy: 0.7714\n",
      "Epoch 2376/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.7714\n",
      "Epoch 2377/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4476 - val_accuracy: 0.7714\n",
      "Epoch 2378/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.4481 - val_accuracy: 0.7714\n",
      "Epoch 2379/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4485 - val_accuracy: 0.7714\n",
      "Epoch 2380/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4490 - val_accuracy: 0.7714\n",
      "Epoch 2381/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4494 - val_accuracy: 0.7714\n",
      "Epoch 2382/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.7714\n",
      "Epoch 2383/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4504 - val_accuracy: 0.7714\n",
      "Epoch 2384/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4510 - val_accuracy: 0.7714\n",
      "Epoch 2385/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4515 - val_accuracy: 0.7714\n",
      "Epoch 2386/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.4519 - val_accuracy: 0.7714\n",
      "Epoch 2387/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.7714\n",
      "Epoch 2388/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4529 - val_accuracy: 0.7714\n",
      "Epoch 2389/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4535 - val_accuracy: 0.7714\n",
      "Epoch 2390/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4540 - val_accuracy: 0.7714\n",
      "Epoch 2391/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4545 - val_accuracy: 0.7714\n",
      "Epoch 2392/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.7714\n",
      "Epoch 2393/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4555 - val_accuracy: 0.7714\n",
      "Epoch 2394/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4560 - val_accuracy: 0.7714\n",
      "Epoch 2395/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4564 - val_accuracy: 0.7714\n",
      "Epoch 2396/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.7857\n",
      "Epoch 2397/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4572 - val_accuracy: 0.7857\n",
      "Epoch 2398/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4577 - val_accuracy: 0.7857\n",
      "Epoch 2399/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4583 - val_accuracy: 0.7857\n",
      "Epoch 2400/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4588 - val_accuracy: 0.7857\n",
      "Epoch 2401/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4593 - val_accuracy: 0.7857\n",
      "Epoch 2402/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4599 - val_accuracy: 0.7857\n",
      "Epoch 2403/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4605 - val_accuracy: 0.7857\n",
      "Epoch 2404/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4610 - val_accuracy: 0.7857\n",
      "Epoch 2405/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4614 - val_accuracy: 0.7857\n",
      "Epoch 2406/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4617 - val_accuracy: 0.7857\n",
      "Epoch 2407/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4621 - val_accuracy: 0.7857\n",
      "Epoch 2408/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4627 - val_accuracy: 0.7857\n",
      "Epoch 2409/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4632 - val_accuracy: 0.7857\n",
      "Epoch 2410/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4638 - val_accuracy: 0.7857\n",
      "Epoch 2411/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.7857\n",
      "Epoch 2412/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4648 - val_accuracy: 0.7857\n",
      "Epoch 2413/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4653 - val_accuracy: 0.7857\n",
      "Epoch 2414/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4659 - val_accuracy: 0.7857\n",
      "Epoch 2415/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4663 - val_accuracy: 0.7857\n",
      "Epoch 2416/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4668 - val_accuracy: 0.7857\n",
      "Epoch 2417/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.7857\n",
      "Epoch 2418/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4678 - val_accuracy: 0.7857\n",
      "Epoch 2419/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4683 - val_accuracy: 0.7857\n",
      "Epoch 2420/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4688 - val_accuracy: 0.7857\n",
      "Epoch 2421/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4694 - val_accuracy: 0.7857\n",
      "Epoch 2422/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4700 - val_accuracy: 0.7857\n",
      "Epoch 2423/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4705 - val_accuracy: 0.7857\n",
      "Epoch 2424/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4710 - val_accuracy: 0.7857\n",
      "Epoch 2425/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4714 - val_accuracy: 0.7857\n",
      "Epoch 2426/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.4717 - val_accuracy: 0.7857\n",
      "Epoch 2427/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4721 - val_accuracy: 0.7857\n",
      "Epoch 2428/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4726 - val_accuracy: 0.7857\n",
      "Epoch 2429/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4731 - val_accuracy: 0.7857\n",
      "Epoch 2430/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4736 - val_accuracy: 0.7857\n",
      "Epoch 2431/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.7857\n",
      "Epoch 2432/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4746 - val_accuracy: 0.7857\n",
      "Epoch 2433/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4752 - val_accuracy: 0.7857\n",
      "Epoch 2434/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4757 - val_accuracy: 0.7857\n",
      "Epoch 2435/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4763 - val_accuracy: 0.7857\n",
      "Epoch 2436/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.7857\n",
      "Epoch 2437/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4770 - val_accuracy: 0.7857\n",
      "Epoch 2438/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4774 - val_accuracy: 0.7857\n",
      "Epoch 2439/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4778 - val_accuracy: 0.7857\n",
      "Epoch 2440/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.7857\n",
      "Epoch 2441/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4789 - val_accuracy: 0.7857\n",
      "Epoch 2442/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.7857\n",
      "Epoch 2443/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 0.7857\n",
      "Epoch 2444/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4806 - val_accuracy: 0.7857\n",
      "Epoch 2445/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4811 - val_accuracy: 0.7857\n",
      "Epoch 2446/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4817 - val_accuracy: 0.7857\n",
      "Epoch 2447/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.7857\n",
      "Epoch 2448/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4826 - val_accuracy: 0.7857\n",
      "Epoch 2449/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4830 - val_accuracy: 0.7857\n",
      "Epoch 2450/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.7857\n",
      "Epoch 2451/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4838 - val_accuracy: 0.7857\n",
      "Epoch 2452/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.7857\n",
      "Epoch 2453/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4848 - val_accuracy: 0.7857\n",
      "Epoch 2454/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4853 - val_accuracy: 0.7857\n",
      "Epoch 2455/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.7857\n",
      "Epoch 2456/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.7857\n",
      "Epoch 2457/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4867 - val_accuracy: 0.7857\n",
      "Epoch 2458/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.7857\n",
      "Epoch 2459/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.7857\n",
      "Epoch 2460/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4881 - val_accuracy: 0.7857\n",
      "Epoch 2461/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.7857\n",
      "Epoch 2462/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.7857\n",
      "Epoch 2463/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.7857\n",
      "Epoch 2464/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.7857\n",
      "Epoch 2465/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4908 - val_accuracy: 0.7857\n",
      "Epoch 2466/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.7857\n",
      "Epoch 2467/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.7857\n",
      "Epoch 2468/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4922 - val_accuracy: 0.7857\n",
      "Epoch 2469/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4927 - val_accuracy: 0.7857\n",
      "Epoch 2470/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.7857\n",
      "Epoch 2471/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.7857\n",
      "Epoch 2472/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4940 - val_accuracy: 0.7857\n",
      "Epoch 2473/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4945 - val_accuracy: 0.7857\n",
      "Epoch 2474/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4950 - val_accuracy: 0.7857\n",
      "Epoch 2475/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4955 - val_accuracy: 0.7857\n",
      "Epoch 2476/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4960 - val_accuracy: 0.7857\n",
      "Epoch 2477/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4965 - val_accuracy: 0.7857\n",
      "Epoch 2478/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4970 - val_accuracy: 0.7857\n",
      "Epoch 2479/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4975 - val_accuracy: 0.7857\n",
      "Epoch 2480/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4980 - val_accuracy: 0.7857\n",
      "Epoch 2481/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.7857\n",
      "Epoch 2482/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4989 - val_accuracy: 0.7857\n",
      "Epoch 2483/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.7857\n",
      "Epoch 2484/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.7857\n",
      "Epoch 2485/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.5003 - val_accuracy: 0.7857\n",
      "Epoch 2486/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.5008 - val_accuracy: 0.7857\n",
      "Epoch 2487/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.7857\n",
      "Epoch 2488/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5018 - val_accuracy: 0.7857\n",
      "Epoch 2489/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.7857\n",
      "Epoch 2490/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5027 - val_accuracy: 0.7857\n",
      "Epoch 2491/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5031 - val_accuracy: 0.7857\n",
      "Epoch 2492/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5036 - val_accuracy: 0.7857\n",
      "Epoch 2493/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.7857\n",
      "Epoch 2494/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5047 - val_accuracy: 0.7857\n",
      "Epoch 2495/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5052 - val_accuracy: 0.7857\n",
      "Epoch 2496/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5056 - val_accuracy: 0.7857\n",
      "Epoch 2497/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5060 - val_accuracy: 0.7857\n",
      "Epoch 2498/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5065 - val_accuracy: 0.7857\n",
      "Epoch 2499/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5071 - val_accuracy: 0.7857\n",
      "Epoch 2500/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.7857\n",
      "Epoch 2501/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5080 - val_accuracy: 0.7857\n",
      "Epoch 2502/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5085 - val_accuracy: 0.7857\n",
      "Epoch 2503/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5091 - val_accuracy: 0.7857\n",
      "Epoch 2504/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.7857\n",
      "Epoch 2505/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5102 - val_accuracy: 0.7857\n",
      "Epoch 2506/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5108 - val_accuracy: 0.7857\n",
      "Epoch 2507/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5115 - val_accuracy: 0.7857\n",
      "Epoch 2508/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5121 - val_accuracy: 0.7857\n",
      "Epoch 2509/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5127 - val_accuracy: 0.7857\n",
      "Epoch 2510/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5131 - val_accuracy: 0.7857\n",
      "Epoch 2511/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.7857\n",
      "Epoch 2512/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5139 - val_accuracy: 0.7857\n",
      "Epoch 2513/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.7857\n",
      "Epoch 2514/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.5148 - val_accuracy: 0.7857\n",
      "Epoch 2515/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5152 - val_accuracy: 0.7857\n",
      "Epoch 2516/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5158 - val_accuracy: 0.7857\n",
      "Epoch 2517/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5164 - val_accuracy: 0.7857\n",
      "Epoch 2518/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.7857\n",
      "Epoch 2519/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5174 - val_accuracy: 0.7857\n",
      "Epoch 2520/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5178 - val_accuracy: 0.7857\n",
      "Epoch 2521/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.7857\n",
      "Epoch 2522/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.7857\n",
      "Epoch 2523/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5191 - val_accuracy: 0.7857\n",
      "Epoch 2524/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.5196 - val_accuracy: 0.7857\n",
      "Epoch 2525/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5200 - val_accuracy: 0.7857\n",
      "Epoch 2526/4000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.7857\n",
      "Epoch 2527/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5211 - val_accuracy: 0.7857\n",
      "Epoch 2528/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5216 - val_accuracy: 0.7857\n",
      "Epoch 2529/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5221 - val_accuracy: 0.7857\n",
      "Epoch 2530/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5226 - val_accuracy: 0.7857\n",
      "Epoch 2531/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5232 - val_accuracy: 0.7857\n",
      "Epoch 2532/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.7857\n",
      "Epoch 2533/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5239 - val_accuracy: 0.7857\n",
      "Epoch 2534/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5243 - val_accuracy: 0.7857\n",
      "Epoch 2535/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.7857\n",
      "Epoch 2536/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5253 - val_accuracy: 0.7857\n",
      "Epoch 2537/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5258 - val_accuracy: 0.7857\n",
      "Epoch 2538/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5263 - val_accuracy: 0.7857\n",
      "Epoch 2539/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.7857\n",
      "Epoch 2540/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5273 - val_accuracy: 0.7857\n",
      "Epoch 2541/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.7857\n",
      "Epoch 2542/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5283 - val_accuracy: 0.7857\n",
      "Epoch 2543/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5288 - val_accuracy: 0.7857\n",
      "Epoch 2544/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.5293 - val_accuracy: 0.7857\n",
      "Epoch 2545/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5298 - val_accuracy: 0.7857\n",
      "Epoch 2546/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5302 - val_accuracy: 0.7857\n",
      "Epoch 2547/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5306 - val_accuracy: 0.7857\n",
      "Epoch 2548/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.7857\n",
      "Epoch 2549/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5314 - val_accuracy: 0.7857\n",
      "Epoch 2550/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5319 - val_accuracy: 0.7857\n",
      "Epoch 2551/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5324 - val_accuracy: 0.7857\n",
      "Epoch 2552/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5328 - val_accuracy: 0.7857\n",
      "Epoch 2553/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.7857\n",
      "Epoch 2554/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.7857\n",
      "Epoch 2555/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5343 - val_accuracy: 0.7857\n",
      "Epoch 2556/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5347 - val_accuracy: 0.7857\n",
      "Epoch 2557/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5351 - val_accuracy: 0.7857\n",
      "Epoch 2558/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5355 - val_accuracy: 0.7857\n",
      "Epoch 2559/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5360 - val_accuracy: 0.7857\n",
      "Epoch 2560/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.7857\n",
      "Epoch 2561/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.7857\n",
      "Epoch 2562/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5373 - val_accuracy: 0.7857\n",
      "Epoch 2563/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5379 - val_accuracy: 0.7857\n",
      "Epoch 2564/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5384 - val_accuracy: 0.7857\n",
      "Epoch 2565/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.7857\n",
      "Epoch 2566/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5394 - val_accuracy: 0.7857\n",
      "Epoch 2567/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5398 - val_accuracy: 0.7857\n",
      "Epoch 2568/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.7857\n",
      "Epoch 2569/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5406 - val_accuracy: 0.7857\n",
      "Epoch 2570/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5410 - val_accuracy: 0.7857\n",
      "Epoch 2571/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.7857\n",
      "Epoch 2572/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.7857\n",
      "Epoch 2573/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5424 - val_accuracy: 0.7857\n",
      "Epoch 2574/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5429 - val_accuracy: 0.7857\n",
      "Epoch 2575/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5434 - val_accuracy: 0.7857\n",
      "Epoch 2576/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5440 - val_accuracy: 0.7857\n",
      "Epoch 2577/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.7857\n",
      "Epoch 2578/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5449 - val_accuracy: 0.7857\n",
      "Epoch 2579/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5453 - val_accuracy: 0.7857\n",
      "Epoch 2580/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.7857\n",
      "Epoch 2581/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5462 - val_accuracy: 0.7857\n",
      "Epoch 2582/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5465 - val_accuracy: 0.7857\n",
      "Epoch 2583/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5469 - val_accuracy: 0.7857\n",
      "Epoch 2584/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5474 - val_accuracy: 0.7857\n",
      "Epoch 2585/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.7857\n",
      "Epoch 2586/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.7857\n",
      "Epoch 2587/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5488 - val_accuracy: 0.7857\n",
      "Epoch 2588/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5493 - val_accuracy: 0.7857\n",
      "Epoch 2589/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5498 - val_accuracy: 0.7857\n",
      "Epoch 2590/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5503 - val_accuracy: 0.7857\n",
      "Epoch 2591/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5507 - val_accuracy: 0.7857\n",
      "Epoch 2592/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5511 - val_accuracy: 0.7857\n",
      "Epoch 2593/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5516 - val_accuracy: 0.7857\n",
      "Epoch 2594/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5520 - val_accuracy: 0.7857\n",
      "Epoch 2595/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5524 - val_accuracy: 0.7857\n",
      "Epoch 2596/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5528 - val_accuracy: 0.7857\n",
      "Epoch 2597/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.7857\n",
      "Epoch 2598/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.7857\n",
      "Epoch 2599/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5544 - val_accuracy: 0.7857\n",
      "Epoch 2600/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5549 - val_accuracy: 0.7857\n",
      "Epoch 2601/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5554 - val_accuracy: 0.7857\n",
      "Epoch 2602/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.7857\n",
      "Epoch 2603/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.7857\n",
      "Epoch 2604/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5564 - val_accuracy: 0.7857\n",
      "Epoch 2605/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5570 - val_accuracy: 0.7857\n",
      "Epoch 2606/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5575 - val_accuracy: 0.7857\n",
      "Epoch 2607/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5580 - val_accuracy: 0.7857\n",
      "Epoch 2608/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5584 - val_accuracy: 0.7857\n",
      "Epoch 2609/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.7857\n",
      "Epoch 2610/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.7857\n",
      "Epoch 2611/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5598 - val_accuracy: 0.7857\n",
      "Epoch 2612/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.7857\n",
      "Epoch 2613/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5605 - val_accuracy: 0.7857\n",
      "Epoch 2614/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.7857\n",
      "Epoch 2615/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5615 - val_accuracy: 0.7857\n",
      "Epoch 2616/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5619 - val_accuracy: 0.7857\n",
      "Epoch 2617/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5625 - val_accuracy: 0.7857\n",
      "Epoch 2618/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5630 - val_accuracy: 0.7857\n",
      "Epoch 2619/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5635 - val_accuracy: 0.7857\n",
      "Epoch 2620/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5640 - val_accuracy: 0.7857\n",
      "Epoch 2621/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5645 - val_accuracy: 0.7857\n",
      "Epoch 2622/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5649 - val_accuracy: 0.7857\n",
      "Epoch 2623/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5653 - val_accuracy: 0.7857\n",
      "Epoch 2624/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.7857\n",
      "Epoch 2625/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.7857\n",
      "Epoch 2626/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5665 - val_accuracy: 0.7857\n",
      "Epoch 2627/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5670 - val_accuracy: 0.7857\n",
      "Epoch 2628/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.5675 - val_accuracy: 0.7857\n",
      "Epoch 2629/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5679 - val_accuracy: 0.7857\n",
      "Epoch 2630/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.7857\n",
      "Epoch 2631/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5689 - val_accuracy: 0.7857\n",
      "Epoch 2632/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5693 - val_accuracy: 0.7857\n",
      "Epoch 2633/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5697 - val_accuracy: 0.7857\n",
      "Epoch 2634/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5701 - val_accuracy: 0.7857\n",
      "Epoch 2635/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5705 - val_accuracy: 0.7857\n",
      "Epoch 2636/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5710 - val_accuracy: 0.7857\n",
      "Epoch 2637/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.7857\n",
      "Epoch 2638/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5722 - val_accuracy: 0.7857\n",
      "Epoch 2639/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5727 - val_accuracy: 0.7857\n",
      "Epoch 2640/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.7857\n",
      "Epoch 2641/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5736 - val_accuracy: 0.7857\n",
      "Epoch 2642/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5741 - val_accuracy: 0.7857\n",
      "Epoch 2643/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5745 - val_accuracy: 0.7857\n",
      "Epoch 2644/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5748 - val_accuracy: 0.7857\n",
      "Epoch 2645/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5750 - val_accuracy: 0.7857\n",
      "Epoch 2646/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.7857\n",
      "Epoch 2647/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5759 - val_accuracy: 0.7857\n",
      "Epoch 2648/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5764 - val_accuracy: 0.7857\n",
      "Epoch 2649/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5769 - val_accuracy: 0.7857\n",
      "Epoch 2650/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5776 - val_accuracy: 0.7857\n",
      "Epoch 2651/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.5781 - val_accuracy: 0.7857\n",
      "Epoch 2652/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.7857\n",
      "Epoch 2653/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5791 - val_accuracy: 0.7857\n",
      "Epoch 2654/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5796 - val_accuracy: 0.7857\n",
      "Epoch 2655/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5800 - val_accuracy: 0.7857\n",
      "Epoch 2656/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.7857\n",
      "Epoch 2657/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5806 - val_accuracy: 0.7857\n",
      "Epoch 2658/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.7857\n",
      "Epoch 2659/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.7857\n",
      "Epoch 2660/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5820 - val_accuracy: 0.7857\n",
      "Epoch 2661/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.7857\n",
      "Epoch 2662/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5829 - val_accuracy: 0.7857\n",
      "Epoch 2663/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.7857\n",
      "Epoch 2664/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.7857\n",
      "Epoch 2665/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.7857\n",
      "Epoch 2666/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.7857\n",
      "Epoch 2667/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5851 - val_accuracy: 0.7857\n",
      "Epoch 2668/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.7857\n",
      "Epoch 2669/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.7857\n",
      "Epoch 2670/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5866 - val_accuracy: 0.7857\n",
      "Epoch 2671/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.7857\n",
      "Epoch 2672/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5875 - val_accuracy: 0.7857\n",
      "Epoch 2673/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.7857\n",
      "Epoch 2674/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5884 - val_accuracy: 0.7857\n",
      "Epoch 2675/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.7857\n",
      "Epoch 2676/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.7857\n",
      "Epoch 2677/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5897 - val_accuracy: 0.7857\n",
      "Epoch 2678/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5901 - val_accuracy: 0.7857\n",
      "Epoch 2679/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5905 - val_accuracy: 0.7857\n",
      "Epoch 2680/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.7857\n",
      "Epoch 2681/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5914 - val_accuracy: 0.7857\n",
      "Epoch 2682/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5920 - val_accuracy: 0.7857\n",
      "Epoch 2683/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5925 - val_accuracy: 0.7857\n",
      "Epoch 2684/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5931 - val_accuracy: 0.7857\n",
      "Epoch 2685/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5936 - val_accuracy: 0.7857\n",
      "Epoch 2686/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5940 - val_accuracy: 0.7857\n",
      "Epoch 2687/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5943 - val_accuracy: 0.7857\n",
      "Epoch 2688/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.7857\n",
      "Epoch 2689/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.7857\n",
      "Epoch 2690/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.7857\n",
      "Epoch 2691/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5960 - val_accuracy: 0.7857\n",
      "Epoch 2692/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.7857\n",
      "Epoch 2693/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.7857\n",
      "Epoch 2694/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5975 - val_accuracy: 0.7857\n",
      "Epoch 2695/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5981 - val_accuracy: 0.7857\n",
      "Epoch 2696/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5985 - val_accuracy: 0.7857\n",
      "Epoch 2697/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5990 - val_accuracy: 0.7857\n",
      "Epoch 2698/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5994 - val_accuracy: 0.7857\n",
      "Epoch 2699/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5998 - val_accuracy: 0.7857\n",
      "Epoch 2700/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6003 - val_accuracy: 0.7857\n",
      "Epoch 2701/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6007 - val_accuracy: 0.7857\n",
      "Epoch 2702/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.7857\n",
      "Epoch 2703/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6016 - val_accuracy: 0.7857\n",
      "Epoch 2704/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6021 - val_accuracy: 0.7857\n",
      "Epoch 2705/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6026 - val_accuracy: 0.7857\n",
      "Epoch 2706/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6031 - val_accuracy: 0.7857\n",
      "Epoch 2707/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6034 - val_accuracy: 0.7857\n",
      "Epoch 2708/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6039 - val_accuracy: 0.7857\n",
      "Epoch 2709/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6044 - val_accuracy: 0.7857\n",
      "Epoch 2710/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6049 - val_accuracy: 0.7857\n",
      "Epoch 2711/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6052 - val_accuracy: 0.7857\n",
      "Epoch 2712/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6057 - val_accuracy: 0.7857\n",
      "Epoch 2713/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6061 - val_accuracy: 0.7857\n",
      "Epoch 2714/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.7857\n",
      "Epoch 2715/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6070 - val_accuracy: 0.7857\n",
      "Epoch 2716/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.7857\n",
      "Epoch 2717/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6079 - val_accuracy: 0.7857\n",
      "Epoch 2718/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6084 - val_accuracy: 0.7857\n",
      "Epoch 2719/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6089 - val_accuracy: 0.7857\n",
      "Epoch 2720/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.7857\n",
      "Epoch 2721/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6099 - val_accuracy: 0.7857\n",
      "Epoch 2722/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.7857\n",
      "Epoch 2723/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6109 - val_accuracy: 0.7857\n",
      "Epoch 2724/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6113 - val_accuracy: 0.7857\n",
      "Epoch 2725/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.6116 - val_accuracy: 0.7857\n",
      "Epoch 2726/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6121 - val_accuracy: 0.7857\n",
      "Epoch 2727/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6125 - val_accuracy: 0.7857\n",
      "Epoch 2728/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6130 - val_accuracy: 0.7857\n",
      "Epoch 2729/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6135 - val_accuracy: 0.7857\n",
      "Epoch 2730/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6140 - val_accuracy: 0.7857\n",
      "Epoch 2731/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6144 - val_accuracy: 0.7857\n",
      "Epoch 2732/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6149 - val_accuracy: 0.7857\n",
      "Epoch 2733/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6153 - val_accuracy: 0.7857\n",
      "Epoch 2734/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6158 - val_accuracy: 0.7857\n",
      "Epoch 2735/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6163 - val_accuracy: 0.7857\n",
      "Epoch 2736/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6167 - val_accuracy: 0.7857\n",
      "Epoch 2737/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6172 - val_accuracy: 0.7857\n",
      "Epoch 2738/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.6176 - val_accuracy: 0.7857\n",
      "Epoch 2739/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.7857\n",
      "Epoch 2740/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6186 - val_accuracy: 0.7857\n",
      "Epoch 2741/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.7857\n",
      "Epoch 2742/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6195 - val_accuracy: 0.7857\n",
      "Epoch 2743/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6198 - val_accuracy: 0.7857\n",
      "Epoch 2744/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6202 - val_accuracy: 0.7857\n",
      "Epoch 2745/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6207 - val_accuracy: 0.7857\n",
      "Epoch 2746/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6211 - val_accuracy: 0.7857\n",
      "Epoch 2747/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6215 - val_accuracy: 0.7857\n",
      "Epoch 2748/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6221 - val_accuracy: 0.7857\n",
      "Epoch 2749/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6227 - val_accuracy: 0.7857\n",
      "Epoch 2750/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.7857\n",
      "Epoch 2751/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.7857\n",
      "Epoch 2752/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6240 - val_accuracy: 0.7857\n",
      "Epoch 2753/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6244 - val_accuracy: 0.7857\n",
      "Epoch 2754/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6248 - val_accuracy: 0.7857\n",
      "Epoch 2755/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6252 - val_accuracy: 0.7857\n",
      "Epoch 2756/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6257 - val_accuracy: 0.7857\n",
      "Epoch 2757/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.7857\n",
      "Epoch 2758/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.7857\n",
      "Epoch 2759/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6271 - val_accuracy: 0.7857\n",
      "Epoch 2760/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6276 - val_accuracy: 0.7857\n",
      "Epoch 2761/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6281 - val_accuracy: 0.7857\n",
      "Epoch 2762/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6285 - val_accuracy: 0.7857\n",
      "Epoch 2763/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6290 - val_accuracy: 0.7857\n",
      "Epoch 2764/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6294 - val_accuracy: 0.7857\n",
      "Epoch 2765/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.7857\n",
      "Epoch 2766/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6301 - val_accuracy: 0.7857\n",
      "Epoch 2767/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6306 - val_accuracy: 0.7857\n",
      "Epoch 2768/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6310 - val_accuracy: 0.7857\n",
      "Epoch 2769/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.7857\n",
      "Epoch 2770/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6320 - val_accuracy: 0.7857\n",
      "Epoch 2771/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6326 - val_accuracy: 0.7857\n",
      "Epoch 2772/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6331 - val_accuracy: 0.7857\n",
      "Epoch 2773/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.7857\n",
      "Epoch 2774/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6340 - val_accuracy: 0.7857\n",
      "Epoch 2775/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6344 - val_accuracy: 0.7857\n",
      "Epoch 2776/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6347 - val_accuracy: 0.7857\n",
      "Epoch 2777/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.7857\n",
      "Epoch 2778/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.7857\n",
      "Epoch 2779/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6360 - val_accuracy: 0.7857\n",
      "Epoch 2780/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6365 - val_accuracy: 0.7857\n",
      "Epoch 2781/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6371 - val_accuracy: 0.7857\n",
      "Epoch 2782/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.7857\n",
      "Epoch 2783/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6381 - val_accuracy: 0.7857\n",
      "Epoch 2784/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6385 - val_accuracy: 0.7857\n",
      "Epoch 2785/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6388 - val_accuracy: 0.7857\n",
      "Epoch 2786/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6392 - val_accuracy: 0.7857\n",
      "Epoch 2787/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6396 - val_accuracy: 0.7857\n",
      "Epoch 2788/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6400 - val_accuracy: 0.7857\n",
      "Epoch 2789/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.7857\n",
      "Epoch 2790/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 0.7857\n",
      "Epoch 2791/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.7857\n",
      "Epoch 2792/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6420 - val_accuracy: 0.7857\n",
      "Epoch 2793/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.7857\n",
      "Epoch 2794/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6431 - val_accuracy: 0.7857\n",
      "Epoch 2795/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6434 - val_accuracy: 0.7857\n",
      "Epoch 2796/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6438 - val_accuracy: 0.7857\n",
      "Epoch 2797/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6442 - val_accuracy: 0.7857\n",
      "Epoch 2798/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6445 - val_accuracy: 0.7857\n",
      "Epoch 2799/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.7857\n",
      "Epoch 2800/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.7857\n",
      "Epoch 2801/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.7857\n",
      "Epoch 2802/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.7857\n",
      "Epoch 2803/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6470 - val_accuracy: 0.7857\n",
      "Epoch 2804/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.7857\n",
      "Epoch 2805/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.7857\n",
      "Epoch 2806/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.7857\n",
      "Epoch 2807/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.7857\n",
      "Epoch 2808/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6490 - val_accuracy: 0.7857\n",
      "Epoch 2809/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6493 - val_accuracy: 0.7857\n",
      "Epoch 2810/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.7857\n",
      "Epoch 2811/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.7857\n",
      "Epoch 2812/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6507 - val_accuracy: 0.7857\n",
      "Epoch 2813/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6513 - val_accuracy: 0.7857\n",
      "Epoch 2814/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6520 - val_accuracy: 0.7857\n",
      "Epoch 2815/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6525 - val_accuracy: 0.7857\n",
      "Epoch 2816/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6530 - val_accuracy: 0.7857\n",
      "Epoch 2817/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6533 - val_accuracy: 0.7857\n",
      "Epoch 2818/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.7857\n",
      "Epoch 2819/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6540 - val_accuracy: 0.7857\n",
      "Epoch 2820/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6543 - val_accuracy: 0.7857\n",
      "Epoch 2821/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6546 - val_accuracy: 0.7857\n",
      "Epoch 2822/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.6549 - val_accuracy: 0.7857\n",
      "Epoch 2823/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6555 - val_accuracy: 0.7857\n",
      "Epoch 2824/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6561 - val_accuracy: 0.7857\n",
      "Epoch 2825/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.7857\n",
      "Epoch 2826/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.7857\n",
      "Epoch 2827/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6577 - val_accuracy: 0.7857\n",
      "Epoch 2828/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6581 - val_accuracy: 0.7857\n",
      "Epoch 2829/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6585 - val_accuracy: 0.7857\n",
      "Epoch 2830/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6589 - val_accuracy: 0.7857\n",
      "Epoch 2831/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6592 - val_accuracy: 0.7857\n",
      "Epoch 2832/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6595 - val_accuracy: 0.7857\n",
      "Epoch 2833/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6600 - val_accuracy: 0.7857\n",
      "Epoch 2834/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.7857\n",
      "Epoch 2835/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6612 - val_accuracy: 0.7857\n",
      "Epoch 2836/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6617 - val_accuracy: 0.7857\n",
      "Epoch 2837/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6622 - val_accuracy: 0.7857\n",
      "Epoch 2838/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6628 - val_accuracy: 0.7857\n",
      "Epoch 2839/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6632 - val_accuracy: 0.7857\n",
      "Epoch 2840/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.7857\n",
      "Epoch 2841/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6637 - val_accuracy: 0.7857\n",
      "Epoch 2842/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6640 - val_accuracy: 0.7857\n",
      "Epoch 2843/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6644 - val_accuracy: 0.7857\n",
      "Epoch 2844/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.7857\n",
      "Epoch 2845/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.7857\n",
      "Epoch 2846/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.7857\n",
      "Epoch 2847/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6663 - val_accuracy: 0.7857\n",
      "Epoch 2848/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6669 - val_accuracy: 0.7857\n",
      "Epoch 2849/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.7857\n",
      "Epoch 2850/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6680 - val_accuracy: 0.7857\n",
      "Epoch 2851/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6683 - val_accuracy: 0.7857\n",
      "Epoch 2852/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6687 - val_accuracy: 0.7857\n",
      "Epoch 2853/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6690 - val_accuracy: 0.7857\n",
      "Epoch 2854/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6693 - val_accuracy: 0.7857\n",
      "Epoch 2855/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6697 - val_accuracy: 0.7857\n",
      "Epoch 2856/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.7857\n",
      "Epoch 2857/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6706 - val_accuracy: 0.7857\n",
      "Epoch 2858/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6711 - val_accuracy: 0.7857\n",
      "Epoch 2859/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6716 - val_accuracy: 0.7857\n",
      "Epoch 2860/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6723 - val_accuracy: 0.7857\n",
      "Epoch 2861/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6728 - val_accuracy: 0.7857\n",
      "Epoch 2862/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6731 - val_accuracy: 0.7857\n",
      "Epoch 2863/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6733 - val_accuracy: 0.7857\n",
      "Epoch 2864/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6737 - val_accuracy: 0.7857\n",
      "Epoch 2865/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.7857\n",
      "Epoch 2866/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6745 - val_accuracy: 0.7857\n",
      "Epoch 2867/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6750 - val_accuracy: 0.7857\n",
      "Epoch 2868/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.6757 - val_accuracy: 0.7857\n",
      "Epoch 2869/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6763 - val_accuracy: 0.7857\n",
      "Epoch 2870/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6768 - val_accuracy: 0.7857\n",
      "Epoch 2871/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6773 - val_accuracy: 0.7857\n",
      "Epoch 2872/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.7857\n",
      "Epoch 2873/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6779 - val_accuracy: 0.7857\n",
      "Epoch 2874/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6783 - val_accuracy: 0.7857\n",
      "Epoch 2875/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.7857\n",
      "Epoch 2876/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6791 - val_accuracy: 0.7857\n",
      "Epoch 2877/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6795 - val_accuracy: 0.7857\n",
      "Epoch 2878/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6800 - val_accuracy: 0.7857\n",
      "Epoch 2879/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6804 - val_accuracy: 0.7857\n",
      "Epoch 2880/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.7857\n",
      "Epoch 2881/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6815 - val_accuracy: 0.7857\n",
      "Epoch 2882/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6820 - val_accuracy: 0.7857\n",
      "Epoch 2883/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6823 - val_accuracy: 0.7857\n",
      "Epoch 2884/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6827 - val_accuracy: 0.7857\n",
      "Epoch 2885/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6831 - val_accuracy: 0.7857\n",
      "Epoch 2886/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6836 - val_accuracy: 0.7857\n",
      "Epoch 2887/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6840 - val_accuracy: 0.7857\n",
      "Epoch 2888/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6844 - val_accuracy: 0.7857\n",
      "Epoch 2889/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6848 - val_accuracy: 0.7857\n",
      "Epoch 2890/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6852 - val_accuracy: 0.7857\n",
      "Epoch 2891/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6857 - val_accuracy: 0.7857\n",
      "Epoch 2892/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6862 - val_accuracy: 0.7857\n",
      "Epoch 2893/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.7857\n",
      "Epoch 2894/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6869 - val_accuracy: 0.7857\n",
      "Epoch 2895/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6873 - val_accuracy: 0.7857\n",
      "Epoch 2896/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6877 - val_accuracy: 0.7857\n",
      "Epoch 2897/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6882 - val_accuracy: 0.7857\n",
      "Epoch 2898/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6887 - val_accuracy: 0.7857\n",
      "Epoch 2899/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6892 - val_accuracy: 0.7857\n",
      "Epoch 2900/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6895 - val_accuracy: 0.7857\n",
      "Epoch 2901/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.6899 - val_accuracy: 0.7857\n",
      "Epoch 2902/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6905 - val_accuracy: 0.7857\n",
      "Epoch 2903/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6909 - val_accuracy: 0.7857\n",
      "Epoch 2904/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6913 - val_accuracy: 0.7857\n",
      "Epoch 2905/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6917 - val_accuracy: 0.7857\n",
      "Epoch 2906/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6921 - val_accuracy: 0.7857\n",
      "Epoch 2907/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6927 - val_accuracy: 0.7857\n",
      "Epoch 2908/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6933 - val_accuracy: 0.7857\n",
      "Epoch 2909/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6937 - val_accuracy: 0.7857\n",
      "Epoch 2910/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6940 - val_accuracy: 0.7857\n",
      "Epoch 2911/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6944 - val_accuracy: 0.7857\n",
      "Epoch 2912/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6948 - val_accuracy: 0.7857\n",
      "Epoch 2913/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6952 - val_accuracy: 0.7857\n",
      "Epoch 2914/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.7857\n",
      "Epoch 2915/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.7857\n",
      "Epoch 2916/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6965 - val_accuracy: 0.7857\n",
      "Epoch 2917/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.7857\n",
      "Epoch 2918/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.7857\n",
      "Epoch 2919/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6978 - val_accuracy: 0.7857\n",
      "Epoch 2920/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6983 - val_accuracy: 0.7857\n",
      "Epoch 2921/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.7857\n",
      "Epoch 2922/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6992 - val_accuracy: 0.7857\n",
      "Epoch 2923/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6995 - val_accuracy: 0.7857\n",
      "Epoch 2924/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.6999 - val_accuracy: 0.7857\n",
      "Epoch 2925/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.7857\n",
      "Epoch 2926/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.7857\n",
      "Epoch 2927/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7013 - val_accuracy: 0.7857\n",
      "Epoch 2928/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7017 - val_accuracy: 0.7857\n",
      "Epoch 2929/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7021 - val_accuracy: 0.7857\n",
      "Epoch 2930/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7025 - val_accuracy: 0.7857\n",
      "Epoch 2931/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.7857\n",
      "Epoch 2932/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.7857\n",
      "Epoch 2933/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.7857\n",
      "Epoch 2934/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7042 - val_accuracy: 0.7857\n",
      "Epoch 2935/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.7046 - val_accuracy: 0.7857\n",
      "Epoch 2936/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.7857\n",
      "Epoch 2937/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7056 - val_accuracy: 0.7857\n",
      "Epoch 2938/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7060 - val_accuracy: 0.7857\n",
      "Epoch 2939/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7065 - val_accuracy: 0.7857\n",
      "Epoch 2940/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.7857\n",
      "Epoch 2941/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7073 - val_accuracy: 0.7857\n",
      "Epoch 2942/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7077 - val_accuracy: 0.7857\n",
      "Epoch 2943/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7080 - val_accuracy: 0.7857\n",
      "Epoch 2944/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7084 - val_accuracy: 0.7857\n",
      "Epoch 2945/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.7857\n",
      "Epoch 2946/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7094 - val_accuracy: 0.7857\n",
      "Epoch 2947/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7099 - val_accuracy: 0.7857\n",
      "Epoch 2948/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7105 - val_accuracy: 0.7857\n",
      "Epoch 2949/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7110 - val_accuracy: 0.7857\n",
      "Epoch 2950/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7113 - val_accuracy: 0.7857\n",
      "Epoch 2951/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7116 - val_accuracy: 0.7857\n",
      "Epoch 2952/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7120 - val_accuracy: 0.7857\n",
      "Epoch 2953/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7125 - val_accuracy: 0.7857\n",
      "Epoch 2954/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.7857\n",
      "Epoch 2955/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7132 - val_accuracy: 0.7857\n",
      "Epoch 2956/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.7857\n",
      "Epoch 2957/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.7857\n",
      "Epoch 2958/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7146 - val_accuracy: 0.7857\n",
      "Epoch 2959/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7152 - val_accuracy: 0.7857\n",
      "Epoch 2960/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7155 - val_accuracy: 0.7857\n",
      "Epoch 2961/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.7857\n",
      "Epoch 2962/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7164 - val_accuracy: 0.7857\n",
      "Epoch 2963/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.7857\n",
      "Epoch 2964/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7172 - val_accuracy: 0.7857\n",
      "Epoch 2965/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7176 - val_accuracy: 0.7857\n",
      "Epoch 2966/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7179 - val_accuracy: 0.7857\n",
      "Epoch 2967/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7184 - val_accuracy: 0.7857\n",
      "Epoch 2968/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7189 - val_accuracy: 0.7857\n",
      "Epoch 2969/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.7857\n",
      "Epoch 2970/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7197 - val_accuracy: 0.7857\n",
      "Epoch 2971/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.7201 - val_accuracy: 0.7857\n",
      "Epoch 2972/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.7857\n",
      "Epoch 2973/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7210 - val_accuracy: 0.7857\n",
      "Epoch 2974/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.7857\n",
      "Epoch 2975/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7218 - val_accuracy: 0.7857\n",
      "Epoch 2976/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7222 - val_accuracy: 0.7857\n",
      "Epoch 2977/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.7857\n",
      "Epoch 2978/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7230 - val_accuracy: 0.7857\n",
      "Epoch 2979/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7236 - val_accuracy: 0.7857\n",
      "Epoch 2980/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7241 - val_accuracy: 0.7857\n",
      "Epoch 2981/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7246 - val_accuracy: 0.7857\n",
      "Epoch 2982/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7250 - val_accuracy: 0.7857\n",
      "Epoch 2983/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7253 - val_accuracy: 0.7857\n",
      "Epoch 2984/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7257 - val_accuracy: 0.7857\n",
      "Epoch 2985/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7261 - val_accuracy: 0.7857\n",
      "Epoch 2986/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7266 - val_accuracy: 0.7857\n",
      "Epoch 2987/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7270 - val_accuracy: 0.7857\n",
      "Epoch 2988/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7273 - val_accuracy: 0.7857\n",
      "Epoch 2989/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7276 - val_accuracy: 0.7857\n",
      "Epoch 2990/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7281 - val_accuracy: 0.7857\n",
      "Epoch 2991/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7287 - val_accuracy: 0.7857\n",
      "Epoch 2992/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7292 - val_accuracy: 0.7857\n",
      "Epoch 2993/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7295 - val_accuracy: 0.7857\n",
      "Epoch 2994/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7299 - val_accuracy: 0.7857\n",
      "Epoch 2995/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7303 - val_accuracy: 0.7857\n",
      "Epoch 2996/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.7857\n",
      "Epoch 2997/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7312 - val_accuracy: 0.7857\n",
      "Epoch 2998/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7317 - val_accuracy: 0.7857\n",
      "Epoch 2999/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.7857\n",
      "Epoch 3000/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7325 - val_accuracy: 0.7857\n",
      "Epoch 3001/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7329 - val_accuracy: 0.7857\n",
      "Epoch 3002/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7333 - val_accuracy: 0.7857\n",
      "Epoch 3003/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7338 - val_accuracy: 0.7857\n",
      "Epoch 3004/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7342 - val_accuracy: 0.7857\n",
      "Epoch 3005/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7345 - val_accuracy: 0.7857\n",
      "Epoch 3006/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7349 - val_accuracy: 0.7857\n",
      "Epoch 3007/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.7857\n",
      "Epoch 3008/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7358 - val_accuracy: 0.7857\n",
      "Epoch 3009/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7362 - val_accuracy: 0.7857\n",
      "Epoch 3010/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7367 - val_accuracy: 0.7857\n",
      "Epoch 3011/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.7857\n",
      "Epoch 3012/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.7857\n",
      "Epoch 3013/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7380 - val_accuracy: 0.7857\n",
      "Epoch 3014/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.7857\n",
      "Epoch 3015/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7387 - val_accuracy: 0.7857\n",
      "Epoch 3016/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7391 - val_accuracy: 0.7857\n",
      "Epoch 3017/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7395 - val_accuracy: 0.7857\n",
      "Epoch 3018/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7399 - val_accuracy: 0.7857\n",
      "Epoch 3019/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.7857\n",
      "Epoch 3020/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7409 - val_accuracy: 0.7857\n",
      "Epoch 3021/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7412 - val_accuracy: 0.7857\n",
      "Epoch 3022/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7416 - val_accuracy: 0.7857\n",
      "Epoch 3023/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7421 - val_accuracy: 0.7857\n",
      "Epoch 3024/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7425 - val_accuracy: 0.7857\n",
      "Epoch 3025/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.7857\n",
      "Epoch 3026/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7434 - val_accuracy: 0.7857\n",
      "Epoch 3027/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7438 - val_accuracy: 0.7857\n",
      "Epoch 3028/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7442 - val_accuracy: 0.7857\n",
      "Epoch 3029/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7447 - val_accuracy: 0.7857\n",
      "Epoch 3030/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7451 - val_accuracy: 0.7857\n",
      "Epoch 3031/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7455 - val_accuracy: 0.7857\n",
      "Epoch 3032/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7459 - val_accuracy: 0.7857\n",
      "Epoch 3033/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7463 - val_accuracy: 0.7857\n",
      "Epoch 3034/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.7857\n",
      "Epoch 3035/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.7857\n",
      "Epoch 3036/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7476 - val_accuracy: 0.7857\n",
      "Epoch 3037/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7480 - val_accuracy: 0.7857\n",
      "Epoch 3038/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7484 - val_accuracy: 0.7857\n",
      "Epoch 3039/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7489 - val_accuracy: 0.7857\n",
      "Epoch 3040/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7493 - val_accuracy: 0.7857\n",
      "Epoch 3041/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7497 - val_accuracy: 0.7857\n",
      "Epoch 3042/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7501 - val_accuracy: 0.7857\n",
      "Epoch 3043/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7506 - val_accuracy: 0.7857\n",
      "Epoch 3044/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7511 - val_accuracy: 0.7857\n",
      "Epoch 3045/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7514 - val_accuracy: 0.7857\n",
      "Epoch 3046/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7517 - val_accuracy: 0.7857\n",
      "Epoch 3047/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.7857\n",
      "Epoch 3048/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7525 - val_accuracy: 0.7857\n",
      "Epoch 3049/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7530 - val_accuracy: 0.7857\n",
      "Epoch 3050/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7857\n",
      "Epoch 3051/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.7857\n",
      "Epoch 3052/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7545 - val_accuracy: 0.7857\n",
      "Epoch 3053/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.7857\n",
      "Epoch 3054/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7557 - val_accuracy: 0.7857\n",
      "Epoch 3055/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7562 - val_accuracy: 0.7857\n",
      "Epoch 3056/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7568 - val_accuracy: 0.7857\n",
      "Epoch 3057/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7571 - val_accuracy: 0.7857\n",
      "Epoch 3058/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7574 - val_accuracy: 0.7857\n",
      "Epoch 3059/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7578 - val_accuracy: 0.7857\n",
      "Epoch 3060/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7582 - val_accuracy: 0.7857\n",
      "Epoch 3061/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7587 - val_accuracy: 0.7857\n",
      "Epoch 3062/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7591 - val_accuracy: 0.7857\n",
      "Epoch 3063/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7595 - val_accuracy: 0.7857\n",
      "Epoch 3064/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7599 - val_accuracy: 0.7857\n",
      "Epoch 3065/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7604 - val_accuracy: 0.7857\n",
      "Epoch 3066/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7609 - val_accuracy: 0.7857\n",
      "Epoch 3067/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7614 - val_accuracy: 0.7857\n",
      "Epoch 3068/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7618 - val_accuracy: 0.7857\n",
      "Epoch 3069/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.7620 - val_accuracy: 0.7857\n",
      "Epoch 3070/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7624 - val_accuracy: 0.7857\n",
      "Epoch 3071/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7629 - val_accuracy: 0.7857\n",
      "Epoch 3072/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7633 - val_accuracy: 0.7857\n",
      "Epoch 3073/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7637 - val_accuracy: 0.7857\n",
      "Epoch 3074/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7640 - val_accuracy: 0.7857\n",
      "Epoch 3075/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7644 - val_accuracy: 0.7857\n",
      "Epoch 3076/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7650 - val_accuracy: 0.7857\n",
      "Epoch 3077/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7654 - val_accuracy: 0.7857\n",
      "Epoch 3078/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7658 - val_accuracy: 0.7857\n",
      "Epoch 3079/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7662 - val_accuracy: 0.7857\n",
      "Epoch 3080/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7665 - val_accuracy: 0.7857\n",
      "Epoch 3081/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7670 - val_accuracy: 0.7857\n",
      "Epoch 3082/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.7857\n",
      "Epoch 3083/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7679 - val_accuracy: 0.7857\n",
      "Epoch 3084/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7682 - val_accuracy: 0.7857\n",
      "Epoch 3085/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7686 - val_accuracy: 0.7857\n",
      "Epoch 3086/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7690 - val_accuracy: 0.7857\n",
      "Epoch 3087/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7695 - val_accuracy: 0.7857\n",
      "Epoch 3088/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.7857\n",
      "Epoch 3089/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7704 - val_accuracy: 0.7857\n",
      "Epoch 3090/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.7708 - val_accuracy: 0.7857\n",
      "Epoch 3091/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7711 - val_accuracy: 0.7857\n",
      "Epoch 3092/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7715 - val_accuracy: 0.7857\n",
      "Epoch 3093/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7720 - val_accuracy: 0.7857\n",
      "Epoch 3094/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7725 - val_accuracy: 0.7857\n",
      "Epoch 3095/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7729 - val_accuracy: 0.7857\n",
      "Epoch 3096/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7733 - val_accuracy: 0.7857\n",
      "Epoch 3097/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7737 - val_accuracy: 0.7857\n",
      "Epoch 3098/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7742 - val_accuracy: 0.7857\n",
      "Epoch 3099/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7747 - val_accuracy: 0.7857\n",
      "Epoch 3100/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7751 - val_accuracy: 0.7857\n",
      "Epoch 3101/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7755 - val_accuracy: 0.7857\n",
      "Epoch 3102/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7759 - val_accuracy: 0.7857\n",
      "Epoch 3103/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7763 - val_accuracy: 0.7857\n",
      "Epoch 3104/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.7857\n",
      "Epoch 3105/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7771 - val_accuracy: 0.7857\n",
      "Epoch 3106/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.7857\n",
      "Epoch 3107/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7778 - val_accuracy: 0.7857\n",
      "Epoch 3108/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7782 - val_accuracy: 0.7857\n",
      "Epoch 3109/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7787 - val_accuracy: 0.7857\n",
      "Epoch 3110/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7791 - val_accuracy: 0.7857\n",
      "Epoch 3111/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7794 - val_accuracy: 0.7857\n",
      "Epoch 3112/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7798 - val_accuracy: 0.7857\n",
      "Epoch 3113/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.7857\n",
      "Epoch 3114/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7808 - val_accuracy: 0.7857\n",
      "Epoch 3115/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7813 - val_accuracy: 0.7857\n",
      "Epoch 3116/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.7857\n",
      "Epoch 3117/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7820 - val_accuracy: 0.7857\n",
      "Epoch 3118/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7824 - val_accuracy: 0.7857\n",
      "Epoch 3119/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.7857\n",
      "Epoch 3120/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7833 - val_accuracy: 0.7857\n",
      "Epoch 3121/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7837 - val_accuracy: 0.7857\n",
      "Epoch 3122/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7840 - val_accuracy: 0.7857\n",
      "Epoch 3123/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7844 - val_accuracy: 0.7857\n",
      "Epoch 3124/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7848 - val_accuracy: 0.7857\n",
      "Epoch 3125/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7853 - val_accuracy: 0.7857\n",
      "Epoch 3126/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7858 - val_accuracy: 0.7857\n",
      "Epoch 3127/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7863 - val_accuracy: 0.7857\n",
      "Epoch 3128/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7867 - val_accuracy: 0.7857\n",
      "Epoch 3129/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7871 - val_accuracy: 0.7857\n",
      "Epoch 3130/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.7857\n",
      "Epoch 3131/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7879 - val_accuracy: 0.7857\n",
      "Epoch 3132/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7883 - val_accuracy: 0.7857\n",
      "Epoch 3133/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7886 - val_accuracy: 0.7857\n",
      "Epoch 3134/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7890 - val_accuracy: 0.7857\n",
      "Epoch 3135/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7895 - val_accuracy: 0.7857\n",
      "Epoch 3136/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7900 - val_accuracy: 0.7857\n",
      "Epoch 3137/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.7857\n",
      "Epoch 3138/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7909 - val_accuracy: 0.7857\n",
      "Epoch 3139/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7912 - val_accuracy: 0.7857\n",
      "Epoch 3140/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7915 - val_accuracy: 0.7857\n",
      "Epoch 3141/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7919 - val_accuracy: 0.7857\n",
      "Epoch 3142/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7922 - val_accuracy: 0.7857\n",
      "Epoch 3143/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 0.7857\n",
      "Epoch 3144/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.7857\n",
      "Epoch 3145/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.7857\n",
      "Epoch 3146/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.7857\n",
      "Epoch 3147/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7943 - val_accuracy: 0.7857\n",
      "Epoch 3148/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7948 - val_accuracy: 0.7857\n",
      "Epoch 3149/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.7857\n",
      "Epoch 3150/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.7857\n",
      "Epoch 3151/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.7857\n",
      "Epoch 3152/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7964 - val_accuracy: 0.7857\n",
      "Epoch 3153/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7968 - val_accuracy: 0.7857\n",
      "Epoch 3154/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7971 - val_accuracy: 0.7857\n",
      "Epoch 3155/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7976 - val_accuracy: 0.7857\n",
      "Epoch 3156/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7981 - val_accuracy: 0.7857\n",
      "Epoch 3157/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.7985 - val_accuracy: 0.7857\n",
      "Epoch 3158/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7990 - val_accuracy: 0.7857\n",
      "Epoch 3159/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 0.7857\n",
      "Epoch 3160/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.7998 - val_accuracy: 0.7857\n",
      "Epoch 3161/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8002 - val_accuracy: 0.7857\n",
      "Epoch 3162/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8006 - val_accuracy: 0.7857\n",
      "Epoch 3163/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8010 - val_accuracy: 0.7857\n",
      "Epoch 3164/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8014 - val_accuracy: 0.7857\n",
      "Epoch 3165/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8017 - val_accuracy: 0.7857\n",
      "Epoch 3166/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8022 - val_accuracy: 0.7857\n",
      "Epoch 3167/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8026 - val_accuracy: 0.7857\n",
      "Epoch 3168/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.7857\n",
      "Epoch 3169/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.7857\n",
      "Epoch 3170/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.7857\n",
      "Epoch 3171/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8044 - val_accuracy: 0.7857\n",
      "Epoch 3172/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8048 - val_accuracy: 0.7857\n",
      "Epoch 3173/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.7857\n",
      "Epoch 3174/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8055 - val_accuracy: 0.7857\n",
      "Epoch 3175/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8059 - val_accuracy: 0.7857\n",
      "Epoch 3176/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8062 - val_accuracy: 0.7857\n",
      "Epoch 3177/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.7857\n",
      "Epoch 3178/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8069 - val_accuracy: 0.7857\n",
      "Epoch 3179/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8074 - val_accuracy: 0.7857\n",
      "Epoch 3180/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8079 - val_accuracy: 0.7857\n",
      "Epoch 3181/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.7857\n",
      "Epoch 3182/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8087 - val_accuracy: 0.7857\n",
      "Epoch 3183/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8090 - val_accuracy: 0.7857\n",
      "Epoch 3184/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8094 - val_accuracy: 0.7857\n",
      "Epoch 3185/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8099 - val_accuracy: 0.7857\n",
      "Epoch 3186/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8103 - val_accuracy: 0.7857\n",
      "Epoch 3187/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8108 - val_accuracy: 0.7857\n",
      "Epoch 3188/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8112 - val_accuracy: 0.7857\n",
      "Epoch 3189/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8117 - val_accuracy: 0.7857\n",
      "Epoch 3190/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8121 - val_accuracy: 0.7857\n",
      "Epoch 3191/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8125 - val_accuracy: 0.7857\n",
      "Epoch 3192/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8129 - val_accuracy: 0.7857\n",
      "Epoch 3193/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.7857\n",
      "Epoch 3194/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8136 - val_accuracy: 0.7857\n",
      "Epoch 3195/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8138 - val_accuracy: 0.7857\n",
      "Epoch 3196/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8143 - val_accuracy: 0.7857\n",
      "Epoch 3197/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.7857\n",
      "Epoch 3198/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8152 - val_accuracy: 0.7857\n",
      "Epoch 3199/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8156 - val_accuracy: 0.7857\n",
      "Epoch 3200/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8160 - val_accuracy: 0.7857\n",
      "Epoch 3201/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8165 - val_accuracy: 0.7857\n",
      "Epoch 3202/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8171 - val_accuracy: 0.7857\n",
      "Epoch 3203/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8175 - val_accuracy: 0.7857\n",
      "Epoch 3204/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.7857\n",
      "Epoch 3205/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.8181 - val_accuracy: 0.7857\n",
      "Epoch 3206/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8184 - val_accuracy: 0.7857\n",
      "Epoch 3207/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8188 - val_accuracy: 0.7857\n",
      "Epoch 3208/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8191 - val_accuracy: 0.7857\n",
      "Epoch 3209/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.7857\n",
      "Epoch 3210/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8199 - val_accuracy: 0.7857\n",
      "Epoch 3211/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8204 - val_accuracy: 0.7857\n",
      "Epoch 3212/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8208 - val_accuracy: 0.7857\n",
      "Epoch 3213/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8213 - val_accuracy: 0.7857\n",
      "Epoch 3214/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.7857\n",
      "Epoch 3215/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8221 - val_accuracy: 0.7857\n",
      "Epoch 3216/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8225 - val_accuracy: 0.7857\n",
      "Epoch 3217/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8229 - val_accuracy: 0.7857\n",
      "Epoch 3218/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.7857\n",
      "Epoch 3219/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8237 - val_accuracy: 0.7857\n",
      "Epoch 3220/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.7857\n",
      "Epoch 3221/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8245 - val_accuracy: 0.7857\n",
      "Epoch 3222/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8249 - val_accuracy: 0.7857\n",
      "Epoch 3223/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8254 - val_accuracy: 0.7857\n",
      "Epoch 3224/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8259 - val_accuracy: 0.7857\n",
      "Epoch 3225/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.7857\n",
      "Epoch 3226/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8266 - val_accuracy: 0.7857\n",
      "Epoch 3227/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8269 - val_accuracy: 0.7857\n",
      "Epoch 3228/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 0.7857\n",
      "Epoch 3229/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8276 - val_accuracy: 0.7857\n",
      "Epoch 3230/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8281 - val_accuracy: 0.7857\n",
      "Epoch 3231/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8284 - val_accuracy: 0.7857\n",
      "Epoch 3232/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8289 - val_accuracy: 0.7857\n",
      "Epoch 3233/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8294 - val_accuracy: 0.7857\n",
      "Epoch 3234/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8299 - val_accuracy: 0.7857\n",
      "Epoch 3235/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8305 - val_accuracy: 0.7857\n",
      "Epoch 3236/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8309 - val_accuracy: 0.7857\n",
      "Epoch 3237/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8312 - val_accuracy: 0.7857\n",
      "Epoch 3238/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8315 - val_accuracy: 0.7857\n",
      "Epoch 3239/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8318 - val_accuracy: 0.7857\n",
      "Epoch 3240/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8321 - val_accuracy: 0.7857\n",
      "Epoch 3241/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8325 - val_accuracy: 0.7857\n",
      "Epoch 3242/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8329 - val_accuracy: 0.7857\n",
      "Epoch 3243/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8334 - val_accuracy: 0.7857\n",
      "Epoch 3244/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8338 - val_accuracy: 0.7857\n",
      "Epoch 3245/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8343 - val_accuracy: 0.7857\n",
      "Epoch 3246/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8348 - val_accuracy: 0.7857\n",
      "Epoch 3247/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8353 - val_accuracy: 0.7857\n",
      "Epoch 3248/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8357 - val_accuracy: 0.7857\n",
      "Epoch 3249/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8360 - val_accuracy: 0.7857\n",
      "Epoch 3250/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8363 - val_accuracy: 0.7857\n",
      "Epoch 3251/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8366 - val_accuracy: 0.7857\n",
      "Epoch 3252/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8369 - val_accuracy: 0.7857\n",
      "Epoch 3253/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.7857\n",
      "Epoch 3254/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8378 - val_accuracy: 0.7857\n",
      "Epoch 3255/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8383 - val_accuracy: 0.7857\n",
      "Epoch 3256/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8388 - val_accuracy: 0.7857\n",
      "Epoch 3257/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8392 - val_accuracy: 0.7857\n",
      "Epoch 3258/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8397 - val_accuracy: 0.7857\n",
      "Epoch 3259/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8401 - val_accuracy: 0.7857\n",
      "Epoch 3260/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8404 - val_accuracy: 0.7857\n",
      "Epoch 3261/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8407 - val_accuracy: 0.7857\n",
      "Epoch 3262/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8411 - val_accuracy: 0.7857\n",
      "Epoch 3263/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8414 - val_accuracy: 0.7857\n",
      "Epoch 3264/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8418 - val_accuracy: 0.7857\n",
      "Epoch 3265/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8423 - val_accuracy: 0.7857\n",
      "Epoch 3266/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8428 - val_accuracy: 0.7857\n",
      "Epoch 3267/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.7857\n",
      "Epoch 3268/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8437 - val_accuracy: 0.7857\n",
      "Epoch 3269/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8441 - val_accuracy: 0.7857\n",
      "Epoch 3270/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8445 - val_accuracy: 0.7857\n",
      "Epoch 3271/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8447 - val_accuracy: 0.7857\n",
      "Epoch 3272/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8451 - val_accuracy: 0.7857\n",
      "Epoch 3273/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8454 - val_accuracy: 0.7857\n",
      "Epoch 3274/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8458 - val_accuracy: 0.7857\n",
      "Epoch 3275/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8462 - val_accuracy: 0.7857\n",
      "Epoch 3276/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8466 - val_accuracy: 0.7857\n",
      "Epoch 3277/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8471 - val_accuracy: 0.7857\n",
      "Epoch 3278/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8476 - val_accuracy: 0.7857\n",
      "Epoch 3279/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8481 - val_accuracy: 0.7857\n",
      "Epoch 3280/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8486 - val_accuracy: 0.7857\n",
      "Epoch 3281/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8488 - val_accuracy: 0.7857\n",
      "Epoch 3282/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8490 - val_accuracy: 0.7857\n",
      "Epoch 3283/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.8493 - val_accuracy: 0.7857\n",
      "Epoch 3284/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8496 - val_accuracy: 0.7857\n",
      "Epoch 3285/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.7857\n",
      "Epoch 3286/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8505 - val_accuracy: 0.7857\n",
      "Epoch 3287/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8509 - val_accuracy: 0.7857\n",
      "Epoch 3288/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8514 - val_accuracy: 0.7857\n",
      "Epoch 3289/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8520 - val_accuracy: 0.7857\n",
      "Epoch 3290/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8525 - val_accuracy: 0.7857\n",
      "Epoch 3291/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.7857\n",
      "Epoch 3292/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8535 - val_accuracy: 0.7857\n",
      "Epoch 3293/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8537 - val_accuracy: 0.7857\n",
      "Epoch 3294/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8540 - val_accuracy: 0.7857\n",
      "Epoch 3295/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8543 - val_accuracy: 0.7857\n",
      "Epoch 3296/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8546 - val_accuracy: 0.7857\n",
      "Epoch 3297/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.7857\n",
      "Epoch 3298/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8554 - val_accuracy: 0.7857\n",
      "Epoch 3299/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8558 - val_accuracy: 0.7857\n",
      "Epoch 3300/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8563 - val_accuracy: 0.7857\n",
      "Epoch 3301/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8567 - val_accuracy: 0.7857\n",
      "Epoch 3302/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8572 - val_accuracy: 0.7857\n",
      "Epoch 3303/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8576 - val_accuracy: 0.7857\n",
      "Epoch 3304/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8579 - val_accuracy: 0.7857\n",
      "Epoch 3305/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8583 - val_accuracy: 0.7857\n",
      "Epoch 3306/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8586 - val_accuracy: 0.7857\n",
      "Epoch 3307/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8590 - val_accuracy: 0.7857\n",
      "Epoch 3308/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8594 - val_accuracy: 0.7857\n",
      "Epoch 3309/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8598 - val_accuracy: 0.7857\n",
      "Epoch 3310/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8603 - val_accuracy: 0.7857\n",
      "Epoch 3311/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.7857\n",
      "Epoch 3312/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.7857\n",
      "Epoch 3313/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8616 - val_accuracy: 0.7857\n",
      "Epoch 3314/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8620 - val_accuracy: 0.7857\n",
      "Epoch 3315/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.7857\n",
      "Epoch 3316/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8626 - val_accuracy: 0.7857\n",
      "Epoch 3317/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8628 - val_accuracy: 0.7857\n",
      "Epoch 3318/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8631 - val_accuracy: 0.7857\n",
      "Epoch 3319/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8636 - val_accuracy: 0.7857\n",
      "Epoch 3320/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8641 - val_accuracy: 0.7857\n",
      "Epoch 3321/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8646 - val_accuracy: 0.7857\n",
      "Epoch 3322/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8650 - val_accuracy: 0.7857\n",
      "Epoch 3323/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8655 - val_accuracy: 0.7857\n",
      "Epoch 3324/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8660 - val_accuracy: 0.7857\n",
      "Epoch 3325/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.7857\n",
      "Epoch 3326/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8667 - val_accuracy: 0.7857\n",
      "Epoch 3327/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8670 - val_accuracy: 0.7857\n",
      "Epoch 3328/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8672 - val_accuracy: 0.7857\n",
      "Epoch 3329/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8675 - val_accuracy: 0.7857\n",
      "Epoch 3330/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8680 - val_accuracy: 0.7857\n",
      "Epoch 3331/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8684 - val_accuracy: 0.7857\n",
      "Epoch 3332/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8688 - val_accuracy: 0.7857\n",
      "Epoch 3333/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8693 - val_accuracy: 0.7857\n",
      "Epoch 3334/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8699 - val_accuracy: 0.7857\n",
      "Epoch 3335/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8704 - val_accuracy: 0.7857\n",
      "Epoch 3336/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8708 - val_accuracy: 0.7857\n",
      "Epoch 3337/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.7857\n",
      "Epoch 3338/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8713 - val_accuracy: 0.7857\n",
      "Epoch 3339/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8715 - val_accuracy: 0.7857\n",
      "Epoch 3340/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8719 - val_accuracy: 0.7857\n",
      "Epoch 3341/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8722 - val_accuracy: 0.7857\n",
      "Epoch 3342/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8726 - val_accuracy: 0.7857\n",
      "Epoch 3343/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.7857\n",
      "Epoch 3344/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8736 - val_accuracy: 0.7857\n",
      "Epoch 3345/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.7857\n",
      "Epoch 3346/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8748 - val_accuracy: 0.7857\n",
      "Epoch 3347/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8753 - val_accuracy: 0.7857\n",
      "Epoch 3348/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8755 - val_accuracy: 0.7857\n",
      "Epoch 3349/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8757 - val_accuracy: 0.7857\n",
      "Epoch 3350/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8759 - val_accuracy: 0.7857\n",
      "Epoch 3351/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8763 - val_accuracy: 0.7857\n",
      "Epoch 3352/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8767 - val_accuracy: 0.7857\n",
      "Epoch 3353/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.7857\n",
      "Epoch 3354/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8774 - val_accuracy: 0.7857\n",
      "Epoch 3355/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8778 - val_accuracy: 0.7857\n",
      "Epoch 3356/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8784 - val_accuracy: 0.7857\n",
      "Epoch 3357/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8790 - val_accuracy: 0.7857\n",
      "Epoch 3358/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8794 - val_accuracy: 0.7857\n",
      "Epoch 3359/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8797 - val_accuracy: 0.7857\n",
      "Epoch 3360/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8799 - val_accuracy: 0.7857\n",
      "Epoch 3361/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8801 - val_accuracy: 0.7857\n",
      "Epoch 3362/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8806 - val_accuracy: 0.7857\n",
      "Epoch 3363/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8810 - val_accuracy: 0.7857\n",
      "Epoch 3364/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8814 - val_accuracy: 0.7857\n",
      "Epoch 3365/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8818 - val_accuracy: 0.7857\n",
      "Epoch 3366/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.7857\n",
      "Epoch 3367/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8827 - val_accuracy: 0.7857\n",
      "Epoch 3368/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8833 - val_accuracy: 0.7857\n",
      "Epoch 3369/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8837 - val_accuracy: 0.7857\n",
      "Epoch 3370/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8840 - val_accuracy: 0.7857\n",
      "Epoch 3371/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8842 - val_accuracy: 0.7857\n",
      "Epoch 3372/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8845 - val_accuracy: 0.7857\n",
      "Epoch 3373/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8848 - val_accuracy: 0.7857\n",
      "Epoch 3374/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8853 - val_accuracy: 0.7857\n",
      "Epoch 3375/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8856 - val_accuracy: 0.7857\n",
      "Epoch 3376/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8860 - val_accuracy: 0.7857\n",
      "Epoch 3377/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8864 - val_accuracy: 0.7857\n",
      "Epoch 3378/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8869 - val_accuracy: 0.7857\n",
      "Epoch 3379/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8874 - val_accuracy: 0.7857\n",
      "Epoch 3380/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8878 - val_accuracy: 0.7857\n",
      "Epoch 3381/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8883 - val_accuracy: 0.7857\n",
      "Epoch 3382/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8885 - val_accuracy: 0.7857\n",
      "Epoch 3383/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8887 - val_accuracy: 0.7857\n",
      "Epoch 3384/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8891 - val_accuracy: 0.7857\n",
      "Epoch 3385/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.7857\n",
      "Epoch 3386/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.7857\n",
      "Epoch 3387/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8903 - val_accuracy: 0.7857\n",
      "Epoch 3388/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8907 - val_accuracy: 0.7714\n",
      "Epoch 3389/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.7714\n",
      "Epoch 3390/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8916 - val_accuracy: 0.7714\n",
      "Epoch 3391/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8920 - val_accuracy: 0.7714\n",
      "Epoch 3392/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.7714\n",
      "Epoch 3393/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8927 - val_accuracy: 0.7714\n",
      "Epoch 3394/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8929 - val_accuracy: 0.7714\n",
      "Epoch 3395/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8932 - val_accuracy: 0.7714\n",
      "Epoch 3396/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8936 - val_accuracy: 0.7714\n",
      "Epoch 3397/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8941 - val_accuracy: 0.7714\n",
      "Epoch 3398/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8946 - val_accuracy: 0.7714\n",
      "Epoch 3399/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8951 - val_accuracy: 0.7714\n",
      "Epoch 3400/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.8956 - val_accuracy: 0.7714\n",
      "Epoch 3401/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8960 - val_accuracy: 0.7714\n",
      "Epoch 3402/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8964 - val_accuracy: 0.7714\n",
      "Epoch 3403/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.7714\n",
      "Epoch 3404/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8970 - val_accuracy: 0.7714\n",
      "Epoch 3405/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8972 - val_accuracy: 0.7714\n",
      "Epoch 3406/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8975 - val_accuracy: 0.7714\n",
      "Epoch 3407/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8979 - val_accuracy: 0.7714\n",
      "Epoch 3408/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8984 - val_accuracy: 0.7714\n",
      "Epoch 3409/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8988 - val_accuracy: 0.7714\n",
      "Epoch 3410/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8993 - val_accuracy: 0.7714\n",
      "Epoch 3411/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8998 - val_accuracy: 0.7714\n",
      "Epoch 3412/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9001 - val_accuracy: 0.7714\n",
      "Epoch 3413/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9004 - val_accuracy: 0.7714\n",
      "Epoch 3414/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9008 - val_accuracy: 0.7714\n",
      "Epoch 3415/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9012 - val_accuracy: 0.7714\n",
      "Epoch 3416/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9015 - val_accuracy: 0.7714\n",
      "Epoch 3417/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.7714\n",
      "Epoch 3418/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.7714\n",
      "Epoch 3419/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9027 - val_accuracy: 0.7714\n",
      "Epoch 3420/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9031 - val_accuracy: 0.7714\n",
      "Epoch 3421/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9036 - val_accuracy: 0.7714\n",
      "Epoch 3422/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.7714\n",
      "Epoch 3423/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.7714\n",
      "Epoch 3424/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9046 - val_accuracy: 0.7714\n",
      "Epoch 3425/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9049 - val_accuracy: 0.7714\n",
      "Epoch 3426/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9053 - val_accuracy: 0.7714\n",
      "Epoch 3427/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9056 - val_accuracy: 0.7714\n",
      "Epoch 3428/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9060 - val_accuracy: 0.7714\n",
      "Epoch 3429/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9063 - val_accuracy: 0.7714\n",
      "Epoch 3430/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9067 - val_accuracy: 0.7714\n",
      "Epoch 3431/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9073 - val_accuracy: 0.7714\n",
      "Epoch 3432/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9078 - val_accuracy: 0.7714\n",
      "Epoch 3433/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9083 - val_accuracy: 0.7714\n",
      "Epoch 3434/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9085 - val_accuracy: 0.7714\n",
      "Epoch 3435/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9088 - val_accuracy: 0.7714\n",
      "Epoch 3436/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.7714\n",
      "Epoch 3437/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9096 - val_accuracy: 0.7714\n",
      "Epoch 3438/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9099 - val_accuracy: 0.7714\n",
      "Epoch 3439/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9102 - val_accuracy: 0.7714\n",
      "Epoch 3440/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9106 - val_accuracy: 0.7714\n",
      "Epoch 3441/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9110 - val_accuracy: 0.7714\n",
      "Epoch 3442/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.7714\n",
      "Epoch 3443/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9119 - val_accuracy: 0.7714\n",
      "Epoch 3444/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9124 - val_accuracy: 0.7714\n",
      "Epoch 3445/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9127 - val_accuracy: 0.7714\n",
      "Epoch 3446/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9129 - val_accuracy: 0.7714\n",
      "Epoch 3447/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9132 - val_accuracy: 0.7714\n",
      "Epoch 3448/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9136 - val_accuracy: 0.7714\n",
      "Epoch 3449/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.7714\n",
      "Epoch 3450/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9144 - val_accuracy: 0.7714\n",
      "Epoch 3451/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9148 - val_accuracy: 0.7714\n",
      "Epoch 3452/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.7714\n",
      "Epoch 3453/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9156 - val_accuracy: 0.7714\n",
      "Epoch 3454/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9161 - val_accuracy: 0.7714\n",
      "Epoch 3455/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9164 - val_accuracy: 0.7714\n",
      "Epoch 3456/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.7714\n",
      "Epoch 3457/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9171 - val_accuracy: 0.7714\n",
      "Epoch 3458/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9174 - val_accuracy: 0.7714\n",
      "Epoch 3459/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9178 - val_accuracy: 0.7714\n",
      "Epoch 3460/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9182 - val_accuracy: 0.7714\n",
      "Epoch 3461/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9185 - val_accuracy: 0.7714\n",
      "Epoch 3462/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9190 - val_accuracy: 0.7714\n",
      "Epoch 3463/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9195 - val_accuracy: 0.7714\n",
      "Epoch 3464/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.7714\n",
      "Epoch 3465/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9204 - val_accuracy: 0.7714\n",
      "Epoch 3466/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9208 - val_accuracy: 0.7714\n",
      "Epoch 3467/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9210 - val_accuracy: 0.7714\n",
      "Epoch 3468/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9214 - val_accuracy: 0.7714\n",
      "Epoch 3469/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9217 - val_accuracy: 0.7714\n",
      "Epoch 3470/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9220 - val_accuracy: 0.7714\n",
      "Epoch 3471/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9223 - val_accuracy: 0.7714\n",
      "Epoch 3472/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9226 - val_accuracy: 0.7714\n",
      "Epoch 3473/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.7714\n",
      "Epoch 3474/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9234 - val_accuracy: 0.7714\n",
      "Epoch 3475/4000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.7714\n",
      "Epoch 3476/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9244 - val_accuracy: 0.7714\n",
      "Epoch 3477/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9247 - val_accuracy: 0.7714\n",
      "Epoch 3478/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9251 - val_accuracy: 0.7714\n",
      "Epoch 3479/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9255 - val_accuracy: 0.7714\n",
      "Epoch 3480/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9258 - val_accuracy: 0.7714\n",
      "Epoch 3481/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9262 - val_accuracy: 0.7714\n",
      "Epoch 3482/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9265 - val_accuracy: 0.7714\n",
      "Epoch 3483/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9269 - val_accuracy: 0.7714\n",
      "Epoch 3484/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9273 - val_accuracy: 0.7714\n",
      "Epoch 3485/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9277 - val_accuracy: 0.7714\n",
      "Epoch 3486/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9281 - val_accuracy: 0.7714\n",
      "Epoch 3487/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9285 - val_accuracy: 0.7714\n",
      "Epoch 3488/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9287 - val_accuracy: 0.7714\n",
      "Epoch 3489/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9291 - val_accuracy: 0.7714\n",
      "Epoch 3490/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9295 - val_accuracy: 0.7714\n",
      "Epoch 3491/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.7714\n",
      "Epoch 3492/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9302 - val_accuracy: 0.7714\n",
      "Epoch 3493/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9307 - val_accuracy: 0.7714\n",
      "Epoch 3494/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9310 - val_accuracy: 0.7714\n",
      "Epoch 3495/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.7714\n",
      "Epoch 3496/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9319 - val_accuracy: 0.7714\n",
      "Epoch 3497/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9323 - val_accuracy: 0.7714\n",
      "Epoch 3498/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9327 - val_accuracy: 0.7714\n",
      "Epoch 3499/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9330 - val_accuracy: 0.7714\n",
      "Epoch 3500/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9334 - val_accuracy: 0.7714\n",
      "Epoch 3501/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9338 - val_accuracy: 0.7714\n",
      "Epoch 3502/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9342 - val_accuracy: 0.7714\n",
      "Epoch 3503/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9345 - val_accuracy: 0.7714\n",
      "Epoch 3504/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9348 - val_accuracy: 0.7714\n",
      "Epoch 3505/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9351 - val_accuracy: 0.7714\n",
      "Epoch 3506/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9355 - val_accuracy: 0.7714\n",
      "Epoch 3507/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9359 - val_accuracy: 0.7714\n",
      "Epoch 3508/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9363 - val_accuracy: 0.7714\n",
      "Epoch 3509/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9366 - val_accuracy: 0.7714\n",
      "Epoch 3510/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9369 - val_accuracy: 0.7714\n",
      "Epoch 3511/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.7714\n",
      "Epoch 3512/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9378 - val_accuracy: 0.7714\n",
      "Epoch 3513/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9383 - val_accuracy: 0.7714\n",
      "Epoch 3514/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9387 - val_accuracy: 0.7714\n",
      "Epoch 3515/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.7714\n",
      "Epoch 3516/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9394 - val_accuracy: 0.7714\n",
      "Epoch 3517/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9398 - val_accuracy: 0.7714\n",
      "Epoch 3518/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9402 - val_accuracy: 0.7714\n",
      "Epoch 3519/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9406 - val_accuracy: 0.7714\n",
      "Epoch 3520/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9410 - val_accuracy: 0.7714\n",
      "Epoch 3521/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9413 - val_accuracy: 0.7714\n",
      "Epoch 3522/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9416 - val_accuracy: 0.7714\n",
      "Epoch 3523/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9420 - val_accuracy: 0.7714\n",
      "Epoch 3524/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9423 - val_accuracy: 0.7714\n",
      "Epoch 3525/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9427 - val_accuracy: 0.7714\n",
      "Epoch 3526/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.7714\n",
      "Epoch 3527/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9434 - val_accuracy: 0.7714\n",
      "Epoch 3528/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9438 - val_accuracy: 0.7714\n",
      "Epoch 3529/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.7714\n",
      "Epoch 3530/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9445 - val_accuracy: 0.7714\n",
      "Epoch 3531/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9450 - val_accuracy: 0.7714\n",
      "Epoch 3532/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9454 - val_accuracy: 0.7714\n",
      "Epoch 3533/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9458 - val_accuracy: 0.7714\n",
      "Epoch 3534/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9462 - val_accuracy: 0.7714\n",
      "Epoch 3535/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9465 - val_accuracy: 0.7714\n",
      "Epoch 3536/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9468 - val_accuracy: 0.7714\n",
      "Epoch 3537/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9472 - val_accuracy: 0.7714\n",
      "Epoch 3538/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9476 - val_accuracy: 0.7714\n",
      "Epoch 3539/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9479 - val_accuracy: 0.7714\n",
      "Epoch 3540/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9482 - val_accuracy: 0.7714\n",
      "Epoch 3541/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9486 - val_accuracy: 0.7714\n",
      "Epoch 3542/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9489 - val_accuracy: 0.7714\n",
      "Epoch 3543/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9493 - val_accuracy: 0.7714\n",
      "Epoch 3544/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9498 - val_accuracy: 0.7714\n",
      "Epoch 3545/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.7714\n",
      "Epoch 3546/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9506 - val_accuracy: 0.7714\n",
      "Epoch 3547/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9509 - val_accuracy: 0.7714\n",
      "Epoch 3548/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9513 - val_accuracy: 0.7714\n",
      "Epoch 3549/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9518 - val_accuracy: 0.7714\n",
      "Epoch 3550/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9521 - val_accuracy: 0.7714\n",
      "Epoch 3551/4000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.7714\n",
      "Epoch 3552/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9529 - val_accuracy: 0.7714\n",
      "Epoch 3553/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9532 - val_accuracy: 0.7714\n",
      "Epoch 3554/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.7714\n",
      "Epoch 3555/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.7714\n",
      "Epoch 3556/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9542 - val_accuracy: 0.7714\n",
      "Epoch 3557/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9545 - val_accuracy: 0.7714\n",
      "Epoch 3558/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9549 - val_accuracy: 0.7714\n",
      "Epoch 3559/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9554 - val_accuracy: 0.7714\n",
      "Epoch 3560/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9557 - val_accuracy: 0.7714\n",
      "Epoch 3561/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9561 - val_accuracy: 0.7714\n",
      "Epoch 3562/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9564 - val_accuracy: 0.7714\n",
      "Epoch 3563/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9568 - val_accuracy: 0.7714\n",
      "Epoch 3564/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9572 - val_accuracy: 0.7714\n",
      "Epoch 3565/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9576 - val_accuracy: 0.7714\n",
      "Epoch 3566/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9580 - val_accuracy: 0.7714\n",
      "Epoch 3567/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9584 - val_accuracy: 0.7714\n",
      "Epoch 3568/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9588 - val_accuracy: 0.7714\n",
      "Epoch 3569/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9591 - val_accuracy: 0.7714\n",
      "Epoch 3570/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.7714\n",
      "Epoch 3571/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9599 - val_accuracy: 0.7714\n",
      "Epoch 3572/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9603 - val_accuracy: 0.7714\n",
      "Epoch 3573/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9607 - val_accuracy: 0.7714\n",
      "Epoch 3574/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9610 - val_accuracy: 0.7714\n",
      "Epoch 3575/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9612 - val_accuracy: 0.7714\n",
      "Epoch 3576/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9615 - val_accuracy: 0.7714\n",
      "Epoch 3577/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.7714\n",
      "Epoch 3578/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9623 - val_accuracy: 0.7714\n",
      "Epoch 3579/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9628 - val_accuracy: 0.7714\n",
      "Epoch 3580/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9633 - val_accuracy: 0.7714\n",
      "Epoch 3581/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9637 - val_accuracy: 0.7714\n",
      "Epoch 3582/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9641 - val_accuracy: 0.7714\n",
      "Epoch 3583/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9644 - val_accuracy: 0.7714\n",
      "Epoch 3584/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9647 - val_accuracy: 0.7714\n",
      "Epoch 3585/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9650 - val_accuracy: 0.7714\n",
      "Epoch 3586/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9654 - val_accuracy: 0.7714\n",
      "Epoch 3587/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9657 - val_accuracy: 0.7714\n",
      "Epoch 3588/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9660 - val_accuracy: 0.7714\n",
      "Epoch 3589/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9662 - val_accuracy: 0.7714\n",
      "Epoch 3590/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9666 - val_accuracy: 0.7714\n",
      "Epoch 3591/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9670 - val_accuracy: 0.7714\n",
      "Epoch 3592/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9675 - val_accuracy: 0.7714\n",
      "Epoch 3593/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9680 - val_accuracy: 0.7714\n",
      "Epoch 3594/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.7714\n",
      "Epoch 3595/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9688 - val_accuracy: 0.7714\n",
      "Epoch 3596/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9690 - val_accuracy: 0.7714\n",
      "Epoch 3597/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9693 - val_accuracy: 0.7714\n",
      "Epoch 3598/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9697 - val_accuracy: 0.7714\n",
      "Epoch 3599/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9701 - val_accuracy: 0.7714\n",
      "Epoch 3600/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9704 - val_accuracy: 0.7714\n",
      "Epoch 3601/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9708 - val_accuracy: 0.7714\n",
      "Epoch 3602/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9712 - val_accuracy: 0.7714\n",
      "Epoch 3603/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9717 - val_accuracy: 0.7714\n",
      "Epoch 3604/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9721 - val_accuracy: 0.7714\n",
      "Epoch 3605/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9725 - val_accuracy: 0.7714\n",
      "Epoch 3606/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9728 - val_accuracy: 0.7714\n",
      "Epoch 3607/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9731 - val_accuracy: 0.7714\n",
      "Epoch 3608/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9733 - val_accuracy: 0.7714\n",
      "Epoch 3609/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9736 - val_accuracy: 0.7714\n",
      "Epoch 3610/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9740 - val_accuracy: 0.7714\n",
      "Epoch 3611/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9744 - val_accuracy: 0.7714\n",
      "Epoch 3612/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9748 - val_accuracy: 0.7714\n",
      "Epoch 3613/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9753 - val_accuracy: 0.7714\n",
      "Epoch 3614/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.9757 - val_accuracy: 0.7714\n",
      "Epoch 3615/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9762 - val_accuracy: 0.7714\n",
      "Epoch 3616/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9765 - val_accuracy: 0.7714\n",
      "Epoch 3617/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9768 - val_accuracy: 0.7714\n",
      "Epoch 3618/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.7714\n",
      "Epoch 3619/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9773 - val_accuracy: 0.7714\n",
      "Epoch 3620/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9776 - val_accuracy: 0.7714\n",
      "Epoch 3621/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9780 - val_accuracy: 0.7714\n",
      "Epoch 3622/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9784 - val_accuracy: 0.7714\n",
      "Epoch 3623/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9788 - val_accuracy: 0.7714\n",
      "Epoch 3624/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9792 - val_accuracy: 0.7714\n",
      "Epoch 3625/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9797 - val_accuracy: 0.7714\n",
      "Epoch 3626/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9801 - val_accuracy: 0.7714\n",
      "Epoch 3627/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.7714\n",
      "Epoch 3628/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9808 - val_accuracy: 0.7714\n",
      "Epoch 3629/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9811 - val_accuracy: 0.7714\n",
      "Epoch 3630/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9814 - val_accuracy: 0.7714\n",
      "Epoch 3631/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9817 - val_accuracy: 0.7714\n",
      "Epoch 3632/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9822 - val_accuracy: 0.7714\n",
      "Epoch 3633/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9825 - val_accuracy: 0.7714\n",
      "Epoch 3634/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9830 - val_accuracy: 0.7714\n",
      "Epoch 3635/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9834 - val_accuracy: 0.7714\n",
      "Epoch 3636/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9838 - val_accuracy: 0.7714\n",
      "Epoch 3637/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9841 - val_accuracy: 0.7714\n",
      "Epoch 3638/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9844 - val_accuracy: 0.7714\n",
      "Epoch 3639/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.7714\n",
      "Epoch 3640/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9851 - val_accuracy: 0.7714\n",
      "Epoch 3641/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9854 - val_accuracy: 0.7714\n",
      "Epoch 3642/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9857 - val_accuracy: 0.7714\n",
      "Epoch 3643/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9861 - val_accuracy: 0.7714\n",
      "Epoch 3644/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.7714\n",
      "Epoch 3645/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9867 - val_accuracy: 0.7714\n",
      "Epoch 3646/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9872 - val_accuracy: 0.7714\n",
      "Epoch 3647/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9877 - val_accuracy: 0.7714\n",
      "Epoch 3648/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9881 - val_accuracy: 0.7714\n",
      "Epoch 3649/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9884 - val_accuracy: 0.7714\n",
      "Epoch 3650/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9887 - val_accuracy: 0.7714\n",
      "Epoch 3651/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9889 - val_accuracy: 0.7714\n",
      "Epoch 3652/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9893 - val_accuracy: 0.7714\n",
      "Epoch 3653/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9898 - val_accuracy: 0.7714\n",
      "Epoch 3654/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9901 - val_accuracy: 0.7714\n",
      "Epoch 3655/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9904 - val_accuracy: 0.7714\n",
      "Epoch 3656/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9907 - val_accuracy: 0.7714\n",
      "Epoch 3657/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9912 - val_accuracy: 0.7714\n",
      "Epoch 3658/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9917 - val_accuracy: 0.7714\n",
      "Epoch 3659/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9922 - val_accuracy: 0.7714\n",
      "Epoch 3660/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9925 - val_accuracy: 0.7714\n",
      "Epoch 3661/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9928 - val_accuracy: 0.7714\n",
      "Epoch 3662/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9930 - val_accuracy: 0.7714\n",
      "Epoch 3663/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.7714\n",
      "Epoch 3664/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9936 - val_accuracy: 0.7714\n",
      "Epoch 3665/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9940 - val_accuracy: 0.7714\n",
      "Epoch 3666/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9944 - val_accuracy: 0.7714\n",
      "Epoch 3667/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9948 - val_accuracy: 0.7714\n",
      "Epoch 3668/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9952 - val_accuracy: 0.7714\n",
      "Epoch 3669/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9956 - val_accuracy: 0.7714\n",
      "Epoch 3670/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.7714\n",
      "Epoch 3671/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.7714\n",
      "Epoch 3672/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9968 - val_accuracy: 0.7714\n",
      "Epoch 3673/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9969 - val_accuracy: 0.7714\n",
      "Epoch 3674/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9971 - val_accuracy: 0.7714\n",
      "Epoch 3675/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9975 - val_accuracy: 0.7714\n",
      "Epoch 3676/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9979 - val_accuracy: 0.7714\n",
      "Epoch 3677/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9984 - val_accuracy: 0.7714\n",
      "Epoch 3678/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9989 - val_accuracy: 0.7714\n",
      "Epoch 3679/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9993 - val_accuracy: 0.7714\n",
      "Epoch 3680/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9997 - val_accuracy: 0.7714\n",
      "Epoch 3681/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0001 - val_accuracy: 0.7714\n",
      "Epoch 3682/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0005 - val_accuracy: 0.7714\n",
      "Epoch 3683/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0008 - val_accuracy: 0.7714\n",
      "Epoch 3684/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0010 - val_accuracy: 0.7714\n",
      "Epoch 3685/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0012 - val_accuracy: 0.7714\n",
      "Epoch 3686/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.7714\n",
      "Epoch 3687/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0018 - val_accuracy: 0.7714\n",
      "Epoch 3688/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0023 - val_accuracy: 0.7714\n",
      "Epoch 3689/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0028 - val_accuracy: 0.7714\n",
      "Epoch 3690/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0032 - val_accuracy: 0.7714\n",
      "Epoch 3691/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0035 - val_accuracy: 0.7714\n",
      "Epoch 3692/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0039 - val_accuracy: 0.7714\n",
      "Epoch 3693/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0042 - val_accuracy: 0.7714\n",
      "Epoch 3694/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0046 - val_accuracy: 0.7714\n",
      "Epoch 3695/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0049 - val_accuracy: 0.7714\n",
      "Epoch 3696/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0052 - val_accuracy: 0.7714\n",
      "Epoch 3697/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0055 - val_accuracy: 0.7714\n",
      "Epoch 3698/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0059 - val_accuracy: 0.7714\n",
      "Epoch 3699/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0063 - val_accuracy: 0.7714\n",
      "Epoch 3700/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0068 - val_accuracy: 0.7714\n",
      "Epoch 3701/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0073 - val_accuracy: 0.7714\n",
      "Epoch 3702/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.7714\n",
      "Epoch 3703/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0080 - val_accuracy: 0.7714\n",
      "Epoch 3704/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0082 - val_accuracy: 0.7714\n",
      "Epoch 3705/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0085 - val_accuracy: 0.7714\n",
      "Epoch 3706/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0088 - val_accuracy: 0.7714\n",
      "Epoch 3707/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0092 - val_accuracy: 0.7714\n",
      "Epoch 3708/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0096 - val_accuracy: 0.7714\n",
      "Epoch 3709/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0099 - val_accuracy: 0.7714\n",
      "Epoch 3710/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0102 - val_accuracy: 0.7714\n",
      "Epoch 3711/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0107 - val_accuracy: 0.7714\n",
      "Epoch 3712/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0111 - val_accuracy: 0.7714\n",
      "Epoch 3713/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0115 - val_accuracy: 0.7714\n",
      "Epoch 3714/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0118 - val_accuracy: 0.7714\n",
      "Epoch 3715/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0122 - val_accuracy: 0.7714\n",
      "Epoch 3716/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0124 - val_accuracy: 0.7714\n",
      "Epoch 3717/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0128 - val_accuracy: 0.7714\n",
      "Epoch 3718/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0131 - val_accuracy: 0.7714\n",
      "Epoch 3719/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0136 - val_accuracy: 0.7714\n",
      "Epoch 3720/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.7714\n",
      "Epoch 3721/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.7714\n",
      "Epoch 3722/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0147 - val_accuracy: 0.7714\n",
      "Epoch 3723/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0150 - val_accuracy: 0.7714\n",
      "Epoch 3724/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0154 - val_accuracy: 0.7714\n",
      "Epoch 3725/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0157 - val_accuracy: 0.7714\n",
      "Epoch 3726/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0160 - val_accuracy: 0.7714\n",
      "Epoch 3727/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0163 - val_accuracy: 0.7714\n",
      "Epoch 3728/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0167 - val_accuracy: 0.7714\n",
      "Epoch 3729/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0171 - val_accuracy: 0.7714\n",
      "Epoch 3730/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0175 - val_accuracy: 0.7714\n",
      "Epoch 3731/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0179 - val_accuracy: 0.7714\n",
      "Epoch 3732/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0183 - val_accuracy: 0.7714\n",
      "Epoch 3733/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0187 - val_accuracy: 0.7714\n",
      "Epoch 3734/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0191 - val_accuracy: 0.7714\n",
      "Epoch 3735/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0194 - val_accuracy: 0.7714\n",
      "Epoch 3736/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0197 - val_accuracy: 0.7714\n",
      "Epoch 3737/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0199 - val_accuracy: 0.7714\n",
      "Epoch 3738/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0202 - val_accuracy: 0.7714\n",
      "Epoch 3739/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0206 - val_accuracy: 0.7714\n",
      "Epoch 3740/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0210 - val_accuracy: 0.7714\n",
      "Epoch 3741/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0215 - val_accuracy: 0.7714\n",
      "Epoch 3742/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0218 - val_accuracy: 0.7714\n",
      "Epoch 3743/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0222 - val_accuracy: 0.7714\n",
      "Epoch 3744/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0226 - val_accuracy: 0.7714\n",
      "Epoch 3745/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0230 - val_accuracy: 0.7714\n",
      "Epoch 3746/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0233 - val_accuracy: 0.7714\n",
      "Epoch 3747/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0235 - val_accuracy: 0.7714\n",
      "Epoch 3748/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0238 - val_accuracy: 0.7714\n",
      "Epoch 3749/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0242 - val_accuracy: 0.7714\n",
      "Epoch 3750/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.7714\n",
      "Epoch 3751/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0250 - val_accuracy: 0.7714\n",
      "Epoch 3752/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0255 - val_accuracy: 0.7714\n",
      "Epoch 3753/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0260 - val_accuracy: 0.7714\n",
      "Epoch 3754/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0263 - val_accuracy: 0.7714\n",
      "Epoch 3755/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0267 - val_accuracy: 0.7714\n",
      "Epoch 3756/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0269 - val_accuracy: 0.7714\n",
      "Epoch 3757/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0271 - val_accuracy: 0.7714\n",
      "Epoch 3758/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0274 - val_accuracy: 0.7714\n",
      "Epoch 3759/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0276 - val_accuracy: 0.7714\n",
      "Epoch 3760/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0279 - val_accuracy: 0.7714\n",
      "Epoch 3761/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0283 - val_accuracy: 0.7714\n",
      "Epoch 3762/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0288 - val_accuracy: 0.7714\n",
      "Epoch 3763/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0293 - val_accuracy: 0.7714\n",
      "Epoch 3764/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0298 - val_accuracy: 0.7714\n",
      "Epoch 3765/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0303 - val_accuracy: 0.7714\n",
      "Epoch 3766/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0307 - val_accuracy: 0.7714\n",
      "Epoch 3767/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0310 - val_accuracy: 0.7714\n",
      "Epoch 3768/4000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0312 - val_accuracy: 0.7714\n",
      "Epoch 3769/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0315 - val_accuracy: 0.7714\n",
      "Epoch 3770/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0317 - val_accuracy: 0.7714\n",
      "Epoch 3771/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0320 - val_accuracy: 0.7714\n",
      "Epoch 3772/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0324 - val_accuracy: 0.7714\n",
      "Epoch 3773/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0328 - val_accuracy: 0.7714\n",
      "Epoch 3774/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0332 - val_accuracy: 0.7714\n",
      "Epoch 3775/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0336 - val_accuracy: 0.7714\n",
      "Epoch 3776/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0340 - val_accuracy: 0.7714\n",
      "Epoch 3777/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0345 - val_accuracy: 0.7714\n",
      "Epoch 3778/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0348 - val_accuracy: 0.7714\n",
      "Epoch 3779/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0351 - val_accuracy: 0.7714\n",
      "Epoch 3780/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0354 - val_accuracy: 0.7714\n",
      "Epoch 3781/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0357 - val_accuracy: 0.7714\n",
      "Epoch 3782/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0360 - val_accuracy: 0.7714\n",
      "Epoch 3783/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0364 - val_accuracy: 0.7714\n",
      "Epoch 3784/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0368 - val_accuracy: 0.7714\n",
      "Epoch 3785/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.7714\n",
      "Epoch 3786/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0376 - val_accuracy: 0.7714\n",
      "Epoch 3787/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0380 - val_accuracy: 0.7714\n",
      "Epoch 3788/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0383 - val_accuracy: 0.7714\n",
      "Epoch 3789/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0387 - val_accuracy: 0.7714\n",
      "Epoch 3790/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0389 - val_accuracy: 0.7714\n",
      "Epoch 3791/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0392 - val_accuracy: 0.7714\n",
      "Epoch 3792/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0395 - val_accuracy: 0.7714\n",
      "Epoch 3793/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0399 - val_accuracy: 0.7714\n",
      "Epoch 3794/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0403 - val_accuracy: 0.7714\n",
      "Epoch 3795/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0407 - val_accuracy: 0.7714\n",
      "Epoch 3796/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0411 - val_accuracy: 0.7714\n",
      "Epoch 3797/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0414 - val_accuracy: 0.7714\n",
      "Epoch 3798/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0417 - val_accuracy: 0.7714\n",
      "Epoch 3799/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0422 - val_accuracy: 0.7714\n",
      "Epoch 3800/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0425 - val_accuracy: 0.7714\n",
      "Epoch 3801/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0428 - val_accuracy: 0.7714\n",
      "Epoch 3802/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0431 - val_accuracy: 0.7714\n",
      "Epoch 3803/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0435 - val_accuracy: 0.7714\n",
      "Epoch 3804/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0438 - val_accuracy: 0.7714\n",
      "Epoch 3805/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0441 - val_accuracy: 0.7714\n",
      "Epoch 3806/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0445 - val_accuracy: 0.7714\n",
      "Epoch 3807/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0449 - val_accuracy: 0.7714\n",
      "Epoch 3808/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0452 - val_accuracy: 0.7714\n",
      "Epoch 3809/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0457 - val_accuracy: 0.7714\n",
      "Epoch 3810/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0460 - val_accuracy: 0.7714\n",
      "Epoch 3811/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0464 - val_accuracy: 0.7714\n",
      "Epoch 3812/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.7714\n",
      "Epoch 3813/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0471 - val_accuracy: 0.7714\n",
      "Epoch 3814/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0476 - val_accuracy: 0.7714\n",
      "Epoch 3815/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0479 - val_accuracy: 0.7714\n",
      "Epoch 3816/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0482 - val_accuracy: 0.7714\n",
      "Epoch 3817/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0484 - val_accuracy: 0.7714\n",
      "Epoch 3818/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0488 - val_accuracy: 0.7714\n",
      "Epoch 3819/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0491 - val_accuracy: 0.7714\n",
      "Epoch 3820/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0494 - val_accuracy: 0.7714\n",
      "Epoch 3821/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0496 - val_accuracy: 0.7714\n",
      "Epoch 3822/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0500 - val_accuracy: 0.7714\n",
      "Epoch 3823/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0504 - val_accuracy: 0.7714\n",
      "Epoch 3824/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.7714\n",
      "Epoch 3825/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0514 - val_accuracy: 0.7714\n",
      "Epoch 3826/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0518 - val_accuracy: 0.7714\n",
      "Epoch 3827/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0522 - val_accuracy: 0.7714\n",
      "Epoch 3828/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0525 - val_accuracy: 0.7714\n",
      "Epoch 3829/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0528 - val_accuracy: 0.7714\n",
      "Epoch 3830/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0531 - val_accuracy: 0.7714\n",
      "Epoch 3831/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0534 - val_accuracy: 0.7714\n",
      "Epoch 3832/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 0.7714\n",
      "Epoch 3833/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0540 - val_accuracy: 0.7714\n",
      "Epoch 3834/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0543 - val_accuracy: 0.7714\n",
      "Epoch 3835/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0547 - val_accuracy: 0.7714\n",
      "Epoch 3836/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0552 - val_accuracy: 0.7714\n",
      "Epoch 3837/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0556 - val_accuracy: 0.7714\n",
      "Epoch 3838/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0560 - val_accuracy: 0.7714\n",
      "Epoch 3839/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0563 - val_accuracy: 0.7714\n",
      "Epoch 3840/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0567 - val_accuracy: 0.7714\n",
      "Epoch 3841/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0570 - val_accuracy: 0.7714\n",
      "Epoch 3842/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.7714\n",
      "Epoch 3843/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0575 - val_accuracy: 0.7714\n",
      "Epoch 3844/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0577 - val_accuracy: 0.7714\n",
      "Epoch 3845/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0581 - val_accuracy: 0.7714\n",
      "Epoch 3846/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0585 - val_accuracy: 0.7714\n",
      "Epoch 3847/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0589 - val_accuracy: 0.7714\n",
      "Epoch 3848/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0594 - val_accuracy: 0.7714\n",
      "Epoch 3849/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0598 - val_accuracy: 0.7714\n",
      "Epoch 3850/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0602 - val_accuracy: 0.7714\n",
      "Epoch 3851/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0605 - val_accuracy: 0.7714\n",
      "Epoch 3852/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0607 - val_accuracy: 0.7714\n",
      "Epoch 3853/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0610 - val_accuracy: 0.7714\n",
      "Epoch 3854/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0613 - val_accuracy: 0.7714\n",
      "Epoch 3855/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0616 - val_accuracy: 0.7714\n",
      "Epoch 3856/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0620 - val_accuracy: 0.7714\n",
      "Epoch 3857/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0625 - val_accuracy: 0.7714\n",
      "Epoch 3858/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0630 - val_accuracy: 0.7714\n",
      "Epoch 3859/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0634 - val_accuracy: 0.7714\n",
      "Epoch 3860/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0637 - val_accuracy: 0.7714\n",
      "Epoch 3861/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0640 - val_accuracy: 0.7714\n",
      "Epoch 3862/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0643 - val_accuracy: 0.7714\n",
      "Epoch 3863/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.7714\n",
      "Epoch 3864/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0648 - val_accuracy: 0.7714\n",
      "Epoch 3865/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0651 - val_accuracy: 0.7714\n",
      "Epoch 3866/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0654 - val_accuracy: 0.7714\n",
      "Epoch 3867/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0658 - val_accuracy: 0.7714\n",
      "Epoch 3868/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0663 - val_accuracy: 0.7714\n",
      "Epoch 3869/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0667 - val_accuracy: 0.7714\n",
      "Epoch 3870/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0672 - val_accuracy: 0.7714\n",
      "Epoch 3871/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0676 - val_accuracy: 0.7714\n",
      "Epoch 3872/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0679 - val_accuracy: 0.7714\n",
      "Epoch 3873/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0682 - val_accuracy: 0.7714\n",
      "Epoch 3874/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.7714\n",
      "Epoch 3875/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0687 - val_accuracy: 0.7714\n",
      "Epoch 3876/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0689 - val_accuracy: 0.7714\n",
      "Epoch 3877/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0692 - val_accuracy: 0.7714\n",
      "Epoch 3878/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0696 - val_accuracy: 0.7714\n",
      "Epoch 3879/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0701 - val_accuracy: 0.7714\n",
      "Epoch 3880/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.7714\n",
      "Epoch 3881/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0710 - val_accuracy: 0.7714\n",
      "Epoch 3882/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0714 - val_accuracy: 0.7714\n",
      "Epoch 3883/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0717 - val_accuracy: 0.7714\n",
      "Epoch 3884/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0720 - val_accuracy: 0.7714\n",
      "Epoch 3885/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0723 - val_accuracy: 0.7714\n",
      "Epoch 3886/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0725 - val_accuracy: 0.7714\n",
      "Epoch 3887/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0728 - val_accuracy: 0.7714\n",
      "Epoch 3888/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0730 - val_accuracy: 0.7714\n",
      "Epoch 3889/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0734 - val_accuracy: 0.7714\n",
      "Epoch 3890/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0739 - val_accuracy: 0.7714\n",
      "Epoch 3891/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0744 - val_accuracy: 0.7714\n",
      "Epoch 3892/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0748 - val_accuracy: 0.7714\n",
      "Epoch 3893/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0752 - val_accuracy: 0.7714\n",
      "Epoch 3894/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0755 - val_accuracy: 0.7714\n",
      "Epoch 3895/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0757 - val_accuracy: 0.7714\n",
      "Epoch 3896/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0759 - val_accuracy: 0.7714\n",
      "Epoch 3897/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.7714\n",
      "Epoch 3898/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0766 - val_accuracy: 0.7714\n",
      "Epoch 3899/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0770 - val_accuracy: 0.7714\n",
      "Epoch 3900/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0774 - val_accuracy: 0.7714\n",
      "Epoch 3901/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0779 - val_accuracy: 0.7714\n",
      "Epoch 3902/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0783 - val_accuracy: 0.7714\n",
      "Epoch 3903/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0787 - val_accuracy: 0.7714\n",
      "Epoch 3904/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0790 - val_accuracy: 0.7714\n",
      "Epoch 3905/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0793 - val_accuracy: 0.7714\n",
      "Epoch 3906/4000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0795 - val_accuracy: 0.7714\n",
      "Epoch 3907/4000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0796 - val_accuracy: 0.7714\n",
      "Epoch 3908/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0799 - val_accuracy: 0.7714\n",
      "Epoch 3909/4000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0803 - val_accuracy: 0.7714\n",
      "Epoch 3910/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0807 - val_accuracy: 0.7714\n",
      "Epoch 3911/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.7714\n",
      "Epoch 3912/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0817 - val_accuracy: 0.7714\n",
      "Epoch 3913/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0821 - val_accuracy: 0.7714\n",
      "Epoch 3914/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0824 - val_accuracy: 0.7714\n",
      "Epoch 3915/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0827 - val_accuracy: 0.7714\n",
      "Epoch 3916/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0831 - val_accuracy: 0.7714\n",
      "Epoch 3917/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0833 - val_accuracy: 0.7714\n",
      "Epoch 3918/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0835 - val_accuracy: 0.7714\n",
      "Epoch 3919/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0838 - val_accuracy: 0.7714\n",
      "Epoch 3920/4000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0841 - val_accuracy: 0.7714\n",
      "Epoch 3921/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0846 - val_accuracy: 0.7714\n",
      "Epoch 3922/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0851 - val_accuracy: 0.7714\n",
      "Epoch 3923/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0856 - val_accuracy: 0.7714\n",
      "Epoch 3924/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0859 - val_accuracy: 0.7714\n",
      "Epoch 3925/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0862 - val_accuracy: 0.7714\n",
      "Epoch 3926/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0865 - val_accuracy: 0.7714\n",
      "Epoch 3927/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0868 - val_accuracy: 0.7714\n",
      "Epoch 3928/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0870 - val_accuracy: 0.7714\n",
      "Epoch 3929/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0872 - val_accuracy: 0.7714\n",
      "Epoch 3930/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0875 - val_accuracy: 0.7714\n",
      "Epoch 3931/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0878 - val_accuracy: 0.7714\n",
      "Epoch 3932/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0883 - val_accuracy: 0.7714\n",
      "Epoch 3933/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0889 - val_accuracy: 0.7714\n",
      "Epoch 3934/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0895 - val_accuracy: 0.7714\n",
      "Epoch 3935/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0899 - val_accuracy: 0.7714\n",
      "Epoch 3936/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0902 - val_accuracy: 0.7714\n",
      "Epoch 3937/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0905 - val_accuracy: 0.7714\n",
      "Epoch 3938/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0906 - val_accuracy: 0.7714\n",
      "Epoch 3939/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0907 - val_accuracy: 0.7714\n",
      "Epoch 3940/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0909 - val_accuracy: 0.7714\n",
      "Epoch 3941/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0912 - val_accuracy: 0.7714\n",
      "Epoch 3942/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0915 - val_accuracy: 0.7714\n",
      "Epoch 3943/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0920 - val_accuracy: 0.7714\n",
      "Epoch 3944/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0925 - val_accuracy: 0.7714\n",
      "Epoch 3945/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0931 - val_accuracy: 0.7714\n",
      "Epoch 3946/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0935 - val_accuracy: 0.7714\n",
      "Epoch 3947/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0939 - val_accuracy: 0.7714\n",
      "Epoch 3948/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0942 - val_accuracy: 0.7714\n",
      "Epoch 3949/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0944 - val_accuracy: 0.7714\n",
      "Epoch 3950/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0947 - val_accuracy: 0.7714\n",
      "Epoch 3951/4000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0949 - val_accuracy: 0.7714\n",
      "Epoch 3952/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0952 - val_accuracy: 0.7714\n",
      "Epoch 3953/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0957 - val_accuracy: 0.7714\n",
      "Epoch 3954/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0962 - val_accuracy: 0.7714\n",
      "Epoch 3955/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.7714\n",
      "Epoch 3956/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0973 - val_accuracy: 0.7714\n",
      "Epoch 3957/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0978 - val_accuracy: 0.7714\n",
      "Epoch 3958/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0982 - val_accuracy: 0.7714\n",
      "Epoch 3959/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0984 - val_accuracy: 0.7714\n",
      "Epoch 3960/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0986 - val_accuracy: 0.7714\n",
      "Epoch 3961/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0988 - val_accuracy: 0.7714\n",
      "Epoch 3962/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0990 - val_accuracy: 0.7714\n",
      "Epoch 3963/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0993 - val_accuracy: 0.7714\n",
      "Epoch 3964/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0997 - val_accuracy: 0.7714\n",
      "Epoch 3965/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1001 - val_accuracy: 0.7714\n",
      "Epoch 3966/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1006 - val_accuracy: 0.7714\n",
      "Epoch 3967/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1011 - val_accuracy: 0.7714\n",
      "Epoch 3968/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1016 - val_accuracy: 0.7714\n",
      "Epoch 3969/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.7714\n",
      "Epoch 3970/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1021 - val_accuracy: 0.7714\n",
      "Epoch 3971/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1024 - val_accuracy: 0.7714\n",
      "Epoch 3972/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1026 - val_accuracy: 0.7714\n",
      "Epoch 3973/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1029 - val_accuracy: 0.7714\n",
      "Epoch 3974/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1032 - val_accuracy: 0.7714\n",
      "Epoch 3975/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1036 - val_accuracy: 0.7714\n",
      "Epoch 3976/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1040 - val_accuracy: 0.7714\n",
      "Epoch 3977/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1045 - val_accuracy: 0.7714\n",
      "Epoch 3978/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1049 - val_accuracy: 0.7714\n",
      "Epoch 3979/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1053 - val_accuracy: 0.7714\n",
      "Epoch 3980/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1057 - val_accuracy: 0.7714\n",
      "Epoch 3981/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.7714\n",
      "Epoch 3982/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1060 - val_accuracy: 0.7714\n",
      "Epoch 3983/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1062 - val_accuracy: 0.7714\n",
      "Epoch 3984/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1065 - val_accuracy: 0.7714\n",
      "Epoch 3985/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1068 - val_accuracy: 0.7714\n",
      "Epoch 3986/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.7714\n",
      "Epoch 3987/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1077 - val_accuracy: 0.7714\n",
      "Epoch 3988/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1082 - val_accuracy: 0.7714\n",
      "Epoch 3989/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1087 - val_accuracy: 0.7714\n",
      "Epoch 3990/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1091 - val_accuracy: 0.7714\n",
      "Epoch 3991/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1094 - val_accuracy: 0.7714\n",
      "Epoch 3992/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1096 - val_accuracy: 0.7714\n",
      "Epoch 3993/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1098 - val_accuracy: 0.7714\n",
      "Epoch 3994/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1099 - val_accuracy: 0.7714\n",
      "Epoch 3995/4000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.7714\n",
      "Epoch 3996/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1106 - val_accuracy: 0.7714\n",
      "Epoch 3997/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.7714\n",
      "Epoch 3998/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1114 - val_accuracy: 0.7714\n",
      "Epoch 3999/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1119 - val_accuracy: 0.7714\n",
      "Epoch 4000/4000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1123 - val_accuracy: 0.7714\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the performance of the model on the test dataset and report the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.771\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will plot the model's performance on both the train and test set for each epoch. If the model does indeed overfit the training dataset, we would expect the line plot of cross-entropy loss and classification accuracy to show the pattern of overfitting. That is an improvement on both train and test sets until an inflection point, after which performance continues to improve for the train set and begins to get worse for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie all of these pieces together; the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.757\n"
     ]
    }
   ],
   "source": [
    "# overfit mlp for the moons dataset\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test sets\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, epochs=4000, validation_data=(testX, testy), verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example first reports the model performance on the train and test datasets. We can see that the model has better performance on the training dataset than the test dataset, one possible sign of overfitting.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figure is created showing line plots of the model loss and accuracy on the train and test sets. We can see the expected shape of an overfit model where test accuracy increases to a point and then begins to decrease again. The effect is even more dramatic with loss, showing a large increase in test set loss as training continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With Input Layer Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is defined by points that have a controlled amount of statistical noise. Nevertheless, we may wish to add further noise to the input values because the dataset is small. This will create more samples or resampling the domain, making the structure of the input space artificially smoother. This may make the problem easier to learn and improve generalization performance. We can add a GaussianNoise layer as the input layer, and the amount of noise must be small. Given that the input values are within the range [0, 1], we will add Gaussian noise with a mean of 0.0 and a standard deviation of 0.01, chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.01, input_shape=(2,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example of this change is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.786\n"
     ]
    }
   ],
   "source": [
    "# mlp overfit on the two circles dataset with input noise\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(GaussianNoise(0.01, input_shape=(2,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we may see a slight lift in the model's performance on the test dataset, with no negative impact on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the impact of the added noise on the evaluation of the model during training as graphed on the line plot. The noise causes the model's accuracy to jump around during training, possibly due to the noise introducing points that conflict with true points from the training dataset. Perhaps a lower input noise standard deviation would be more appropriate. The model still shows a pattern of overfitting, with a rise and then fall in test accuracy over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP With Hidden Layer Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to adding noise to the input values is to add noise between the hidden layers. This can be done by adding noise to the linear output of the layer (weighted sum) before the activation function is applied, in this case, a rectified linear activation function. We can also use a larger standard deviation for the noise as the model is less sensitive to noise at this level, given the presumably larger weights from overfitting. We will use a standard deviation of 0.1, again, chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example with Gaussian noise between the hidden layers is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.967, Test: 0.786\n"
     ]
    }
   ],
   "source": [
    "# mlp overfit on the two circles dataset with hidden layer noise\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "In this case, we can see a marked increase in the model's performance on the hold-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see from the line plot of accuracy over training epochs that the model no longer appears to show the properties of overfitting with regard to classification accuracy. The learning curves for loss do still show a pattern of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also experiment and add the noise after the outputs of the first hidden layer pass through the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.814\n"
     ]
    }
   ],
   "source": [
    "# mlp overfit on the two circles dataset with hidden layer noise (alternate)\n",
    "from sklearn.datasets import make_circles\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GaussianNoise\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_circles(n_samples=100, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(GaussianNoise(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example reports the model performance on the train and test datasets.\n",
    "\n",
    "**Note:** Your specific results may vary, given the stochastic nature of the learning algorithm. Consider running the example a few times and compare the average performance.\n",
    "\n",
    "Surprisingly, we see little difference in the model's performance, perhaps a tiny lift in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see from the line plot of accuracy over training epochs that the model no longer shows signs of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss learning curves\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross-Entropy Loss', pad=-40)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "# plot accuracy learning curves\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy', pad=-40)\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "* **Repeated Evaluation**. Update the example to use repeated model evaluation with and without noise and report performance as the mean and standard deviation over repeats.\n",
    "* **Grid Search Standard Deviation**. Develop a grid search to discover the amount of noise that reliably results in the best-performing model.\n",
    "* **Input and Hidden Noise**. Update the example to introduce noise at both the input and hidden layers of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you discovered that adding noise to a neural network during training can improve the robustness of the network resulting in better generalization and faster learning. Specifically, you learned:\n",
    "\n",
    "* Small datasets can make learning challenging for neural nets, and the examples can be memorized.\n",
    "* Adding noise during training can make the training process more robust and reduce generalization error.\n",
    "* Noise is traditionally added to the inputs but can also be added to weights, gradients, and even activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
